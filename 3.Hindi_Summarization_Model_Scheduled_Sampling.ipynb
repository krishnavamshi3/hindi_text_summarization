{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "VOhw4MViOlgb",
        "nPshHzWkGy9G",
        "Ifr6xPCCH-6r",
        "oeWwMVL0Ic2r",
        "oapGiq-KLiFL",
        "XpqwdCAVK5uE",
        "Fxvwy-T5KvIz",
        "y4EKS0e5IsEB",
        "f5lP9ZHFMLlD",
        "Vl42_ExqL17l",
        "HArp8MJDMePU",
        "HyX9o0teI4fb",
        "0CT_2nWdJNnD",
        "-BUkkzzj20LP",
        "e7ViuuP3IIeL",
        "KbiV0YM0O0MO",
        "Ww6wYED7O5Z0",
        "-1QqzygJ2cxz"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrVBK1BuGuXT"
      },
      "source": [
        "https://github.com/yaserkl/RLSeq2Seq/blob/master/src/run_summarization.py\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "@article{keneshloo2018deep,\n",
        " title={Deep Reinforcement Learning For Sequence to Sequence Models},\n",
        "}\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lx4W7ksuGwUT"
      },
      "source": [
        "## Helpers (Google Drive)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scSsHjmDGzrK"
      },
      "source": [
        "### Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bpp_81k95QL",
        "outputId": "dfc7cb8a-d182-4d62-b1c3-cc57b413ac77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge"
      ],
      "metadata": {
        "id": "ClIK_lU16Cbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "tf.disable_v2_behavior() "
      ],
      "metadata": {
        "id": "c1EaBHL4CmEW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66e8ef0b-8484-4f68-aaf3-fc7952529757"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gR-ZiNFACW46"
      },
      "source": [
        "default_path = \"drive/My Drive/hindi_dataset/\"\n",
        "\n",
        "#-------------------------------save/load--------------------------------------#\n",
        "pickle_path = default_path + \"pickles/\"\n",
        "log_file = default_path + \"logs.txt\"\n",
        "csv_file = default_path + \"logs.csv\"\n",
        "\n",
        "tensorflow_log_file = default_path + 'tensorflow3.log'\n",
        "\n",
        "log_file_handler = open(log_file,\"a\")\n",
        "csv_file_handler = open(csv_file,\"a\")\n",
        "\n",
        "file1 = open(log_file , \"w+\")\n",
        "file2 = open(csv_file , \"w+\")\n",
        "\n",
        "import pickle\n",
        "\n",
        "def save(obj , filename):\n",
        "  print(\"saving {} ..\".format(filename))\n",
        "  with open(filename, 'wb') as handle:\n",
        "      pickle.dump(obj, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "      \n",
        "def load(filename):\n",
        "  print(\"loading {} ..\".format(filename))\n",
        "  with open(filename, 'rb') as handle:\n",
        "    return pickle.load(handle)\n",
        "#-----------------------------------------------------------------------------------#  "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqDmhQeuS81V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5bbbea7-f62d-4b0e-c7d5-367d8ee902c1"
      },
      "source": [
        "with open(tensorflow_log_file , \"r\") as reader:\n",
        "  print(reader.read())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOhw4MViOlgb"
      },
      "source": [
        "### Requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSb-2ufSOrAC"
      },
      "source": [
        "https://github.com/yaserkl/RLSeq2Seq/blob/master/python_requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qyq4XU7OnrC",
        "outputId": "3ab51300-ae35-4c70-baae-fada509388af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install PyYAML\n",
        "!pip install spacy\n",
        "!pip install scikit-learn\n",
        "!pip install nltk\n",
        "!pip install pyrouge"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (6.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.4.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.5)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.1.1)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.10.2)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.1.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.10.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.24)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyrouge\n",
            "  Downloading pyrouge-0.1.3.tar.gz (60 kB)\n",
            "\u001b[K     |████████████████████████████████| 60 kB 4.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyrouge\n",
            "  Building wheel for pyrouge (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyrouge: filename=pyrouge-0.1.3-py3-none-any.whl size=191621 sha256=393e5d7ff636e3d1818804bd669eed7dd18d638982cda7cadb3814b057c4475a\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/35/6a/ffb9a1f51b2b00fee42e7f67f5a5d8e10c67d048cda09ccd57\n",
            "Successfully built pyrouge\n",
            "Installing collected packages: pyrouge\n",
            "Successfully installed pyrouge-0.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgCuTT0PZ8wq",
        "outputId": "bd09ab53-c697-4cb2-898b-fe97916fd10c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CI_dHFzBG33S"
      },
      "source": [
        "## Model Helpers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPshHzWkGy9G"
      },
      "source": [
        "### Progress Bar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HfUeKZkG1EC"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "\n",
        "import json\n",
        "import os\n",
        "import pandas\n",
        "import io\n",
        "import sys\n",
        "import re\n",
        "\n",
        "\n",
        "class ProgressBar(object):\n",
        "    DEFAULT = 'Progress: %(bar)s %(percent)3d%%'\n",
        "    FULL = '%(bar)s %(current)d/%(total)d (%(percent)3d%%) %(remaining)d to go'\n",
        "\n",
        "    def __init__(self, total, width=40, fmt=DEFAULT, symbol='=',\n",
        "                 output=sys.stderr):\n",
        "        assert len(symbol) == 1\n",
        "\n",
        "        self.total = total\n",
        "        self.width = width\n",
        "        self.symbol = symbol\n",
        "        self.output = output\n",
        "        self.fmt = re.sub(r'(?P<name>%\\(.+?\\))d',\n",
        "            r'\\g<name>%dd' % len(str(total)), fmt)\n",
        "\n",
        "        self.current = 0\n",
        "\n",
        "    def __call__(self):\n",
        "        percent = self.current / float(self.total)\n",
        "        size = int(self.width * percent)\n",
        "        remaining = self.total - self.current\n",
        "        bar = '[' + self.symbol * size + ' ' * (self.width - size) + ']'\n",
        "\n",
        "        args = {\n",
        "            'total': self.total,\n",
        "            'bar': bar,\n",
        "            'current': self.current,\n",
        "            'percent': percent * 100,\n",
        "            'remaining': remaining\n",
        "        }\n",
        "        print('\\r' + self.fmt % args, file=self.output, end='')\n",
        "\n",
        "    def done(self):\n",
        "        self.current = self.total\n",
        "        self()\n",
        "        print('', file=self.output)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ifr6xPCCH-6r"
      },
      "source": [
        "### Vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T27x4AEeIC67"
      },
      "source": [
        "https://github.com/yaserkl/RLSeq2Seq/blob/master/src/data.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuHqMQ0xIDMy"
      },
      "source": [
        "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
        "# Modifications Copyright 2017 Abigail See\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "\"\"\"This file contains code to read the train/eval/test data from file and process it, and read the vocab data from file and process it\"\"\"\n",
        "\n",
        "import glob\n",
        "import random\n",
        "import struct\n",
        "import csv\n",
        "from tensorflow.core.example import example_pb2\n",
        "import operator\n",
        "import numpy as np\n",
        "np.random.seed(123)\n",
        "\n",
        "# <s> and </s> are used in the data files to segment the abstracts into sentences. They don't receive vocab ids.\n",
        "SENTENCE_START = '<s>'\n",
        "SENTENCE_END = '</s>'\n",
        "\n",
        "PAD_TOKEN = '[PAD]' # This has a vocab id, which is used to pad the encoder input, decoder input and target sequence\n",
        "UNKNOWN_TOKEN = '[UNK]' # This has a vocab id, which is used to represent out-of-vocabulary words\n",
        "START_DECODING = '[START]' # This has a vocab id, which is used at the start of every decoder input sequence\n",
        "STOP_DECODING = '[STOP]' # This has a vocab id, which is used at the end of untruncated target sequences\n",
        "\n",
        "# Note: none of <s>, </s>, [PAD], [UNK], [START], [STOP] should appear in the vocab file.\n",
        "\n",
        "\n",
        "class Vocab(object):\n",
        "  \"\"\"Vocabulary class for mapping between words and ids (integers)\"\"\"\n",
        "\n",
        "  def __init__(self, vocab_file, max_size):\n",
        "    \"\"\"Creates a vocab of up to max_size words, reading from the vocab_file. If max_size is 0, reads the entire vocab file.\n",
        "    Args:\n",
        "      vocab_file: path to the vocab file, which is assumed to contain \"<word> <frequency>\" on each line, sorted with most frequent word first. This code doesn't actually use the frequencies, though.\n",
        "      max_size: integer. The maximum size of the resulting Vocabulary.\"\"\"\n",
        "    self._word_to_id = {}\n",
        "    self._id_to_word = {}\n",
        "    self._count = 0 # keeps track of total number of words in the Vocab\n",
        "\n",
        "    # [UNK], [PAD], [START] and [STOP] get the ids 0,1,2,3.\n",
        "    for w in [UNKNOWN_TOKEN, PAD_TOKEN, START_DECODING, STOP_DECODING]:\n",
        "      self._word_to_id[w.lower()] = self._count\n",
        "      self._id_to_word[self._count] = w.lower()\n",
        "      self._count += 1\n",
        "\n",
        "    # Read the vocab file and add words up to max_size\n",
        "    with open(vocab_file, 'r') as vocab_f:\n",
        "      for line in vocab_f:\n",
        "        pieces = line.split()\n",
        "        if len(pieces) != 2:\n",
        "          print('Warning: incorrectly formatted line in vocabulary file: %s\\n' % line)\n",
        "          continue\n",
        "        w = pieces[0].lower()\n",
        "        if w in [SENTENCE_START, SENTENCE_END, UNKNOWN_TOKEN, PAD_TOKEN, START_DECODING, STOP_DECODING]:\n",
        "          raise Exception('<s>, </s>, [UNK], [PAD], [START] and [STOP] shouldn\\'t be in the vocab file, but %s is' % w)\n",
        "        if w in self._word_to_id:\n",
        "          print(\"Duplicate:\",w)\n",
        "          continue\n",
        "          raise Exception('Duplicated word in vocabulary file: %s' % w)\n",
        "        self._word_to_id[w] = self._count\n",
        "        self._id_to_word[self._count] = w\n",
        "        self._count += 1\n",
        "        if max_size != 0 and self._count >= max_size:\n",
        "          print(\"max_size of vocab was specified as %i; we now have %i words. Stopping reading.\" % (max_size, self._count))\n",
        "          break\n",
        "\n",
        "    #print(\"Finished constructing vocabulary of %i total words. Last word added: %s\" % (self._count, self._id_to_word[self._count-1]))\n",
        "\n",
        "  def word2id(self, word):\n",
        "    \"\"\"Returns the id (integer) of a word (string). Returns [UNK] id if word is OOV.\"\"\"\n",
        "    if word not in self._word_to_id:\n",
        "      return self._word_to_id[UNKNOWN_TOKEN.lower()]\n",
        "    return self._word_to_id[word.lower()]\n",
        "\n",
        "  def id2word(self, word_id):\n",
        "    \"\"\"Returns the word (string) corresponding to an id (integer).\"\"\"\n",
        "    if word_id not in self._id_to_word:\n",
        "      raise ValueError('Id not found in vocab: %d' % word_id)\n",
        "    return self._id_to_word[word_id]\n",
        "\n",
        "  def size(self):\n",
        "    \"\"\"Returns the total size of the vocabulary\"\"\"\n",
        "    return self._count\n",
        "\n",
        "  def write_metadata(self, fpath):\n",
        "    \"\"\"Writes metadata file for Tensorboard word embedding visualizer as described here:\n",
        "      https://www.tensorflow.org/get_started/embedding_viz\n",
        "    Args:\n",
        "      fpath: place to write the metadata file\n",
        "    \"\"\"\n",
        "    print(\"Writing word embedding metadata file to %s...\" % (fpath))\n",
        "    with open(fpath, \"w\") as f:\n",
        "      fieldnames = ['word']\n",
        "      writer = csv.DictWriter(f,delimiter=str(u\"\\t\").encode('utf-8') , fieldnames=fieldnames)\n",
        "      for i in range(self.size()):\n",
        "        writer.writerow({\"word\": self._id_to_word[i]})\n",
        "\n",
        "  def LoadWordEmbedding(self, w2v_file, word_dim):\n",
        "    self.wordDict = {}\n",
        "    self.word_dim = word_dim\n",
        "\n",
        "    self.wordDict[UNKNOWN_TOKEN] = np.zeros(self.word_dim,dtype=np.float32)\n",
        "    self.wordDict[PAD_TOKEN] = np.random.uniform(-1,1,self.word_dim)\n",
        "    self.wordDict[START_DECODING] = np.random.uniform(-1,1,self.word_dim)\n",
        "    self.wordDict[STOP_DECODING] = np.random.uniform(-1,1,self.word_dim)\n",
        "    ##with open(w2v_file) as wf:\n",
        "    ##  for line in wf:\n",
        "    ##    info = line.strip().split()\n",
        "    ##    word = info[0]\n",
        "    ##    coef = np.asarray(info[1:], dtype='float32')\n",
        "    ##    self.wordDict[word] = coef\n",
        "    ##    assert self.word_dim == len(coef)\n",
        "    #for a in embeddings_index.keys():\n",
        "    #  self.wordDict[a] = embeddings_index[a]\n",
        "      \n",
        "      \n",
        "    import gensim\n",
        "    from gensim.models.keyedvectors import KeyedVectors\n",
        "\n",
        "    #--------------------------------------my model-------------------------------------------#\n",
        "    print('Loading my Model ..')\n",
        "    model = KeyedVectors.load(w2v_file, mmap='r')\n",
        "    print('Loading Done el7 !!')\n",
        "    progress = ProgressBar(len(model.vocab), fmt=ProgressBar.FULL)\n",
        "\n",
        "    for word in model.wv.vocab:\n",
        "          embedding = np.asarray(model[word], dtype='float32')\n",
        "          self.wordDict[word] = embedding\n",
        "          progress.current += 1\n",
        "          progress()\n",
        "    progress.done()\n",
        "    print('\\n Word embeddings:', len(self.wordDict))\n",
        "    print('\\n')\n",
        "\n",
        "    self.MakeWordEmbedding()\n",
        "\n",
        "  def MakeWordEmbedding(self):\n",
        "    sorted_x = sorted(self._word_to_id.items(), key=operator.itemgetter(1))\n",
        "    self._wordEmbedding = np.zeros((self.size(), self.word_dim),dtype=np.float32) # replace unknown words with UNKNOWN_TOKEN embedding (zero vector)\n",
        "    for word,i in sorted_x:\n",
        "      if word in self.wordDict:\n",
        "        self._wordEmbedding[i,:] = self.wordDict[word.lower()]\n",
        "    print('Word Embedding Reading done.')\n",
        "\n",
        "  def getWordEmbedding(self):\n",
        "    print('getWordEmbedding.')\n",
        "    return self._wordEmbedding\n",
        "\n",
        "def example_generator(data_path, single_pass):\n",
        "  \"\"\"Generates tf.Examples from data files.\n",
        "    Binary data format: <length><blob>. <length> represents the byte size\n",
        "    of <blob>. <blob> is serialized tf.Example proto. The tf.Example contains\n",
        "    the tokenized article text and summary.\n",
        "  Args:\n",
        "    data_path:\n",
        "      Path to tf.Example data files. Can include wildcards, e.g. if you have several training data chunk files train_001.bin, train_002.bin, etc, then pass data_path=train_* to access them all.\n",
        "    single_pass:\n",
        "      Boolean. If True, go through the dataset exactly once, generating examples in the order they appear, then return. Otherwise, generate random examples indefinitely.\n",
        "  Yields:\n",
        "    Deserialized tf.Example.\n",
        "  \"\"\"\n",
        "  while True:\n",
        "    import glob\n",
        "    filelist = glob.glob(data_path)\n",
        "    #filelist = glob.glob(data_path) # get the list of datafiles\n",
        "    #assert filelist, ('Error: Empty filelist at %s' % data_path) # check filelist isn't empty\n",
        "    if single_pass:\n",
        "      filelist = sorted(filelist)\n",
        "    else:\n",
        "      random.shuffle(filelist)\n",
        "    for f in filelist:\n",
        "      reader = open(f, 'rb')\n",
        "      while True:\n",
        "        len_bytes = reader.read(8)\n",
        "        if not len_bytes: break # finished reading this file\n",
        "        str_len = struct.unpack('q', len_bytes)[0]\n",
        "        example_str = struct.unpack('%ds' % str_len, reader.read(str_len))[0]\n",
        "        yield example_pb2.Example.FromString(example_str)\n",
        "    if single_pass:\n",
        "      print(\"example_generator completed reading all datafiles. No more data.\")\n",
        "      break\n",
        "\n",
        "\n",
        "def article2ids(article_words, vocab):\n",
        "  \"\"\"Map the article words to their ids. Also return a list of OOVs in the article.\n",
        "  Args:\n",
        "    article_words: list of words (strings)\n",
        "    vocab: Vocabulary object\n",
        "  Returns:\n",
        "    ids:\n",
        "      A list of word ids (integers); OOVs are represented by their temporary article OOV number. If the vocabulary size is 50k and the article has 3 OOVs, then these temporary OOV numbers will be 50000, 50001, 50002.\n",
        "    oovs:\n",
        "      A list of the OOV words in the article (strings), in the order corresponding to their temporary article OOV numbers.\"\"\"\n",
        "  ids = []\n",
        "  oovs = []\n",
        "  unk_id = vocab.word2id(UNKNOWN_TOKEN)\n",
        "  for w in article_words:\n",
        "    i = vocab.word2id(w)\n",
        "    if i == unk_id: # If w is OOV\n",
        "      if w not in oovs: # Add to list of OOVs\n",
        "        oovs.append(w)\n",
        "      oov_num = oovs.index(w) # This is 0 for the first article OOV, 1 for the second article OOV...\n",
        "      ids.append(vocab.size() + oov_num) # This is e.g. 50000 for the first article OOV, 50001 for the second...\n",
        "    else:\n",
        "      ids.append(i)\n",
        "  return ids, oovs\n",
        "\n",
        "\n",
        "def abstract2ids(abstract_words, vocab, article_oovs):\n",
        "  \"\"\"Map the abstract words to their ids. In-article OOVs are mapped to their temporary OOV numbers.\n",
        "  Args:\n",
        "    abstract_words: list of words (strings)\n",
        "    vocab: Vocabulary object\n",
        "    article_oovs: list of in-article OOV words (strings), in the order corresponding to their temporary article OOV numbers\n",
        "  Returns:\n",
        "    ids: List of ids (integers). In-article OOV words are mapped to their temporary OOV numbers. Out-of-article OOV words are mapped to the UNK token id.\"\"\"\n",
        "  ids = []\n",
        "  unk_id = vocab.word2id(UNKNOWN_TOKEN)\n",
        "  for w in abstract_words:\n",
        "    i = vocab.word2id(w)\n",
        "    if i == unk_id: # If w is an OOV word\n",
        "      if w in article_oovs: # If w is an in-article OOV\n",
        "        vocab_idx = vocab.size() + article_oovs.index(w) # Map to its temporary article OOV number\n",
        "        ids.append(vocab_idx)\n",
        "      else: # If w is an out-of-article OOV\n",
        "        ids.append(unk_id) # Map to the UNK token id\n",
        "    else:\n",
        "      ids.append(i)\n",
        "  return ids\n",
        "\n",
        "\n",
        "def outputids2words(id_list, vocab, article_oovs):\n",
        "  \"\"\"Maps output ids to words, including mapping in-article OOVs from their temporary ids to the original OOV string (applicable in pointer-generator mode).\n",
        "  Args:\n",
        "    id_list: list of ids (integers)\n",
        "    vocab: Vocabulary object\n",
        "    article_oovs: list of OOV words (strings) in the order corresponding to their temporary article OOV ids (that have been assigned in pointer-generator mode), or None (in baseline mode)\n",
        "  Returns:\n",
        "    words: list of words (strings)\n",
        "  \"\"\"\n",
        "  words = []\n",
        "  for i in id_list:\n",
        "    try:\n",
        "      w = vocab.id2word(i) # might be [UNK]\n",
        "    except ValueError as e: # w is OOV\n",
        "      assert article_oovs is not None, \"Error: model produced a word ID that isn't in the vocabulary. This should not happen in baseline (no pointer-generator) mode\"\n",
        "      article_oov_idx = i - vocab.size()\n",
        "      try:\n",
        "        w = article_oovs[article_oov_idx]\n",
        "      except ValueError as e: # i doesn't correspond to an article oov\n",
        "        raise ValueError('Error: model produced word ID %i which corresponds to article OOV %i but this example only has %i article OOVs' % (i, article_oov_idx, len(article_oovs)))\n",
        "    words.append(w)\n",
        "  return words\n",
        "\n",
        "\n",
        "def abstract2sents(abstract):\n",
        "  \"\"\"Splits abstract text from datafile into list of sentences.\n",
        "  Args:\n",
        "    abstract: string containing <s> and </s> tags for starts and ends of sentences\n",
        "  Returns:\n",
        "    sents: List of sentence strings (no tags)\"\"\"\n",
        "  abstract = abstract.decode(encoding=\"utf-8\", errors=\"strict\")\n",
        "  cur = 0\n",
        "  sents = []\n",
        "  while True:\n",
        "    try:\n",
        "      # print(\"SENCENCE TYPE:\",type(SENTENCE_START))\n",
        "      # print(\"CUR TYPE:\", type(cur))\n",
        "      # print(\"ABSTRACT\", type(abstract))\n",
        "      start_p = abstract.index(SENTENCE_START,cur)\n",
        "      end_p = abstract.index(SENTENCE_END, start_p + 1)\n",
        "      cur = end_p + len(SENTENCE_END)\n",
        "      sents.append(abstract[start_p+len(SENTENCE_START):end_p])\n",
        "    except ValueError as e: # no more sentences\n",
        "      return sents\n",
        "\n",
        "\n",
        "def show_art_oovs(article, vocab):\n",
        "  \"\"\"Returns the article string, highlighting the OOVs by placing __underscores__ around them\"\"\"\n",
        "  unk_token = vocab.word2id(UNKNOWN_TOKEN)\n",
        "  words = article.split(' ')\n",
        "  words = [(\"__%s__\" % w) if vocab.word2id(w)==unk_token else w for w in words]\n",
        "  out_str = ' '.join(words)\n",
        "  return out_str\n",
        "\n",
        "\n",
        "def show_abs_oovs(abstract, vocab, article_oovs):\n",
        "  \"\"\"Returns the abstract string, highlighting the article OOVs with __underscores__.\n",
        "  If a list of article_oovs is provided, non-article OOVs are differentiated like !!__this__!!.\n",
        "  Args:\n",
        "    abstract: string\n",
        "    vocab: Vocabulary object\n",
        "    article_oovs: list of words (strings), or None (in baseline mode)\n",
        "  \"\"\"\n",
        "  unk_token = vocab.word2id(UNKNOWN_TOKEN)\n",
        "  words = abstract.split(' ')\n",
        "  new_words = []\n",
        "  for w in words:\n",
        "    if vocab.word2id(w) == unk_token: # w is oov\n",
        "      if article_oovs is None: # baseline mode\n",
        "        new_words.append(\"__%s__\" % w)\n",
        "      else: # pointer-generator mode\n",
        "        if w in article_oovs:\n",
        "          new_words.append(\"__%s__\" % w)\n",
        "        else:\n",
        "          new_words.append(\"!!__%s__!!\" % w)\n",
        "    else: # w is in-vocab word\n",
        "      new_words.append(w)\n",
        "  out_str = ' '.join(new_words)\n",
        "  return out_str"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeWwMVL0Ic2r"
      },
      "source": [
        "### Batcher"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V493B7xoIeBs"
      },
      "source": [
        "https://github.com/yaserkl/RLSeq2Seq/blob/master/src/batcher.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH-PxZaBIfQL"
      },
      "source": [
        "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
        "# Modifications Copyright 2017 Abigail See\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "\"\"\"This file contains code to process data into batches\"\"\"\n",
        "try:\n",
        "  import queue\n",
        "except:\n",
        "  import Queue as queue\n",
        "from random import shuffle\n",
        "from random import seed\n",
        "seed(123)\n",
        "from threading import Thread\n",
        "import time\n",
        "import numpy as np\n",
        "# import tensorflow as tf\n",
        "#import data\n",
        "\n",
        "FLAGS = tf.compat.v1.flags\n",
        "\n",
        "class Example(object):\n",
        "  \"\"\"Class representing a train/val/test example for text summarization.\"\"\"\n",
        "\n",
        "  def __init__(self, article, abstract_sentences, vocab, hps):\n",
        "    \"\"\"Initializes the Example, performing tokenization and truncation to produce the encoder, decoder and target sequences, which are stored in self.\n",
        "    Args:\n",
        "      article: source text; a string. each token is separated by a single space.\n",
        "      abstract_sentences: list of strings, one per abstract sentence. In each sentence, each token is separated by a single space.\n",
        "      vocab: Vocabulary object\n",
        "      hps: hyperparameters\n",
        "    \"\"\"\n",
        "    self.hps = hps\n",
        "\n",
        "    # Get ids of special tokens\n",
        "    start_decoding = vocab.word2id(START_DECODING)\n",
        "    stop_decoding = vocab.word2id(STOP_DECODING)\n",
        "\n",
        "    # Process the article\n",
        "    article_words = article.split()\n",
        "    if len(article_words) > hps.max_enc_steps:\n",
        "      article_words = article_words[:hps.max_enc_steps]\n",
        "    self.enc_len = len(article_words) # store the length after truncation but before padding\n",
        "    self.enc_input = [vocab.word2id(w) for w in article_words] # list of word ids; OOVs are represented by the id for UNK token\n",
        "\n",
        "    # Process the abstract\n",
        "    abstract = abstract_sentences #' '.join(abstract_sentences) # string\n",
        "    abstract_words = abstract.split() # list of strings\n",
        "    abs_ids = [vocab.word2id(w) for w in abstract_words] # list of word ids; OOVs are represented by the id for UNK token\n",
        "\n",
        "    # Get the decoder input sequence and target sequence\n",
        "    self.dec_input, self.target = self.get_dec_inp_targ_seqs(abs_ids, hps.max_dec_steps, start_decoding, stop_decoding)\n",
        "    self.dec_len = len(self.dec_input)\n",
        "\n",
        "    # If using pointer-generator mode, we need to store some extra info\n",
        "    if hps.pointer_gen:\n",
        "      # Store a version of the enc_input where in-article OOVs are represented by their temporary OOV id; also store the in-article OOVs words themselves\n",
        "      self.enc_input_extend_vocab, self.article_oovs = article2ids(article_words, vocab)\n",
        "\n",
        "      # Get a verison of the reference summary where in-article OOVs are represented by their temporary article OOV id\n",
        "      abs_ids_extend_vocab = abstract2ids(abstract_words, vocab, self.article_oovs)\n",
        "\n",
        "      # Overwrite decoder target sequence so it uses the temp article OOV ids\n",
        "      _, self.target = self.get_dec_inp_targ_seqs(abs_ids_extend_vocab, hps.max_dec_steps, start_decoding, stop_decoding)\n",
        "\n",
        "    # Store the original strings\n",
        "    self.original_article = article\n",
        "    self.original_abstract = abstract\n",
        "    self.original_abstract_sents = abstract_sentences\n",
        "\n",
        "\n",
        "  def get_dec_inp_targ_seqs(self, sequence, max_len, start_id, stop_id):\n",
        "    \"\"\"Given the reference summary as a sequence of tokens, return the input sequence for the decoder, and the target sequence which we will use to calculate loss. The sequence will be truncated if it is longer than max_len. The input sequence must start with the start_id and the target sequence must end with the stop_id (but not if it's been truncated).\n",
        "    Args:\n",
        "      sequence: List of ids (integers)\n",
        "      max_len: integer\n",
        "      start_id: integer\n",
        "      stop_id: integer\n",
        "    Returns:\n",
        "      inp: sequence length <=max_len starting with start_id\n",
        "      target: sequence same length as input, ending with stop_id only if there was no truncation\n",
        "    \"\"\"\n",
        "    inp = [start_id] + sequence[:]\n",
        "    target = sequence[:]\n",
        "    if len(inp) > max_len: # truncate\n",
        "      inp = inp[:max_len]\n",
        "      target = target[:max_len] # no end_token\n",
        "    else: # no truncation\n",
        "      target.append(stop_id) # end token\n",
        "    assert len(inp) == len(target)\n",
        "    return inp, target\n",
        "\n",
        "\n",
        "  def pad_decoder_inp_targ(self, max_len, pad_id):\n",
        "    \"\"\"Pad decoder input and target sequences with pad_id up to max_len.\"\"\"\n",
        "    while len(self.dec_input) < max_len:\n",
        "      self.dec_input.append(pad_id)\n",
        "    while len(self.target) < max_len:\n",
        "      self.target.append(pad_id)\n",
        "\n",
        "\n",
        "  def pad_encoder_input(self, max_len, pad_id):\n",
        "    \"\"\"Pad the encoder input sequence with pad_id up to max_len.\"\"\"\n",
        "    while len(self.enc_input) < max_len:\n",
        "      self.enc_input.append(pad_id)\n",
        "    if self.hps.pointer_gen:\n",
        "      while len(self.enc_input_extend_vocab) < max_len:\n",
        "        self.enc_input_extend_vocab.append(pad_id)\n",
        "\n",
        "\n",
        "class Batch(object):\n",
        "  \"\"\"Class representing a minibatch of train/val/test examples for text summarization.\"\"\"\n",
        "\n",
        "  def __init__(self, example_list, hps, vocab):\n",
        "    \"\"\"Turns the example_list into a Batch object.\n",
        "    Args:\n",
        "       example_list: List of Example objects\n",
        "       hps: hyperparameters\n",
        "       vocab: Vocabulary object\n",
        "    \"\"\"\n",
        "    self.pad_id = vocab.word2id(PAD_TOKEN) # id of the PAD token used to pad sequences\n",
        "    self.init_encoder_seq(example_list, hps) # initialize the input to the encoder\n",
        "    self.init_decoder_seq(example_list, hps) # initialize the input and targets for the decoder\n",
        "    self.store_orig_strings(example_list) # store the original strings\n",
        "\n",
        "  def init_encoder_seq(self, example_list, hps):\n",
        "    \"\"\"Initializes the following:\n",
        "        self.enc_batch:\n",
        "          numpy array of shape (batch_size, <=max_enc_steps) containing integer ids (all OOVs represented by UNK id), padded to length of longest sequence in the batch\n",
        "        self.enc_lens:\n",
        "          numpy array of shape (batch_size) containing integers. The (truncated) length of each encoder input sequence (pre-padding).\n",
        "        self.enc_padding_mask:\n",
        "          numpy array of shape (batch_size, <=max_enc_steps), containing 1s and 0s. 1s correspond to real tokens in enc_batch and target_batch; 0s correspond to padding.\n",
        "      If hps.pointer_gen, additionally initializes the following:\n",
        "        self.max_art_oovs:\n",
        "          maximum number of in-article OOVs in the batch\n",
        "        self.art_oovs:\n",
        "          list of list of in-article OOVs (strings), for each example in the batch\n",
        "        self.enc_batch_extend_vocab:\n",
        "          Same as self.enc_batch, but in-article OOVs are represented by their temporary article OOV number.\n",
        "    \"\"\"\n",
        "    # Determine the maximum length of the encoder input sequence in this batch\n",
        "    max_enc_seq_len = max([ex.enc_len for ex in example_list])\n",
        "\n",
        "    # Pad the encoder input sequences up to the length of the longest sequence\n",
        "    for ex in example_list:\n",
        "      ex.pad_encoder_input(max_enc_seq_len, self.pad_id)\n",
        "\n",
        "    # Initialize the numpy arrays\n",
        "    # Note: our enc_batch can have different length (second dimension) for each batch because we use dynamic_rnn for the encoder.\n",
        "    self.enc_batch = np.zeros((hps.batch_size, max_enc_seq_len), dtype=np.int32)\n",
        "    self.enc_lens = np.zeros((hps.batch_size), dtype=np.int32)\n",
        "    self.enc_padding_mask = np.zeros((hps.batch_size, max_enc_seq_len), dtype=np.float32)\n",
        "\n",
        "    # Fill in the numpy arrays\n",
        "    for i, ex in enumerate(example_list):\n",
        "      self.enc_batch[i, :] = ex.enc_input[:]\n",
        "      self.enc_lens[i] = ex.enc_len\n",
        "      for j in range(ex.enc_len):\n",
        "        self.enc_padding_mask[i][j] = 1\n",
        "\n",
        "    # For pointer-generator mode, need to store some extra info\n",
        "    if hps.pointer_gen:\n",
        "      # Determine the max number of in-article OOVs in this batch\n",
        "      self.max_art_oovs = max([len(ex.article_oovs) for ex in example_list])\n",
        "      # Store the in-article OOVs themselves\n",
        "      self.art_oovs = [ex.article_oovs for ex in example_list]\n",
        "      # Store the version of the enc_batch that uses the article OOV ids\n",
        "      self.enc_batch_extend_vocab = np.zeros((hps.batch_size, max_enc_seq_len), dtype=np.int32)\n",
        "      for i, ex in enumerate(example_list):\n",
        "        self.enc_batch_extend_vocab[i, :] = ex.enc_input_extend_vocab[:]\n",
        "\n",
        "  def init_decoder_seq(self, example_list, hps):\n",
        "    \"\"\"Initializes the following:\n",
        "        self.dec_batch:\n",
        "          numpy array of shape (batch_size, max_dec_steps), containing integer ids as input for the decoder, padded to max_dec_steps length.\n",
        "        self.target_batch:\n",
        "          numpy array of shape (batch_size, max_dec_steps), containing integer ids for the target sequence, padded to max_dec_steps length.\n",
        "        self.dec_padding_mask:\n",
        "          numpy array of shape (batch_size, max_dec_steps), containing 1s and 0s. 1s correspond to real tokens in dec_batch and target_batch; 0s correspond to padding.\n",
        "        \"\"\"\n",
        "    # Pad the inputs and targets\n",
        "    for ex in example_list:\n",
        "      ex.pad_decoder_inp_targ(hps.max_dec_steps, self.pad_id)\n",
        "\n",
        "    # Initialize the numpy arrays.\n",
        "    # Note: our decoder inputs and targets must be the same length for each batch (second dimension = max_dec_steps) because we do not use a dynamic_rnn for decoding. However I believe this is possible, or will soon be possible, with Tensorflow 1.0, in which case it may be best to upgrade to that.\n",
        "    self.dec_batch = np.zeros((hps.batch_size, hps.max_dec_steps), dtype=np.int32)\n",
        "    self.target_batch = np.zeros((hps.batch_size, hps.max_dec_steps), dtype=np.int32)\n",
        "    self.dec_padding_mask = np.zeros((hps.batch_size, hps.max_dec_steps), dtype=np.float32)\n",
        "\n",
        "    # Fill in the numpy arrays\n",
        "    for i, ex in enumerate(example_list):\n",
        "      self.dec_batch[i, :] = ex.dec_input[:]\n",
        "      self.target_batch[i, :] = ex.target[:]\n",
        "      for j in range(ex.dec_len):\n",
        "        self.dec_padding_mask[i][j] = 1\n",
        "\n",
        "  def store_orig_strings(self, example_list):\n",
        "    \"\"\"Store the original article and abstract strings in the Batch object\"\"\"\n",
        "    self.original_articles = [ex.original_article for ex in example_list] # list of lists\n",
        "    self.original_abstracts = [ex.original_abstract for ex in example_list] # list of lists\n",
        "    self.original_abstracts_sents = [ex.original_abstract_sents for ex in example_list] # list of list of lists\n",
        "\n",
        "\n",
        "class Batcher(object):\n",
        "  \"\"\"A class to generate minibatches of data. Buckets examples together based on length of the encoder sequence.\"\"\"\n",
        "\n",
        "  BATCH_QUEUE_MAX = 100 # max number of batches the batch_queue can hold\n",
        "\n",
        "  def __init__(self, data_path,csv, vocab, hps, single_pass, decode_after):\n",
        "    \"\"\"Initialize the batcher. Start threads that process the data into batches.\n",
        "    Args:\n",
        "      data_path: tf.Example filepattern.\n",
        "      vocab: Vocabulary object\n",
        "      hps: hyperparameters\n",
        "      single_pass: If True, run through the dataset exactly once (useful for when you want to run evaluation on the dev or test set). Otherwise generate random batches indefinitely (useful for training).\n",
        "    \"\"\"\n",
        "    self._data_path = data_path\n",
        "    self._csv = csv\n",
        "    self._vocab = vocab\n",
        "    self._hps = hps\n",
        "    self._single_pass = single_pass\n",
        "    self._decode_after = decode_after\n",
        "\n",
        "    # Initialize a queue of Batches waiting to be used, and a queue of Examples waiting to be batched\n",
        "    self._batch_queue = queue.Queue(self.BATCH_QUEUE_MAX)\n",
        "    self._example_queue = queue.Queue(self.BATCH_QUEUE_MAX * self._hps.batch_size)\n",
        "\n",
        "    # Different settings depending on whether we're in single_pass mode or not\n",
        "    if single_pass:\n",
        "      self._num_example_q_threads = 1 # just one thread, so we read through the dataset just once\n",
        "      self._num_batch_q_threads = 1  # just one thread to batch examples\n",
        "      self._bucketing_cache_size = 1 # only load one batch's worth of examples before bucketing; this essentially means no bucketing\n",
        "      self._finished_reading = False # this will tell us when we're finished reading the dataset\n",
        "    else:\n",
        "      self._num_example_q_threads = FLAGS.example_queue_threads # num threads to fill example queue\n",
        "      self._num_batch_q_threads = FLAGS.batch_queue_threads  # num threads to fill batch queue\n",
        "      self._bucketing_cache_size = FLAGS.bucketing_cache_size # how many batches-worth of examples to load into cache before bucketing\n",
        "\n",
        "    # Start the threads that load the queues\n",
        "    self._example_q_threads = []\n",
        "    for _ in range(self._num_example_q_threads):\n",
        "      self._example_q_threads.append(Thread(target=self.fill_example_queue))\n",
        "      self._example_q_threads[-1].daemon = True\n",
        "      self._example_q_threads[-1].start()\n",
        "    self._batch_q_threads = []\n",
        "    for _ in range(self._num_batch_q_threads):\n",
        "      self._batch_q_threads.append(Thread(target=self.fill_batch_queue))\n",
        "      self._batch_q_threads[-1].daemon = True\n",
        "      self._batch_q_threads[-1].start()\n",
        "\n",
        "    # Start a thread that watches the other threads and restarts them if they're dead\n",
        "    if not single_pass: # We don't want a watcher in single_pass mode because the threads shouldn't run forever\n",
        "      self._watch_thread = Thread(target=self.watch_threads)\n",
        "      self._watch_thread.daemon = True\n",
        "      self._watch_thread.start()\n",
        "\n",
        "  def next_batch(self):\n",
        "    \"\"\"Return a Batch from the batch queue.\n",
        "    If mode='decode' then each batch contains a single example repeated beam_size-many times; this is necessary for beam search.\n",
        "    Returns:\n",
        "      batch: a Batch object, or None if we're in single_pass mode and we've exhausted the dataset.\n",
        "    \"\"\"\n",
        "    # If the batch queue is empty, print a warning\n",
        "    if self._batch_queue.qsize() == 0:\n",
        "      tf.compat.v1.logging.warning('Bucket input queue is empty when calling next_batch. Bucket queue size: %i, Input queue size: %i', self._batch_queue.qsize(), self._example_queue.qsize())\n",
        "      if self._single_pass and self._finished_reading:\n",
        "        tf.compat.v1.logging.info(\"Finished reading dataset in single_pass mode.\")\n",
        "        return None\n",
        "\n",
        "    batch = self._batch_queue.get() # get the next Batch\n",
        "    return batch\n",
        "\n",
        "  def fill_example_queue(self):\n",
        "    \"\"\"Reads data from file and processes into Examples which are then placed into the example queue.\"\"\"\n",
        "\n",
        "    #input_gen = self.text_generator(example_generator(self._data_path, self._single_pass))\n",
        "    input_gen = self._csv\n",
        "    for index, row  in input_gen.iterrows():\n",
        "      #try:\n",
        "      #  (article, abstract) = input_gen.next() # read the next example from file. article and abstract are both strings.\n",
        "      #except StopIteration: # if there are no more examples:\n",
        "      #  tf.compat.v1.logging.info(\"The example generator for this example queue filling thread has exhausted data.\")\n",
        "      #  if self._single_pass:\n",
        "      #    tf.compat.v1.logging.info(\"single_pass mode is on, so we've finished reading dataset. This thread is stopping.\")\n",
        "      #    self._finished_reading = True\n",
        "      #    break\n",
        "      #  else:\n",
        "      #    raise Exception(\"single_pass mode is off but the example generator is out of data; error.\")\n",
        "\n",
        "      #abstract_sentences = [sent.strip() for sent in abstract2sents(abstract)] # Use the <s> and </s> tags in abstract to get a list of sentences.\n",
        "      if (row['article'] != \"\" and  row['headline'] != \"\"):\n",
        "        article = row['article'] \n",
        "        abstract_sentences = row['headline'] \n",
        "        example = Example(article, abstract_sentences, self._vocab, self._hps) # Process into an Example.\n",
        "        self._example_queue.put(example) # place the Example in the example queue.\n",
        "\n",
        "  def fill_batch_queue(self):\n",
        "    \"\"\"Takes Examples out of example queue, sorts them by encoder sequence length, processes into Batches and places them in the batch queue.\n",
        "    In decode mode, makes batches that each contain a single example repeated.\n",
        "    \"\"\"\n",
        "    while True:\n",
        "      if self._hps.mode != 'decode':\n",
        "        # Get bucketing_cache_size-many batches of Examples into a list, then sort\n",
        "        inputs = []\n",
        "        for _ in range(self._hps.batch_size * self._bucketing_cache_size):\n",
        "          inputs.append(self._example_queue.get())\n",
        "        inputs = sorted(inputs, key=lambda inp: inp.enc_len) # sort by length of encoder sequence\n",
        "\n",
        "        # Group the sorted Examples into batches, optionally shuffle the batches, and place in the batch queue.\n",
        "        batches = []\n",
        "        for i in range(0, len(inputs), self._hps.batch_size):\n",
        "          batches.append(inputs[i:i + self._hps.batch_size])\n",
        "        if not self._single_pass:\n",
        "          shuffle(batches)\n",
        "        for b in batches:  # each b is a list of Example objects\n",
        "          self._batch_queue.put(Batch(b, self._hps, self._vocab))\n",
        "\n",
        "      else: # beam search decode mode\n",
        "        ex = self._example_queue.get()\n",
        "        b = [ex for _ in range(self._hps.batch_size)]\n",
        "        self._batch_queue.put(Batch(b, self._hps, self._vocab))\n",
        "\n",
        "  def watch_threads(self):\n",
        "    \"\"\"Watch example queue and batch queue threads and restart if dead.\"\"\"\n",
        "    while True:\n",
        "      time.sleep(60)\n",
        "      for idx,t in enumerate(self._example_q_threads):\n",
        "        if not t.is_alive(): # if the thread is dead\n",
        "          tf.compat.v1.logging.error('Found example queue thread dead. Restarting.')\n",
        "          new_t = Thread(target=self.fill_example_queue)\n",
        "          self._example_q_threads[idx] = new_t\n",
        "          new_t.daemon = True\n",
        "          new_t.start()\n",
        "      for idx,t in enumerate(self._batch_q_threads):\n",
        "        if not t.is_alive(): # if the thread is dead\n",
        "          tf.compat.v1.logging.error('Found batch queue thread dead. Restarting.')\n",
        "          new_t = Thread(target=self.fill_batch_queue)\n",
        "          self._batch_q_threads[idx] = new_t\n",
        "          new_t.daemon = True\n",
        "          new_t.start()\n",
        "\n",
        "  def text_generator(self, example_generator):\n",
        "    \"\"\"Generates article and abstract text from tf.Example.\n",
        "    Args:\n",
        "      example_generator: a generator of tf.Examples from file. See data.example_generator\"\"\"\n",
        "    cnt = 0\n",
        "    while True:\n",
        "      e = next(example_generator) ##example_generator.next() # e is a tf.Example\n",
        "      try:\n",
        "        article_text = e.features.feature['article'].bytes_list.value[0] # the article text was saved under the key 'article' in the data files\n",
        "        abstract_text = e.features.feature['abstract'].bytes_list.value[0] # the abstract text was saved under the key 'abstract' in the data files\n",
        "      except ValueError:\n",
        "        tf.compat.v1.logging.error('Failed to get article or abstract from example')\n",
        "        continue\n",
        "      if len(article_text)==0: # See https://github.com/abisee/pointer-generator/issues/1\n",
        "        tf.compat.v1.logging.warning('Found an example with empty article text. Skipping it.')\n",
        "      else:\n",
        "        if self._single_pass and cnt < self._decode_after: #skip already decoded docs\n",
        "          cnt +=1\n",
        "          continue\n",
        "        yield (article_text, abstract_text)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oapGiq-KLiFL"
      },
      "source": [
        "### Rouge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d86tpuvTLjTD"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# Copyright 2017 Google Inc.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#      http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\"\"\"ROUGe metric implementation.\n",
        "This is a modified and slightly extended verison of\n",
        "https://github.com/miso-belica/sumy/blob/dev/sumy/evaluation/rouge.py.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals\n",
        "\n",
        "import itertools\n",
        "import numpy as np\n",
        "\n",
        "#pylint: disable=C0103\n",
        "\n",
        "\n",
        "def _get_ngrams(n, text):\n",
        "  \"\"\"Calcualtes n-grams.\n",
        "  Args:\n",
        "    n: which n-grams to calculate\n",
        "    text: An array of tokens\n",
        "  Returns:\n",
        "    A set of n-grams\n",
        "  \"\"\"\n",
        "  ngram_set = set()\n",
        "  text_length = len(text)\n",
        "  max_index_ngram_start = text_length - n\n",
        "  for i in range(max_index_ngram_start + 1):\n",
        "    ngram_set.add(tuple(text[i:i + n]))\n",
        "  return ngram_set\n",
        "\n",
        "def _split_into_words(sentences):\n",
        "  \"\"\"Splits multiple sentences into words and flattens the result\"\"\"\n",
        "  return list(itertools.chain(*[_.split(\" \") for _ in sentences]))\n",
        "\n",
        "def _get_word_ngrams(n, sentences):\n",
        "  \"\"\"Calculates word n-grams for multiple sentences.\n",
        "  \"\"\"\n",
        "  assert len(sentences) > 0\n",
        "  assert n > 0\n",
        "\n",
        "  words = _split_into_words(sentences)\n",
        "  return _get_ngrams(n, words)\n",
        "\n",
        "def _len_lcs(x, y):\n",
        "  \"\"\"\n",
        "  Returns the length of the Longest Common Subsequence between sequences x\n",
        "  and y.\n",
        "  Source: http://www.algorithmist.com/index.php/Longest_Common_Subsequence\n",
        "  Args:\n",
        "    x: sequence of words\n",
        "    y: sequence of words\n",
        "  Returns\n",
        "    integer: Length of LCS between x and y\n",
        "  \"\"\"\n",
        "  table = _lcs(x, y)\n",
        "  n, m = len(x), len(y)\n",
        "  return table[n, m]\n",
        "\n",
        "def _lcs(x, y):\n",
        "  \"\"\"\n",
        "  Computes the length of the longest common subsequence (lcs) between two\n",
        "  strings. The implementation below uses a DP programming algorithm and runs\n",
        "  in O(nm) time where n = len(x) and m = len(y).\n",
        "  Source: http://www.algorithmist.com/index.php/Longest_Common_Subsequence\n",
        "  Args:\n",
        "    x: collection of words\n",
        "    y: collection of words\n",
        "  Returns:\n",
        "    Table of dictionary of coord and len lcs\n",
        "  \"\"\"\n",
        "  n, m = len(x), len(y)\n",
        "  table = dict()\n",
        "  for i in range(n + 1):\n",
        "    for j in range(m + 1):\n",
        "      if i == 0 or j == 0:\n",
        "        table[i, j] = 0\n",
        "      elif x[i - 1] == y[j - 1]:\n",
        "        table[i, j] = table[i - 1, j - 1] + 1\n",
        "      else:\n",
        "        table[i, j] = max(table[i - 1, j], table[i, j - 1])\n",
        "  return table\n",
        "\n",
        "def _recon_lcs(x, y):\n",
        "  \"\"\"\n",
        "  Returns the Longest Subsequence between x and y.\n",
        "  Source: http://www.algorithmist.com/index.php/Longest_Common_Subsequence\n",
        "  Args:\n",
        "    x: sequence of words\n",
        "    y: sequence of words\n",
        "  Returns:\n",
        "    sequence: LCS of x and y\n",
        "  \"\"\"\n",
        "  i, j = len(x), len(y)\n",
        "  table = _lcs(x, y)\n",
        "\n",
        "  def _recon(i, j):\n",
        "    \"\"\"private recon calculation\"\"\"\n",
        "    if i == 0 or j == 0:\n",
        "      return []\n",
        "    elif x[i - 1] == y[j - 1]:\n",
        "      return _recon(i - 1, j - 1) + [(x[i - 1], i)]\n",
        "    elif table[i - 1, j] > table[i, j - 1]:\n",
        "      return _recon(i - 1, j)\n",
        "    else:\n",
        "      return _recon(i, j - 1)\n",
        "\n",
        "  recon_tuple = tuple(map(lambda x: x[0], _recon(i, j)))\n",
        "  return recon_tuple\n",
        "\n",
        "def rouge_n(evaluated_sentences, reference_sentences, n=2):\n",
        "  \"\"\"\n",
        "  Computes ROUGE-N of two text collections of sentences.\n",
        "  Sourece: http://research.microsoft.com/en-us/um/people/cyl/download/\n",
        "  papers/rouge-working-note-v1.3.1.pdf\n",
        "  Args:\n",
        "    evaluated_sentences: The sentences that have been picked by the summarizer\n",
        "    reference_sentences: The sentences from the referene set\n",
        "    n: Size of ngram.  Defaults to 2.\n",
        "  Returns:\n",
        "    A tuple (f1, precision, recall) for ROUGE-N\n",
        "  Raises:\n",
        "    ValueError: raises exception if a param has len <= 0\n",
        "  \"\"\"\n",
        "  if len(evaluated_sentences) <= 0 or len(reference_sentences) <= 0:\n",
        "    raise ValueError(\"Collections must contain at least 1 sentence.\")\n",
        "\n",
        "  evaluated_ngrams = _get_word_ngrams(n, evaluated_sentences)\n",
        "  reference_ngrams = _get_word_ngrams(n, reference_sentences)\n",
        "  reference_count = len(reference_ngrams)\n",
        "  evaluated_count = len(evaluated_ngrams)\n",
        "\n",
        "  # Gets the overlapping ngrams between evaluated and reference\n",
        "  overlapping_ngrams = evaluated_ngrams.intersection(reference_ngrams)\n",
        "  overlapping_count = len(overlapping_ngrams)\n",
        "\n",
        "  # Handle edge case. This isn't mathematically correct, but it's good enough\n",
        "  if evaluated_count == 0:\n",
        "    precision = 0.0\n",
        "  else:\n",
        "    precision = overlapping_count / evaluated_count\n",
        "\n",
        "  if reference_count == 0:\n",
        "    recall = 0.0\n",
        "  else:\n",
        "    recall = overlapping_count / reference_count\n",
        "\n",
        "  f1_score = 2.0 * ((precision * recall) / (precision + recall + 1e-8))\n",
        "\n",
        "  # return overlapping_count / reference_count\n",
        "  return f1_score, precision, recall\n",
        "\n",
        "def _f_p_r_lcs(llcs, m, n):\n",
        "  \"\"\"\n",
        "  Computes the LCS-based F-measure score\n",
        "  Source: http://research.microsoft.com/en-us/um/people/cyl/download/papers/\n",
        "  rouge-working-note-v1.3.1.pdf\n",
        "  Args:\n",
        "    llcs: Length of LCS\n",
        "    m: number of words in reference summary\n",
        "    n: number of words in candidate summary\n",
        "  Returns:\n",
        "    Float. LCS-based F-measure score\n",
        "  \"\"\"\n",
        "  r_lcs = llcs / m\n",
        "  p_lcs = llcs / n\n",
        "  beta = p_lcs / (r_lcs + 1e-12)\n",
        "  num = (1 + (beta**2)) * r_lcs * p_lcs\n",
        "  denom = r_lcs + ((beta**2) * p_lcs)\n",
        "  f_lcs = num / (denom + 1e-12)\n",
        "  return f_lcs, p_lcs, r_lcs\n",
        "\n",
        "\n",
        "def rouge_l_sentence_level(evaluated_sentences, reference_sentences):\n",
        "  \"\"\"\n",
        "  Computes ROUGE-L (sentence level) of two text collections of sentences.\n",
        "  http://research.microsoft.com/en-us/um/people/cyl/download/papers/\n",
        "  rouge-working-note-v1.3.1.pdf\n",
        "  Calculated according to:\n",
        "  R_lcs = LCS(X,Y)/m\n",
        "  P_lcs = LCS(X,Y)/n\n",
        "  F_lcs = ((1 + beta^2)*R_lcs*P_lcs) / (R_lcs + (beta^2) * P_lcs)\n",
        "  where:\n",
        "  X = reference summary\n",
        "  Y = Candidate summary\n",
        "  m = length of reference summary\n",
        "  n = length of candidate summary\n",
        "  Args:\n",
        "    evaluated_sentences: The sentences that have been picked by the summarizer\n",
        "    reference_sentences: The sentences from the referene set\n",
        "  Returns:\n",
        "    A float: F_lcs\n",
        "  Raises:\n",
        "    ValueError: raises exception if a param has len <= 0\n",
        "  \"\"\"\n",
        "  if len(evaluated_sentences) <= 0 or len(reference_sentences) <= 0:\n",
        "    raise ValueError(\"Collections must contain at least 1 sentence.\")\n",
        "  reference_words = _split_into_words(reference_sentences)\n",
        "  evaluated_words = _split_into_words(evaluated_sentences)\n",
        "  m = len(reference_words)\n",
        "  n = len(evaluated_words)\n",
        "  lcs = _len_lcs(evaluated_words, reference_words)\n",
        "  return _f_p_r_lcs(lcs, m, n)\n",
        "\n",
        "\n",
        "def _union_lcs(evaluated_sentences, reference_sentence):\n",
        "  \"\"\"\n",
        "  Returns LCS_u(r_i, C) which is the LCS score of the union longest common\n",
        "  subsequence between reference sentence ri and candidate summary C. For example\n",
        "  if r_i= w1 w2 w3 w4 w5, and C contains two sentences: c1 = w1 w2 w6 w7 w8 and\n",
        "  c2 = w1 w3 w8 w9 w5, then the longest common subsequence of r_i and c1 is\n",
        "  “w1 w2” and the longest common subsequence of r_i and c2 is “w1 w3 w5”. The\n",
        "  union longest common subsequence of r_i, c1, and c2 is “w1 w2 w3 w5” and\n",
        "  LCS_u(r_i, C) = 4/5.\n",
        "  Args:\n",
        "    evaluated_sentences: The sentences that have been picked by the summarizer\n",
        "    reference_sentence: One of the sentences in the reference summaries\n",
        "  Returns:\n",
        "    float: LCS_u(r_i, C)\n",
        "  ValueError:\n",
        "    Raises exception if a param has len <= 0\n",
        "  \"\"\"\n",
        "  if len(evaluated_sentences) <= 0:\n",
        "    raise ValueError(\"Collections must contain at least 1 sentence.\")\n",
        "\n",
        "  lcs_union = set()\n",
        "  reference_words = _split_into_words([reference_sentence])\n",
        "  combined_lcs_length = 0\n",
        "  for eval_s in evaluated_sentences:\n",
        "    evaluated_words = _split_into_words([eval_s])\n",
        "    lcs = set(_recon_lcs(reference_words, evaluated_words))\n",
        "    combined_lcs_length += len(lcs)\n",
        "    lcs_union = lcs_union.union(lcs)\n",
        "\n",
        "  union_lcs_count = len(lcs_union)\n",
        "  union_lcs_value = union_lcs_count / combined_lcs_length\n",
        "  return union_lcs_value\n",
        "\n",
        "\n",
        "def rouge_l_summary_level(evaluated_sentences, reference_sentences):\n",
        "  \"\"\"\n",
        "  Computes ROUGE-L (summary level) of two text collections of sentences.\n",
        "  http://research.microsoft.com/en-us/um/people/cyl/download/papers/\n",
        "  rouge-working-note-v1.3.1.pdf\n",
        "  Calculated according to:\n",
        "  R_lcs = SUM(1, u)[LCS<union>(r_i,C)]/m\n",
        "  P_lcs = SUM(1, u)[LCS<union>(r_i,C)]/n\n",
        "  F_lcs = ((1 + beta^2)*R_lcs*P_lcs) / (R_lcs + (beta^2) * P_lcs)\n",
        "  where:\n",
        "  SUM(i,u) = SUM from i through u\n",
        "  u = number of sentences in reference summary\n",
        "  C = Candidate summary made up of v sentences\n",
        "  m = number of words in reference summary\n",
        "  n = number of words in candidate summary\n",
        "  Args:\n",
        "    evaluated_sentences: The sentences that have been picked by the summarizer\n",
        "    reference_sentence: One of the sentences in the reference summaries\n",
        "  Returns:\n",
        "    A float: F_lcs\n",
        "  Raises:\n",
        "    ValueError: raises exception if a param has len <= 0\n",
        "  \"\"\"\n",
        "  if len(evaluated_sentences) <= 0 or len(reference_sentences) <= 0:\n",
        "    raise ValueError(\"Collections must contain at least 1 sentence.\")\n",
        "\n",
        "  # total number of words in reference sentences\n",
        "  m = len(_split_into_words(reference_sentences))\n",
        "\n",
        "  # total number of words in evaluated sentences\n",
        "  n = len(_split_into_words(evaluated_sentences))\n",
        "\n",
        "  union_lcs_sum_across_all_references = 0\n",
        "  for ref_s in reference_sentences:\n",
        "    union_lcs_sum_across_all_references += _union_lcs(evaluated_sentences,\n",
        "                                                      ref_s)\n",
        "  return _f_p_r_lcs(union_lcs_sum_across_all_references, m, n)\n",
        "\n",
        "\n",
        "def rouge(hypotheses, references):\n",
        "  \"\"\"Calculates average rouge scores for a list of hypotheses and\n",
        "  references\"\"\"\n",
        "\n",
        "  # Filter out hyps that are of 0 length\n",
        "  # hyps_and_refs = zip(hypotheses, references)\n",
        "  # hyps_and_refs = [_ for _ in hyps_and_refs if len(_[0]) > 0]\n",
        "  # hypotheses, references = zip(*hyps_and_refs)\n",
        "\n",
        "  # Calculate ROUGE-1 F1, precision, recall scores\n",
        "  rouge_1 = [\n",
        "      rouge_n([hyp], [ref], 1) for hyp, ref in zip(hypotheses, references)\n",
        "  ]\n",
        "  rouge_1_f, rouge_1_p, rouge_1_r = map(np.mean, zip(*rouge_1))\n",
        "\n",
        "  # Calculate ROUGE-2 F1, precision, recall scores\n",
        "  rouge_2 = [\n",
        "      rouge_n([hyp], [ref], 2) for hyp, ref in zip(hypotheses, references)\n",
        "  ]\n",
        "  rouge_2_f, rouge_2_p, rouge_2_r = map(np.mean, zip(*rouge_2))\n",
        "\n",
        "  # Calculate ROUGE-L F1, precision, recall scores\n",
        "  rouge_l = [\n",
        "      rouge_l_sentence_level([hyp], [ref])\n",
        "      for hyp, ref in zip(hypotheses, references)\n",
        "  ]\n",
        "  rouge_l_f, rouge_l_p, rouge_l_r = map(np.mean, zip(*rouge_l))\n",
        "\n",
        "  return {\n",
        "      \"rouge_1/f_score\": rouge_1_f,\n",
        "      \"rouge_1/r_score\": rouge_1_r,\n",
        "      \"rouge_1/p_score\": rouge_1_p,\n",
        "      \"rouge_2/f_score\": rouge_2_f,\n",
        "      \"rouge_2/r_score\": rouge_2_r,\n",
        "      \"rouge_2/p_score\": rouge_2_p,\n",
        "      \"rouge_l/f_score\": rouge_l_f,\n",
        "      \"rouge_l/r_score\": rouge_l_r,\n",
        "      \"rouge_l/p_score\": rouge_l_p,\n",
        "  }"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpqwdCAVK5uE"
      },
      "source": [
        "### Rouge Tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtrJ_qoPK7lb"
      },
      "source": [
        "# coding=utf-8\n",
        "# Copyright 2018 The Tensor2Tensor Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# coding=utf-8\n",
        "\"\"\"ROUGE metric implementation.\n",
        "This is a modified and slightly extended version of\n",
        "https://github.com/miso-belica/sumy/blob/dev/sumy/evaluation/rouge.py.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# import tensorflow as tf\n",
        "\n",
        "\n",
        "def _len_lcs(x, y):\n",
        "  \"\"\"Returns the length of the Longest Common Subsequence between two seqs.\n",
        "  Source: http://www.algorithmist.com/index.php/Longest_Common_Subsequence\n",
        "  Args:\n",
        "    x: sequence of words\n",
        "    y: sequence of words\n",
        "  Returns\n",
        "    integer: Length of LCS between x and y\n",
        "  \"\"\"\n",
        "  table = _lcs(x, y)\n",
        "  n, m = len(x), len(y)\n",
        "  return table[n, m]\n",
        "\n",
        "\n",
        "def _lcs(x, y):\n",
        "  \"\"\"Computes the length of the LCS between two seqs.\n",
        "  The implementation below uses a DP programming algorithm and runs\n",
        "  in O(nm) time where n = len(x) and m = len(y).\n",
        "  Source: http://www.algorithmist.com/index.php/Longest_Common_Subsequence\n",
        "  Args:\n",
        "    x: collection of words\n",
        "    y: collection of words\n",
        "  Returns:\n",
        "    Table of dictionary of coord and len lcs\n",
        "  \"\"\"\n",
        "  n, m = len(x), len(y)\n",
        "  table = dict()\n",
        "  for i in range(n + 1):\n",
        "    for j in range(m + 1):\n",
        "      if i == 0 or j == 0:\n",
        "        table[i, j] = 0\n",
        "      elif x[i - 1] == y[j - 1]:\n",
        "        table[i, j] = table[i - 1, j - 1] + 1\n",
        "      else:\n",
        "        table[i, j] = max(table[i - 1, j], table[i, j - 1])\n",
        "  return table\n",
        "\n",
        "\n",
        "def _f_lcs(llcs, m, n):\n",
        "  \"\"\"Computes the LCS-based F-measure score.\n",
        "  Source: https://www.microsoft.com/en-us/research/publication/\n",
        "  rouge-a-package-for-automatic-evaluation-of-summaries/\n",
        "  Args:\n",
        "    llcs: Length of LCS\n",
        "    m: number of words in reference summary\n",
        "    n: number of words in candidate summary\n",
        "  Returns:\n",
        "    Float. LCS-based F-measure score\n",
        "  \"\"\"\n",
        "  r_lcs = llcs / m\n",
        "  p_lcs = llcs / n\n",
        "  beta = p_lcs / (r_lcs + 1e-12)\n",
        "  num = (1 + (beta**2)) * r_lcs * p_lcs\n",
        "  denom = r_lcs + ((beta**2) * p_lcs)\n",
        "  f_lcs = num / (denom + 1e-12)\n",
        "  return f_lcs\n",
        "\n",
        "\n",
        "def rouge_l_sentence_level(eval_sentences, ref_sentences):\n",
        "  \"\"\"Computes ROUGE-L (sentence level) of two collections of sentences.\n",
        "  Source: https://www.microsoft.com/en-us/research/publication/\n",
        "  rouge-a-package-for-automatic-evaluation-of-summaries/\n",
        "  Calculated according to:\n",
        "  R_lcs = LCS(X,Y)/m\n",
        "  P_lcs = LCS(X,Y)/n\n",
        "  F_lcs = ((1 + beta^2)*R_lcs*P_lcs) / (R_lcs + (beta^2) * P_lcs)\n",
        "  where:\n",
        "  X = reference summary\n",
        "  Y = Candidate summary\n",
        "  m = length of reference summary\n",
        "  n = length of candidate summary\n",
        "  Args:\n",
        "    eval_sentences: The sentences that have been picked by the summarizer\n",
        "    ref_sentences: The sentences from the reference set\n",
        "  Returns:\n",
        "    A float: F_lcs\n",
        "  \"\"\"\n",
        "\n",
        "  f1_scores = []\n",
        "  for eval_sentence, ref_sentence in zip(eval_sentences, ref_sentences):\n",
        "    m = len(ref_sentence)\n",
        "    n = len(eval_sentence)\n",
        "    lcs = _len_lcs(eval_sentence, ref_sentence)\n",
        "    f1_scores.append(_f_lcs(lcs, m, n))\n",
        "  return np.array(f1_scores).astype(np.float32)\n",
        "\n",
        "\n",
        "def rouge_l_fscore(hypothesis, references, **unused_kwargs):\n",
        "  \"\"\"ROUGE scores computation between labels and predictions.\n",
        "  This is an approximate ROUGE scoring method since we do not glue word pieces\n",
        "  or decode the ids and tokenize the output.\n",
        "  Args:\n",
        "    predictions: tensor, model predictions (batch_size, <=max_dec_steps)\n",
        "    labels: tensor, gold output. (batch_size, max_dec_steps)\n",
        "  Returns:\n",
        "    rouge_l_fscore: approx rouge-l f1 score.\n",
        "  \"\"\"\n",
        "  rouge_l_f_score = tf.py_func(rouge_l_sentence_level, (hypothesis, references), [tf.float32])\n",
        "  return rouge_l_f_score\n",
        "\n",
        "\n",
        "def _get_ngrams(n, text):\n",
        "  \"\"\"Calculates n-grams.\n",
        "  Args:\n",
        "    n: which n-grams to calculate\n",
        "    text: An array of tokens\n",
        "  Returns:\n",
        "    A set of n-grams\n",
        "  \"\"\"\n",
        "  ngram_set = set()\n",
        "  text_length = len(text)\n",
        "  max_index_ngram_start = text_length - n\n",
        "  for i in range(max_index_ngram_start + 1):\n",
        "    ngram_set.add(tuple(text[i:i + n]))\n",
        "  return ngram_set\n",
        "\n",
        "\n",
        "def rouge_n(eval_sentences, ref_sentences, n=2):\n",
        "  \"\"\"Computes ROUGE-N f1 score of two text collections of sentences.\n",
        "  Source: https://www.microsoft.com/en-us/research/publication/\n",
        "  rouge-a-package-for-automatic-evaluation-of-summaries/\n",
        "  Args:\n",
        "    eval_sentences: The sentences that have been picked by the summarizer\n",
        "    ref_sentences: The sentences from the reference set\n",
        "    n: Size of ngram.  Defaults to 2.\n",
        "  Returns:\n",
        "    f1 score for ROUGE-N\n",
        "  \"\"\"\n",
        "\n",
        "  f1_scores = []\n",
        "  for eval_sentence, ref_sentence in zip(eval_sentences, ref_sentences):\n",
        "    eval_ngrams = _get_ngrams(n, eval_sentence)\n",
        "    ref_ngrams = _get_ngrams(n, ref_sentence)\n",
        "    ref_count = len(ref_ngrams)\n",
        "    eval_count = len(eval_ngrams)\n",
        "\n",
        "    # Gets the overlapping ngrams between evaluated and reference\n",
        "    overlapping_ngrams = eval_ngrams.intersection(ref_ngrams)\n",
        "    overlapping_count = len(overlapping_ngrams)\n",
        "\n",
        "    # Handle edge case. This isn't mathematically correct, but it's good enough\n",
        "    if eval_count == 0:\n",
        "      precision = 0.0\n",
        "    else:\n",
        "      precision = overlapping_count / eval_count\n",
        "\n",
        "    if ref_count == 0:\n",
        "      recall = 0.0\n",
        "    else:\n",
        "      recall = overlapping_count / ref_count\n",
        "\n",
        "    f1_scores.append(2.0 * ((precision * recall) / (precision + recall + 1e-8)))\n",
        "\n",
        "  # return overlapping_count / reference_count\n",
        "  return np.array(f1_scores).astype(np.float32)\n",
        "\n",
        "\n",
        "def rouge_2_fscore(predictions, labels, **unused_kwargs):\n",
        "  \"\"\"ROUGE-2 F1 score computation between labels and predictions.\n",
        "  This is an approximate ROUGE scoring method since we do not glue word pieces\n",
        "  or decode the ids and tokenize the output.\n",
        "  Args:\n",
        "    predictions: tensor, model predictions (batch_size, <=max_dec_steps)\n",
        "    labels: tensor, gold output. (batch_size, max_dec_steps)\n",
        "  Returns:\n",
        "    rouge2_fscore: approx rouge-2 f1 score.\n",
        "  \"\"\"\n",
        "\n",
        "  rouge_2_f_score = tf.py_func(rouge_n, (predictions, labels), [tf.float32])\n",
        "  return rouge_2_f_score, tf.constant(1.0)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fxvwy-T5KvIz"
      },
      "source": [
        "### Attention Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbSu87w-KxiM"
      },
      "source": [
        "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
        "# Modifications Copyright 2017 Abigail See\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "\"\"\"This file defines the decoder\"\"\"\n",
        "\n",
        "# import tensorflow as tf\n",
        "from tensorflow.python.ops import variable_scope\n",
        "from tensorflow.python.ops import array_ops\n",
        "from tensorflow.python.ops import nn_ops\n",
        "from tensorflow.python.ops import gen_array_ops\n",
        "from tensorflow.python.ops import math_ops\n",
        "from tensorflow.python.ops.distributions import categorical\n",
        "from tensorflow.python.ops.distributions import bernoulli\n",
        "#from rouge_tensor import rouge_l_fscore\n",
        "\n",
        "FLAGS = tf.compat.v1.flags\n",
        "\n",
        "def print_shape(str, var):\n",
        "  tf.compat.v1.logging.info('shape of {}: {}'.format(str, [k for k in var.get_shape()]))\n",
        "\n",
        "import sys\n",
        "def add_epsilon(dist, epsilon=sys.float_info.epsilon):\n",
        "      epsilon_mask = tf.ones_like(dist) * epsilon\n",
        "      return dist + epsilon_mask\n",
        "    \n",
        "def _calc_final_dist(_hps, v_size, _max_art_oovs, _enc_batch_extend_vocab, p_gen, vocab_dist, attn_dist):\n",
        "  \"\"\"Calculate the final distribution, for the pointer-generator model\n",
        "  Args:\n",
        "    vocab_dists: The vocabulary distributions. List length max_dec_steps of (batch_size, vsize) arrays. The words are in the order they appear in the vocabulary file.\n",
        "    attn_dists: The attention distributions. List length max_dec_steps of (batch_size, max_enc_steps) arrays\n",
        "  Returns:\n",
        "    final_dists: The final distributions. List length max_dec_steps of (batch_size, extended_vsize) arrays.\n",
        "  \"\"\"\n",
        "  with tf.variable_scope('final_distribution'):\n",
        "    # Multiply vocab dists by p_gen and attention dists by (1-p_gen)\n",
        "    vocab_dist = p_gen * vocab_dist\n",
        "    attn_dist = (1-p_gen) * attn_dist\n",
        "\n",
        "    # Concatenate some zeros to each vocabulary dist, to hold the probabilities for in-article OOV words\n",
        "    extended_vsize = v_size + _max_art_oovs # the maximum (over the batch) size of the extended vocabulary\n",
        "    extra_zeros = tf.zeros((_hps.batch_size, _max_art_oovs))\n",
        "    vocab_dists_extended = tf.concat(axis=1, values=[vocab_dist, extra_zeros]) # list length max_dec_steps of shape (batch_size, extended_vsize)\n",
        "\n",
        "    # Project the values in the attention distributions onto the appropriate entries in the final distributions\n",
        "    # This means that if a_i = 0.1 and the ith encoder word is w, and w has index 500 in the vocabulary, then we add 0.1 onto the 500th entry of the final distribution\n",
        "    # This is done for each decoder timestep.\n",
        "    # This is fiddly; we use tf.scatter_nd to do the projection\n",
        "    batch_nums = tf.range(0, limit=_hps.batch_size) # shape (batch_size)\n",
        "    batch_nums = tf.expand_dims(batch_nums, 1) # shape (batch_size, 1)\n",
        "    attn_len = tf.shape(_enc_batch_extend_vocab)[1] # number of states we attend over\n",
        "    batch_nums = tf.tile(batch_nums, [1, attn_len]) # shape (batch_size, attn_len)\n",
        "    indices = tf.stack( (batch_nums, _enc_batch_extend_vocab), axis=2) # shape (batch_size, enc_t, 2)\n",
        "    shape = [_hps.batch_size, extended_vsize]\n",
        "    attn_dists_projected = tf.scatter_nd(indices, attn_dist, shape) # list length max_dec_steps (batch_size, extended_vsize)\n",
        "\n",
        "    # Add the vocab distributions and the copy distributions together to get the final distributions\n",
        "    # final_dists is a list length max_dec_steps; each entry is a tensor shape (batch_size, extended_vsize) giving the final distribution for that decoder timestep\n",
        "    # Note that for decoder timesteps and examples corresponding to a [PAD] token, this is junk - ignore.\n",
        "    final_dist = vocab_dists_extended + attn_dists_projected\n",
        "    final_dist +=1e-15 # for cases where we have zero in the final dist, especially for oov words\n",
        "    dist_sums = tf.reduce_sum(final_dist, axis=1)\n",
        "    final_dist = final_dist / tf.reshape(dist_sums, [-1, 1]) # re-normalize\n",
        "    \n",
        "    ### for NANs\n",
        "    #final_dist = add_epsilon(final_dist)\n",
        "    \n",
        "  return final_dist\n",
        "\n",
        "# Note: this function is based on tf.contrib.legacy_seq2seq_attention_decoder, which is now outdated.\n",
        "# In the future, it would make more sense to write variants on the attention mechanism using the new seq2seq library for tensorflow 1.0: https://www.tensorflow.org/api_guides/python/contrib.seq2seq#Attention\n",
        "def attention_decoder(_hps, \n",
        "  v_size, \n",
        "  _max_art_oovs, \n",
        "  _enc_batch_extend_vocab, \n",
        "  emb_dec_inputs,\n",
        "  target_batch,\n",
        "  _dec_in_state, \n",
        "  _enc_states, \n",
        "  enc_padding_mask, \n",
        "  dec_padding_mask, \n",
        "  cell, \n",
        "  embedding, \n",
        "  sampling_probability,\n",
        "  alpha,\n",
        "  unk_id,\n",
        "  initial_state_attention=False,\n",
        "  pointer_gen=True, \n",
        "  use_coverage=False, \n",
        "  prev_coverage=None, \n",
        "  prev_decoder_outputs=[], \n",
        "  prev_encoder_es = []):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    _hps: parameter of the models.\n",
        "    v_size: vocab size.\n",
        "    _max_art_oovs: size of the oov tokens in current batch.\n",
        "    _enc_batch_extend_vocab: encoder extended vocab batch.\n",
        "    emb_dec_inputs: A list of 2D Tensors [batch_size x emb_dim].\n",
        "    target_batch: The indices of the target words. shape (max_dec_steps, batch_size)\n",
        "    _dec_in_state: 2D Tensor [batch_size x cell.state_size].\n",
        "    _enc_states: 3D Tensor [batch_size x max_enc_steps x attn_size].\n",
        "    enc_padding_mask: 2D Tensor [batch_size x max_enc_steps] containing 1s and 0s; indicates which of the encoder locations are padding (0) or a real token (1).\n",
        "    dec_padding_mask: 2D Tensor [batch_size x max_dec_steps] containing 1s and 0s; indicates which of the decoder locations are padding (0) or a real token (1).\n",
        "    cell: rnn_cell.RNNCell defining the cell function and size.\n",
        "    embedding: embedding matrix [vocab_size, emb_dim].\n",
        "    sampling_probability: sampling probability for scheduled sampling.\n",
        "    alpha: soft-argmax argument.\n",
        "    initial_state_attention:\n",
        "      Note that this attention decoder passes each decoder input through a linear layer with the previous step's context vector to get a modified version of the input. If initial_state_attention is False, on the first decoder step the \"previous context vector\" is just a zero vector. If initial_state_attention is True, we use _dec_in_state to (re)calculate the previous step's context vector. We set this to False for train/eval mode (because we call attention_decoder once for all decoder steps) and True for decode mode (because we call attention_decoder once for each decoder step).\n",
        "    pointer_gen: boolean. If True, calculate the generation probability p_gen for each decoder step.\n",
        "    use_coverage: boolean. If True, use coverage mechanism.\n",
        "    prev_coverage:\n",
        "      If not None, a tensor with shape (batch_size, max_enc_steps). The previous step's coverage vector. This is only not None in decode mode when using coverage.\n",
        "    prev_decoder_outputs: if not empty, a tensor of (len(prev_decoder_steps), batch_size, hidden_dim). The previous decoder output used for calculating the intradecoder attention during decode mode\n",
        "    prev_encoder_es: if not empty, a tensor of (len(prev_encoder_es), batch_size, hidden_dim). The previous attention vector used for calculating the temporal attention during decode mode.\n",
        "  Returns:\n",
        "    outputs: A list of the same length as emb_dec_inputs of 2D Tensors of\n",
        "      shape [batch_size x cell.output_size]. The output vectors.\n",
        "    state: The final state of the decoder. A tensor shape [batch_size x cell.state_size].\n",
        "    attn_dists: A list containing tensors of shape (batch_size,max_enc_steps).\n",
        "      The attention distributions for each decoder step.\n",
        "    p_gens: List of length emb_dim, containing tensors of shape [batch_size, 1]. The values of p_gen for each decoder step. Empty list if pointer_gen=False.\n",
        "    coverage: Coverage vector on the last step computed. None if use_coverage=False.\n",
        "    vocab_scores: vocab distribution.\n",
        "    final_dists: final output distribution.\n",
        "    samples: contains sampled tokens.\n",
        "    greedy_search_samples: contains greedy tokens.\n",
        "    temporal_e: contains temporal attention.\n",
        "  \"\"\"\n",
        "  with variable_scope.variable_scope(\"attention_decoder\") as scope:\n",
        "    batch_size = _enc_states.get_shape()[0] # if this line fails, it's because the batch size isn't defined\n",
        "    attn_size = _enc_states.get_shape()[2] # if this line fails, it's because the attention length isn't defined\n",
        "    emb_size = emb_dec_inputs[0].get_shape()[1] # if this line fails, it's because the embedding isn't defined\n",
        "    decoder_attn_size = _dec_in_state.c.get_shape()[1]\n",
        "    tf.compat.v1.logging.info(\"batch_size %i, attn_size: %i, emb_size: %i\", batch_size, attn_size, emb_size)\n",
        "    # Reshape _enc_states (need to insert a dim)\n",
        "    _enc_states = tf.expand_dims(_enc_states, axis=2) # now is shape (batch_size, max_enc_steps, 1, attn_size)\n",
        "\n",
        "    # To calculate attention, we calculate\n",
        "    #   v^T tanh(W_h h_i + W_s s_t + b_attn)\n",
        "    # where h_i is an encoder state, and s_t a decoder state.\n",
        "    # attn_vec_size is the length of the vectors v, b_attn, (W_h h_i) and (W_s s_t).\n",
        "    # We set it to be equal to the size of the encoder states.\n",
        "    attention_vec_size = attn_size\n",
        "\n",
        "    # Get the weight matrix W_h and apply it to each encoder state to get (W_h h_i), the encoder features\n",
        "    if _hps.matrix_attention:\n",
        "      w_attn = variable_scope.get_variable(\"w_attn\", [attention_vec_size, attention_vec_size])\n",
        "      if _hps.intradecoder:\n",
        "        w_dec_attn = variable_scope.get_variable(\"w_dec_attn\", [decoder_attn_size, decoder_attn_size])\n",
        "    else:\n",
        "      W_h = variable_scope.get_variable(\"W_h\", [1, 1, attn_size, attention_vec_size])\n",
        "      v = variable_scope.get_variable(\"v\", [attention_vec_size])\n",
        "      encoder_features = nn_ops.conv2d(_enc_states, W_h, [1, 1, 1, 1], \"SAME\") # shape (batch_size,max_enc_steps,1,attention_vec_size)\n",
        "    if _hps.intradecoder:\n",
        "      W_h_d = variable_scope.get_variable(\"W_h_d\", [1, 1, decoder_attn_size, decoder_attn_size])\n",
        "      v_d = variable_scope.get_variable(\"v_d\", [decoder_attn_size])\n",
        "\n",
        "    # Get the weight vectors v and w_c (w_c is for coverage)\n",
        "    if use_coverage:\n",
        "      with variable_scope.variable_scope(\"coverage\"):\n",
        "        w_c = variable_scope.get_variable(\"w_c\", [1, 1, 1, attention_vec_size])\n",
        "\n",
        "    if prev_coverage is not None: # for beam search mode with coverage\n",
        "      # reshape from (batch_size, max_enc_steps) to (batch_size, max_enc_steps, 1, 1)\n",
        "      prev_coverage = tf.expand_dims(tf.expand_dims(prev_coverage,2),3)\n",
        "\n",
        "    def attention(decoder_state, temporal_e, coverage=None):\n",
        "      \"\"\"Calculate the context vector and attention distribution from the decoder state.\n",
        "      Args:\n",
        "        decoder_state: state of the decoder\n",
        "        temporal_e: store previous attentions for temporal attention mechanism\n",
        "        coverage: Optional. Previous timestep's coverage vector, shape (batch_size, max_enc_steps, 1, 1).\n",
        "      Returns:\n",
        "        context_vector: weighted sum of _enc_states\n",
        "        attn_dist: attention distribution\n",
        "        coverage: new coverage vector. shape (batch_size, max_enc_steps, 1, 1)\n",
        "        masked_e: store the attention score for temporal attention mechanism.\n",
        "      \"\"\"\n",
        "      with variable_scope.variable_scope(\"Attention\"):\n",
        "        # Pass the decoder state through a linear layer (this is W_s s_t + b_attn in the paper)\n",
        "        decoder_features = linear(decoder_state, attention_vec_size, True) # shape (batch_size, attention_vec_size)\n",
        "        decoder_features = tf.expand_dims(tf.expand_dims(decoder_features, 1), 1) # reshape to (batch_size, 1, 1, attention_vec_size)\n",
        "\n",
        "        # We can't have coverage with matrix attention\n",
        "        if not _hps.matrix_attention and use_coverage and coverage is not None: # non-first step of coverage\n",
        "          # Multiply coverage vector by w_c to get coverage_features.\n",
        "          coverage_features = nn_ops.conv2d(coverage, w_c, [1, 1, 1, 1], \"SAME\") # c has shape (batch_size, max_enc_steps, 1, attention_vec_size)\n",
        "          # Calculate v^T tanh(W_h h_i + W_s s_t + w_c c_i^t + b_attn)\n",
        "          e_not_masked = math_ops.reduce_sum(v * math_ops.tanh(encoder_features + decoder_features + coverage_features), [2, 3])  # shape (batch_size,max_enc_steps)\n",
        "          masked_e = nn_ops.softmax(e_not_masked) * enc_padding_mask # (batch_size, max_enc_steps)\n",
        "          masked_sums = tf.reduce_sum(masked_e, axis=1) # shape (batch_size)\n",
        "          masked_e = masked_e / tf.reshape(masked_sums, [-1, 1])\n",
        "          # Equation 3 in \n",
        "          if _hps.use_temporal_attention:\n",
        "            try:\n",
        "              len_temporal_e = temporal_e.get_shape()[0]\n",
        "            except:\n",
        "              len_temporal_e = 0\n",
        "            if len_temporal_e==0:\n",
        "              attn_dist = masked_e\n",
        "            else:\n",
        "              masked_sums = tf.reduce_sum(temporal_e,axis=0)+1e-10 # if it's zero due to masking we set it to a small value\n",
        "              attn_dist = masked_e / masked_sums # (batch_size, max_enc_steps)\n",
        "          else:\n",
        "            attn_dist = masked_e\n",
        "          masked_attn_sums = tf.reduce_sum(attn_dist, axis=1)\n",
        "          attn_dist = attn_dist / tf.reshape(masked_attn_sums, [-1, 1]) # re-normalize\n",
        "          # Update coverage vector\n",
        "          coverage += array_ops.reshape(attn_dist, [batch_size, -1, 1, 1])\n",
        "        else:\n",
        "          if _hps.matrix_attention:\n",
        "            # Calculate h_d * W_attn * h_i, equation 2 in https://arxiv.org/pdf/1705.04304.pdf\n",
        "            _dec_attn = tf.unstack(tf.matmul(tf.squeeze(decoder_features,axis=[1,2]),w_attn),axis=0) # batch_size * (attention_vec_size)\n",
        "            _enc_states_lst = tf.unstack(tf.squeeze(_enc_states,axis=2),axis=0) # batch_size * (max_enc_steps, attention_vec_size)\n",
        "\n",
        "            e_not_masked = tf.squeeze(tf.stack([tf.matmul(tf.reshape(_dec,[1,-1]), tf.transpose(_enc)) for _dec, _enc in zip(_dec_attn,_enc_states_lst)]),axis=1) # (batch_size, max_enc_steps)\n",
        "            masked_e = tf.exp(e_not_masked * enc_padding_mask) # (batch_size, max_enc_steps)\n",
        "          else:\n",
        "            # Calculate v^T tanh(W_h h_i + W_s s_t + b_attn)\n",
        "            e_not_masked = math_ops.reduce_sum(v * math_ops.tanh(encoder_features + decoder_features), [2, 3]) # calculate e, (batch_size, max_enc_steps)\n",
        "            masked_e = nn_ops.softmax(e_not_masked) * enc_padding_mask # (batch_size, max_enc_steps)\n",
        "            masked_sums = tf.reduce_sum(masked_e, axis=1) # shape (batch_size)\n",
        "            masked_e = masked_e / tf.reshape(masked_sums, [-1, 1])\n",
        "          if _hps.use_temporal_attention:\n",
        "            try:\n",
        "              len_temporal_e = temporal_e.get_shape()[0]\n",
        "            except:\n",
        "              len_temporal_e = 0\n",
        "            if len_temporal_e==0:\n",
        "              attn_dist = masked_e\n",
        "            else:\n",
        "              masked_sums = tf.reduce_sum(temporal_e,axis=0)+1e-10 # if it's zero due to masking we set it to a small value\n",
        "              attn_dist = masked_e / masked_sums # (batch_size, max_enc_steps)\n",
        "          else:\n",
        "            attn_dist = masked_e\n",
        "          # Calculate attention distribution\n",
        "          masked_attn_sums = tf.reduce_sum(attn_dist, axis=1)\n",
        "          attn_dist = attn_dist / tf.reshape(masked_attn_sums, [-1, 1]) # re-normalize\n",
        "\n",
        "          if use_coverage: # first step of training\n",
        "            coverage = tf.expand_dims(tf.expand_dims(attn_dist,2),2) # initialize coverage\n",
        "\n",
        "        # Calculate the context vector from attn_dist and _enc_states\n",
        "        context_vector = math_ops.reduce_sum(array_ops.reshape(attn_dist, [batch_size, -1, 1, 1]) * _enc_states, [1, 2]) # shape (batch_size, attn_size).\n",
        "        context_vector = array_ops.reshape(context_vector, [-1, attn_size])\n",
        "\n",
        "      return context_vector, attn_dist, coverage, masked_e\n",
        "\n",
        "    def intra_decoder_attention(decoder_state, outputs):\n",
        "      \"\"\"Calculate the context vector and attention distribution from the decoder state.\n",
        "      Args:\n",
        "        decoder_state: state of the decoder\n",
        "        outputs: list of decoder states for implementing intra-decoder mechanism, len(decoder_states) * (batch_size, hidden_dim)\n",
        "      Returns:\n",
        "        context_decoder_vector: weighted sum of _dec_states\n",
        "        decoder_attn_dist: intra-decoder attention distribution\n",
        "      \"\"\"\n",
        "      attention_dec_vec_size = attn_dec_size = decoder_state.c.get_shape()[1] # hidden_dim\n",
        "      try:\n",
        "        len_dec_states = outputs.get_shape()[0]\n",
        "      except:\n",
        "        len_dec_states = 0\n",
        "      attention_dec_vec_size = attn_dec_size = decoder_state.c.get_shape()[1] # hidden_dim\n",
        "      _decoder_states = tf.expand_dims(tf.reshape(outputs,[batch_size,-1,attn_dec_size]), axis=2) # now is shape (batch_size,len(decoder_states), 1, attn_size)\n",
        "      _prev_decoder_features = nn_ops.conv2d(_decoder_states, W_h_d, [1, 1, 1, 1], \"SAME\") # shape (batch_size,len(decoder_states),1,attention_vec_size)\n",
        "      with variable_scope.variable_scope(\"DecoderAttention\"):\n",
        "        # Pass the decoder state through a linear layer (this is W_s s_t + b_attn in the paper)\n",
        "        try:\n",
        "          decoder_features = linear(decoder_state, attention_dec_vec_size, True) # shape (batch_size, attention_vec_size)\n",
        "          decoder_features = tf.expand_dims(tf.expand_dims(decoder_features, 1), 1) # reshape to (batch_size, 1, 1, attention_dec_vec_size)\n",
        "          # Calculate v^T tanh(W_h h_i + W_s s_t + b_attn)\n",
        "          if _hps.matrix_attention:\n",
        "            # Calculate h_d * W_attn * h_d, equation 6 in https://arxiv.org/pdf/1705.04304.pdf\n",
        "            _dec_attn = tf.matmul(tf.squeeze(decoder_features),w_dec_attn) # (batch_size, decoder_attn_size)\n",
        "            _dec_states_lst = tf.unstack(tf.reshape(_prev_decoder_features,[batch_size,-1,decoder_attn_size])) # batch_size * (len(decoder_states), decoder_attn_size)\n",
        "            e_not_masked = tf.reshape(tf.stack([tf.matmul(_dec_attn, tf.transpose(k)) for k in _dec_states_lst]),[batch_size,-1]) # (batch_size, len(decoder_states))\n",
        "            masked_e = tf.exp(e_not_masked * dec_padding_mask[:,:len_dec_states]) # (batch_size, len(decoder_states))\n",
        "          else:\n",
        "            # Calculate v^T tanh(W_h h_i + W_s s_t + b_attn)\n",
        "            e_not_masked = math_ops.reduce_sum(v_d * math_ops.tanh(_prev_decoder_features + decoder_features), [2, 3]) # calculate e, (batch_size,len(decoder_states))\n",
        "            masked_e = nn_ops.softmax(e_not_masked) * dec_padding_mask[:,:len_dec_states] # (batch_size,len(decoder_states))\n",
        "          if len_dec_states <= 1:\n",
        "            masked_e = array_ops.ones([batch_size,1]) # first step is filled with equal values\n",
        "          masked_sums = tf.reshape(tf.reduce_sum(masked_e,axis=1),[-1,1]) # (batch_size,1), # if it's zero due to masking we set it to a small value\n",
        "          decoder_attn_dist = masked_e / masked_sums # (batch_size,len(decoder_states))\n",
        "          context_decoder_vector = math_ops.reduce_sum(array_ops.reshape(decoder_attn_dist, [batch_size, -1, 1, 1]) * _decoder_states, [1, 2]) # (batch_size, attn_size)\n",
        "          context_decoder_vector = array_ops.reshape(context_decoder_vector, [-1, attn_dec_size]) # (batch_size, attn_size)\n",
        "        except:\n",
        "          return array_ops.zeros([batch_size, decoder_attn_size]), array_ops.zeros([batch_size, 0])\n",
        "      return context_decoder_vector, decoder_attn_dist\n",
        "\n",
        "    outputs = []\n",
        "    temporal_e = []\n",
        "    attn_dists = []\n",
        "    vocab_scores = []\n",
        "    vocab_dists = []\n",
        "    final_dists = []\n",
        "    p_gens = []\n",
        "    samples = [] # this holds the words chosen by sampling based on the final distribution for each decoding step, list of max_dec_steps of (batch_size, 1)\n",
        "    greedy_search_samples = [] # this holds the words chosen by greedy search (taking the max) on the final distribution for each decoding step, list of max_dec_steps of (batch_size, 1)\n",
        "    sampling_rewards = [] # list of size max_dec_steps (batch_size, k)\n",
        "    greedy_rewards = [] # list of size max_dec_steps (batch_size, k)\n",
        "    state = _dec_in_state\n",
        "    coverage = prev_coverage # initialize coverage to None or whatever was passed in\n",
        "    context_vector = array_ops.zeros([batch_size, attn_size])\n",
        "    context_decoder_vector = array_ops.zeros([batch_size, decoder_attn_size])\n",
        "    context_vector.set_shape([None, attn_size])  # Ensure the second shape of attention vectors is set.\n",
        "    if initial_state_attention: # true in decode mode\n",
        "      # Re-calculate the context vector from the previous step so that we can pass it through a linear layer with this step's input to get a modified version of the input\n",
        "      context_vector, _, coverage, _ = attention(_dec_in_state, tf.stack(prev_encoder_es,axis=0), coverage) # in decode mode, this is what updates the coverage vector\n",
        "      if _hps.intradecoder:\n",
        "        context_decoder_vector, _ = intra_decoder_attention(_dec_in_state, tf.stack(prev_decoder_outputs,axis=0))\n",
        "    for i, inp in enumerate(emb_dec_inputs):\n",
        "      tf.compat.v1.logging.info(\"Adding attention_decoder timestep %i of %i\", i, len(emb_dec_inputs))\n",
        "      \n",
        "      \n",
        "      if i > 0:\n",
        "        variable_scope.get_variable_scope().reuse_variables()\n",
        "\n",
        "      if _hps.mode in ['train','eval'] and _hps.scheduled_sampling and i > 0: # start scheduled sampling after we received the first decoder's output\n",
        "        # modify the input to next decoder using scheduled sampling\n",
        "        if FLAGS.scheduled_sampling_final_dist:\n",
        "          inp = scheduled_sampling(_hps, sampling_probability, final_dist, embedding, inp, alpha)\n",
        "        else:\n",
        "          inp = scheduled_sampling_vocab_dist(_hps, sampling_probability, vocab_dist, embedding, inp, alpha)\n",
        "\n",
        "      # Merge input and previous attentions into one vector x of the same size as inp\n",
        "      emb_dim = inp.get_shape().with_rank(2)[1]\n",
        "      if emb_dim is None:\n",
        "        raise ValueError(\"Could not infer input size from input: %s\" % inp.name)\n",
        "\n",
        "      x = linear([inp] + [context_vector], emb_dim, True)\n",
        "      # Run the decoder RNN cell. cell_output = decoder state\n",
        "      cell_output, state = cell(x, state)\n",
        "\n",
        "      # Run the attention mechanism.\n",
        "      if i == 0 and initial_state_attention:  # always true in decode mode\n",
        "        with variable_scope.variable_scope(variable_scope.get_variable_scope()):#, reuse=True): # you need this because you've already run the initial attention(...) call\n",
        "          context_vector, attn_dist, _, masked_e = attention(state, tf.stack(prev_encoder_es,axis=0), coverage) # don't allow coverage to update\n",
        "          if _hps.intradecoder:\n",
        "            context_decoder_vector, _ = intra_decoder_attention(state, tf.stack(prev_decoder_outputs,axis=0))\n",
        "      else:\n",
        "        context_vector, attn_dist, coverage, masked_e = attention(state, tf.stack(temporal_e,axis=0), coverage)\n",
        "        if _hps.intradecoder:\n",
        "          context_decoder_vector, _ = intra_decoder_attention(state, tf.stack(outputs,axis=0))\n",
        "      attn_dists.append(attn_dist)\n",
        "      temporal_e.append(masked_e)\n",
        "\n",
        "      with variable_scope.variable_scope(\"combined_context\"):\n",
        "        if _hps.intradecoder:\n",
        "          context_vector = linear([context_vector] + [context_decoder_vector], attn_size, False)\n",
        "      # Calculate p_gen\n",
        "      if pointer_gen:\n",
        "        with tf.variable_scope('calculate_pgen'):\n",
        "          p_gen = linear([context_vector, state.c, state.h, x], 1, True) # Tensor shape (batch_size, 1)\n",
        "          p_gen = tf.sigmoid(p_gen)\n",
        "          p_gens.append(p_gen)\n",
        "\n",
        "      # Concatenate the cell_output (= decoder state) and the context vector, and pass them through a linear layer\n",
        "      # This is V[s_t, h*_t] + b in the paper\n",
        "      with variable_scope.variable_scope(\"AttnOutputProjection\"):\n",
        "        output = linear([cell_output] + [context_vector], cell.output_size, True)\n",
        "      outputs.append(output)\n",
        "\n",
        "      # Add the output projection to obtain the vocabulary distribution\n",
        "      with tf.variable_scope('output_projection'):\n",
        "        if i > 0:\n",
        "          tf.get_variable_scope().reuse_variables()\n",
        "        trunc_norm_init = tf.truncated_normal_initializer(stddev=_hps.trunc_norm_init_std)\n",
        "        w_out = tf.get_variable('w', [_hps.dec_hidden_dim, v_size], dtype=tf.float32, initializer=trunc_norm_init)\n",
        "        #w_t_out = tf.transpose(w)\n",
        "        v_out = tf.get_variable('v', [v_size], dtype=tf.float32, initializer=trunc_norm_init)\n",
        "        if i > 0:\n",
        "          tf.get_variable_scope().reuse_variables()\n",
        "        if FLAGS.share_decoder_weights: # Eq. 13 in https://arxiv.org/pdf/1705.04304.pdf\n",
        "          w_out = tf.transpose(\n",
        "            math_ops.tanh(linear([embedding] + [tf.transpose(w_out)], _hps.dec_hidden_dim, bias=False)))\n",
        "        score = tf.nn.xw_plus_b(output, w_out, v_out)\n",
        "        if _hps.scheduled_sampling and not _hps.greedy_scheduled_sampling:\n",
        "          # Gumbel reparametrization trick: https://arxiv.org/abs/1704.06970\n",
        "          U = tf.random_uniform(score.get_shape(),10e-12,(1-10e-12)) # add a small number to avoid log(0)\n",
        "          G = -tf.log(-tf.log(U))\n",
        "          score = score + G\n",
        "        vocab_scores.append(score) # apply the linear layer\n",
        "        vocab_dist = tf.nn.softmax(score)\n",
        "        vocab_dists.append(vocab_dist) # The vocabulary distributions. List length max_dec_steps of (batch_size, vsize) arrays. The words are in the order they appear in the vocabulary file.\n",
        "\n",
        "      # For pointer-generator model, calc final distribution from copy distribution and vocabulary distribution\n",
        "      if _hps.pointer_gen:\n",
        "        final_dist = _calc_final_dist(_hps, v_size, _max_art_oovs, _enc_batch_extend_vocab, p_gen, vocab_dist,\n",
        "                                      attn_dist)\n",
        "      else: # final distribution is just vocabulary distribution\n",
        "        final_dist = vocab_dist\n",
        "      final_dists.append(final_dist)\n",
        "\n",
        "      # get the sampled token and greedy token\n",
        "      # this will take the final_dist and sample from it for a total count of k (k samples)\n",
        "      one_hot_k_samples = tf.distributions.Multinomial(total_count=1., probs=final_dist).sample(\n",
        "        _hps.k)  # sample k times according to https://arxiv.org/pdf/1705.04304.pdf, size (k, batch_size, extended_vsize)\n",
        "      k_argmax = tf.argmax(one_hot_k_samples, axis=2, output_type=tf.int32) # (k, batch_size)\n",
        "      k_sample = tf.transpose(k_argmax) # shape (batch_size, k)\n",
        "      greedy_search_prob, greedy_search_sample = tf.nn.top_k(final_dist, k=_hps.k) # (batch_size, k)\n",
        "      greedy_search_samples.append(greedy_search_sample)\n",
        "      samples.append(k_sample)\n",
        "      if FLAGS.use_discounted_rewards:\n",
        "        _sampling_rewards = []\n",
        "        _greedy_rewards = []\n",
        "        for _ in range(_hps.k):\n",
        "          rl_fscore = tf.reshape(rouge_l_fscore(tf.transpose(tf.stack(samples)[:, :, _]), target_batch),\n",
        "                                 [-1, 1])  # shape (batch_size, 1)\n",
        "          _sampling_rewards.append(tf.reshape(rl_fscore, [-1, 1]))\n",
        "          rl_fscore = tf.reshape(rouge_l_fscore(tf.transpose(tf.stack(greedy_search_samples)[:, :, _]), target_batch),\n",
        "                                 [-1, 1])  # shape (batch_size, 1)\n",
        "          _greedy_rewards.append(tf.reshape(rl_fscore, [-1, 1]))\n",
        "        sampling_rewards.append(tf.squeeze(tf.stack(_sampling_rewards, axis=1), axis = -1)) # (batch_size, k)\n",
        "        greedy_rewards.append(tf.squeeze(tf.stack(_greedy_rewards, axis=1), axis = -1))  # (batch_size, k)\n",
        "\n",
        "    if FLAGS.use_discounted_rewards:\n",
        "      sampling_rewards = tf.stack(sampling_rewards)\n",
        "      greedy_rewards = tf.stack(greedy_rewards)\n",
        "    else:\n",
        "      _sampling_rewards = []\n",
        "      _greedy_rewards = []\n",
        "      for _ in range(_hps.k):\n",
        "        rl_fscore = rouge_l_fscore(tf.transpose(tf.stack(samples)[:, :, _]), target_batch) # shape (batch_size, 1)\n",
        "        _sampling_rewards.append(tf.reshape(rl_fscore, [-1, 1]))\n",
        "        rl_fscore = rouge_l_fscore(tf.transpose(tf.stack(greedy_search_samples)[:, :, _]), target_batch)  # shape (batch_size, 1)\n",
        "        _greedy_rewards.append(tf.reshape(rl_fscore, [-1, 1]))\n",
        "      sampling_rewards = tf.squeeze(tf.stack(_sampling_rewards, axis=1), axis=-1) # (batch_size, k)\n",
        "      greedy_rewards = tf.squeeze(tf.stack(_greedy_rewards, axis=1), axis=-1) # (batch_size, k)\n",
        "    # If using coverage, reshape it\n",
        "    if coverage is not None:\n",
        "      coverage = array_ops.reshape(coverage, [batch_size, -1])\n",
        "\n",
        "  return (\n",
        "  outputs, state, attn_dists, p_gens, coverage, vocab_scores, final_dists, samples, greedy_search_samples, temporal_e,\n",
        "  sampling_rewards, greedy_rewards)\n",
        "\n",
        "def scheduled_sampling(hps, sampling_probability, output, embedding, inp, alpha = 0):\n",
        "  # borrowed ideas from https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/ScheduledEmbeddingTrainingHelper\n",
        "  vocab_size = embedding.get_shape()[0]\n",
        "\n",
        "  def soft_argmax(alpha, _output):\n",
        "    new_oov_scores = tf.reshape(_output[:, 0] + tf.reduce_sum(_output[:, vocab_size:], axis=1),\n",
        "                                [-1, 1])  # add score for all OOV to the UNK score\n",
        "    _output = tf.concat([new_oov_scores, _output[:, 1:vocab_size]], axis=1) # select only the vocab_size outputs\n",
        "    _output = _output / tf.reshape(tf.reduce_sum(output, axis=1), [-1, 1]) # re-normalize scores\n",
        "\n",
        "    #alpha_exp = tf.exp(alpha * _output) # (batch_size, vocab_size)\n",
        "    #one_hot_scores = alpha_exp / tf.reshape(tf.reduce_sum(alpha_exp, axis=1),[-1,1]) #(batch_size, vocab_size)\n",
        "    one_hot_scores = tf.nn.softmax((alpha * _output))\n",
        "    return one_hot_scores\n",
        "\n",
        "  def soft_top_k(alpha, _output, K):\n",
        "    copy = tf.identity(_output)\n",
        "    p = []\n",
        "    arg_top_k = []\n",
        "    for k in range(K):\n",
        "      sargmax = soft_argmax(alpha, copy)\n",
        "      copy = (1-sargmax)* copy\n",
        "      p.append(tf.reduce_sum(sargmax * _output, axis=1))\n",
        "      arg_top_k.append(sargmax)\n",
        "\n",
        "    return tf.stack(p, axis=1), tf.stack(arg_top_k)\n",
        "\n",
        "  with variable_scope.variable_scope(\"ScheduledEmbedding\"):\n",
        "    # Return -1s where we did not sample, and sample_ids elsewhere\n",
        "    select_sampler = bernoulli.Bernoulli(probs=sampling_probability, dtype=tf.bool)\n",
        "    select_sample = select_sampler.sample(sample_shape=hps.batch_size)\n",
        "    sample_id_sampler = categorical.Categorical(probs=output) # equals to argmax{ Multinomial(output, total_count=1) }, our greedy search selection\n",
        "    sample_ids = array_ops.where(\n",
        "            select_sample,\n",
        "            sample_id_sampler.sample(seed=123),\n",
        "            gen_array_ops.fill([hps.batch_size], -1))\n",
        "\n",
        "    where_sampling = math_ops.cast(\n",
        "        array_ops.where(sample_ids > -1), tf.int32)\n",
        "    where_not_sampling = math_ops.cast(\n",
        "        array_ops.where(sample_ids <= -1), tf.int32)\n",
        "\n",
        "    if hps.greedy_scheduled_sampling:\n",
        "      sample_ids = tf.argmax(output, axis=1, output_type=tf.int32)\n",
        "\n",
        "    sample_ids_sampling = array_ops.gather_nd(sample_ids, where_sampling)\n",
        "\n",
        "    cond = tf.less(sample_ids_sampling, vocab_size) # replace oov with unk\n",
        "    sample_ids_sampling = tf.cast(cond, tf.int32) * sample_ids_sampling\n",
        "    inputs_not_sampling = array_ops.gather_nd(inp, where_not_sampling)\n",
        "\n",
        "    if hps.E2EBackProp:\n",
        "      if hps.hard_argmax:\n",
        "        greedy_search_prob, greedy_search_sample = tf.nn.top_k(output, k=hps.k) # (batch_size, k)\n",
        "        greedy_search_prob_normalized = greedy_search_prob/tf.reshape(tf.reduce_sum(greedy_search_prob,axis=1),[-1,1])\n",
        "\n",
        "        cond = tf.less(greedy_search_sample, vocab_size) # replace oov with unk\n",
        "        greedy_search_sample = tf.cast(cond, tf.int32) * greedy_search_sample\n",
        "\n",
        "        greedy_embedding = tf.nn.embedding_lookup(embedding, greedy_search_sample)\n",
        "        normalized_embedding = tf.multiply(tf.reshape(greedy_search_prob_normalized,[hps.batch_size,hps.k,1]), greedy_embedding)\n",
        "        e2e_embedding = tf.reduce_mean(normalized_embedding,axis=1)\n",
        "      else:\n",
        "        e = []\n",
        "        greedy_search_prob, greedy_search_sample = soft_top_k(alpha, output,\n",
        "                                                              K=hps.k)  # (batch_size, k), (k, batch_size, vocab_size)\n",
        "        greedy_search_prob_normalized = greedy_search_prob / tf.reshape(tf.reduce_sum(greedy_search_prob, axis=1),\n",
        "                                                                        [-1, 1])\n",
        "\n",
        "        for _ in range(hps.k):\n",
        "          a_k = greedy_search_sample[_]\n",
        "          e_k = tf.matmul(tf.reshape(greedy_search_prob_normalized[:,_],[-1,1]) * a_k, embedding)\n",
        "          e.append(e_k)\n",
        "        e2e_embedding = tf.reduce_sum(e, axis=0) # (batch_size, emb_dim)\n",
        "      sampled_next_inputs = array_ops.gather_nd(e2e_embedding, where_sampling)\n",
        "    else:\n",
        "      if hps.hard_argmax:\n",
        "        sampled_next_inputs = tf.nn.embedding_lookup(embedding, sample_ids_sampling)\n",
        "      else: # using soft armax (greedy) proposed in: https://arxiv.org/abs/1704.06970\n",
        "        #alpha_exp = tf.exp(alpha * (output_not_extended + G)) # (batch_size, vocab_size)\n",
        "        #one_hot_scores = alpha_exp / tf.reduce_sum(alpha_exp, axis=1) #(batch_size, vocab_size)\n",
        "        one_hot_scores = soft_argmax(alpha, output) #(batch_size, vocab_size)\n",
        "        soft_argmax_embedding = tf.matmul(one_hot_scores, embedding) #(batch_size, emb_size)\n",
        "        sampled_next_inputs = array_ops.gather_nd(soft_argmax_embedding, where_sampling)\n",
        "\n",
        "    base_shape = array_ops.shape(inp)\n",
        "    result1 = array_ops.scatter_nd(indices=where_sampling, updates=sampled_next_inputs, shape=base_shape)\n",
        "    result2 = array_ops.scatter_nd(indices=where_not_sampling, updates=inputs_not_sampling, shape=base_shape)\n",
        "    return result1 + result2\n",
        "\n",
        "def scheduled_sampling_vocab_dist(hps, sampling_probability, output, embedding, inp, alpha = 0):\n",
        "  # borrowed ideas from https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/ScheduledEmbeddingTrainingHelper\n",
        "\n",
        "  def soft_argmax(alpha, output):\n",
        "    #alpha_exp = tf.exp(alpha * output) # (batch_size, vocab_size)\n",
        "    #one_hot_scores = alpha_exp / tf.reshape(tf.reduce_sum(alpha_exp, axis=1),[-1,1]) #(batch_size, vocab_size)\n",
        "    one_hot_scores = tf.nn.softmax(alpha * output)\n",
        "    return one_hot_scores\n",
        "\n",
        "  def soft_top_k(alpha, output, K):\n",
        "    copy = tf.identity(output)\n",
        "    p = []\n",
        "    arg_top_k = []\n",
        "    for k in range(K):\n",
        "      sargmax = soft_argmax(alpha, copy)\n",
        "      copy = (1-sargmax)* copy\n",
        "      p.append(tf.reduce_sum(sargmax * output, axis=1))\n",
        "      arg_top_k.append(sargmax)\n",
        "\n",
        "    return tf.stack(p, axis=1), tf.stack(arg_top_k)\n",
        "\n",
        "  with variable_scope.variable_scope(\"ScheduledEmbedding\"):\n",
        "    # Return -1s where we did not sample, and sample_ids elsewhere\n",
        "    select_sampler = bernoulli.Bernoulli(probs=sampling_probability, dtype=tf.bool)\n",
        "    select_sample = select_sampler.sample(sample_shape=hps.batch_size)\n",
        "    sample_id_sampler = categorical.Categorical(probs=output) # equals to argmax{ Multinomial(output, total_count=1) }, our greedy search selection\n",
        "    sample_ids = array_ops.where(\n",
        "            select_sample,\n",
        "            sample_id_sampler.sample(seed=123),\n",
        "            gen_array_ops.fill([hps.batch_size], -1))\n",
        "\n",
        "    where_sampling = math_ops.cast(\n",
        "        array_ops.where(sample_ids > -1), tf.int32)\n",
        "    where_not_sampling = math_ops.cast(\n",
        "        array_ops.where(sample_ids <= -1), tf.int32)\n",
        "\n",
        "    if hps.greedy_scheduled_sampling:\n",
        "      sample_ids = tf.argmax(output, axis=1, output_type=tf.int32)\n",
        "\n",
        "    sample_ids_sampling = array_ops.gather_nd(sample_ids, where_sampling)\n",
        "    inputs_not_sampling = array_ops.gather_nd(inp, where_not_sampling)\n",
        "\n",
        "    if hps.E2EBackProp:\n",
        "      if hps.hard_argmax:\n",
        "        greedy_search_prob, greedy_search_sample = tf.nn.top_k(output, k=hps.k) # (batch_size, k)\n",
        "        greedy_search_prob_normalized = greedy_search_prob/tf.reshape(tf.reduce_sum(greedy_search_prob,axis=1),[-1,1])\n",
        "        greedy_embedding = tf.nn.embedding_lookup(embedding, greedy_search_sample)\n",
        "        normalized_embedding = tf.multiply(tf.reshape(greedy_search_prob_normalized,[hps.batch_size,hps.k,1]), greedy_embedding)\n",
        "        e2e_embedding = tf.reduce_mean(normalized_embedding,axis=1)\n",
        "      else:\n",
        "        e = []\n",
        "        greedy_search_prob, greedy_search_sample = soft_top_k(alpha, output,\n",
        "                                                              K=hps.k)  # (batch_size, k), (k, batch_size, vocab_size)\n",
        "        greedy_search_prob_normalized = greedy_search_prob / tf.reshape(tf.reduce_sum(greedy_search_prob, axis=1),\n",
        "                                                                        [-1, 1])\n",
        "\n",
        "        for _ in range(hps.k):\n",
        "          a_k = greedy_search_sample[_]\n",
        "          e_k = tf.matmul(tf.reshape(greedy_search_prob_normalized[:,_],[-1,1]) * a_k, embedding)\n",
        "          e.append(e_k)\n",
        "        e2e_embedding = tf.reduce_sum(e, axis=0) # (batch_size, emb_dim)\n",
        "      sampled_next_inputs = array_ops.gather_nd(e2e_embedding, where_sampling)\n",
        "    else:\n",
        "      if hps.hard_argmax:\n",
        "        sampled_next_inputs = tf.nn.embedding_lookup(embedding, sample_ids_sampling)\n",
        "      else: # using soft armax (greedy) proposed in: https://arxiv.org/abs/1704.06970\n",
        "        #alpha_exp = tf.exp(alpha * (output_not_extended + G)) # (batch_size, vocab_size)\n",
        "        #one_hot_scores = alpha_exp / tf.reduce_sum(alpha_exp, axis=1) #(batch_size, vocab_size)\n",
        "        one_hot_scores = soft_argmax(alpha, output) #(batch_size, vocab_size)\n",
        "        soft_argmax_embedding = tf.matmul(one_hot_scores, embedding) #(batch_size, emb_size)\n",
        "        sampled_next_inputs = array_ops.gather_nd(soft_argmax_embedding, where_sampling)\n",
        "\n",
        "    base_shape = array_ops.shape(inp)\n",
        "    result1 = array_ops.scatter_nd(indices=where_sampling, updates=sampled_next_inputs, shape=base_shape)\n",
        "    result2 = array_ops.scatter_nd(indices=where_not_sampling, updates=inputs_not_sampling, shape=base_shape)\n",
        "    return result1 + result2\n",
        "\n",
        "def linear(args, output_size, bias, bias_start=0.0, scope=None):\n",
        "  \"\"\"Linear map: sum_i(args[i] * W[i]), where W[i] is a variable.\n",
        "  Args:\n",
        "    args: a 2D Tensor or a list of 2D, batch x n, Tensors.\n",
        "    output_size: int, second dimension of W[i].\n",
        "    bias: boolean, whether to add a bias term or not.\n",
        "    bias_start: starting value to initialize the bias; 0 by default.\n",
        "    scope: VariableScope for the created subgraph; defaults to \"Linear\".\n",
        "  Returns:\n",
        "    A 2D Tensor with shape [batch x output_size] equal to\n",
        "    sum_i(args[i] * W[i]), where W[i]s are newly created matrices.\n",
        "  Raises:\n",
        "    ValueError: if some of the arguments has unspecified or wrong shape.\n",
        "  \"\"\"\n",
        "  if args is None or (isinstance(args, (list, tuple)) and not args):\n",
        "    raise ValueError(\"`args` must be specified\")\n",
        "  if not isinstance(args, (list, tuple)):\n",
        "    args = [args]\n",
        "  # Calculate the total size of arguments on dimension 1.\n",
        "  total_arg_size = 0\n",
        "  shapes = [a.get_shape().as_list() for a in args]\n",
        "  for shape in shapes:\n",
        "    if len(shape) != 2:\n",
        "      raise ValueError(\"Linear is expecting 2D arguments: %s\" % str(shapes))\n",
        "    if not shape[1]:\n",
        "      raise ValueError(\"Linear expects shape[1] of arguments: %s\" % str(shapes))\n",
        "    else:\n",
        "      total_arg_size += shape[1]\n",
        "\n",
        "  # Now the computation.\n",
        "  with tf.variable_scope(scope or \"Linear\" , reuse=tf.AUTO_REUSE):\n",
        "    matrix = tf.get_variable(\"Matrix\", [total_arg_size, output_size])\n",
        "    if len(args) == 1:\n",
        "      res = tf.matmul(args[0], matrix)\n",
        "    else:\n",
        "      res = tf.matmul(tf.concat(axis=1, values=args), matrix)\n",
        "    if not bias:\n",
        "      return res\n",
        "    bias_term = tf.get_variable(\n",
        "        \"Bias\", [output_size], initializer=tf.constant_initializer(bias_start))\n",
        "  return res + bias_term"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4EKS0e5IsEB"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZxgFOulIu3b"
      },
      "source": [
        "https://github.com/yaserkl/RLSeq2Seq/blob/master/src/model.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOpxpsHjIwaE"
      },
      "source": [
        "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
        "# Modifications Copyright 2017 Abigail See\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "\"\"\"This file contains code to build and run the tensorflow graph for the sequence-to-sequence model\"\"\"\n",
        "\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "# import tensorflow as tf\n",
        "#from attention_decoder import attention_decoder\n",
        "##from tensorflow.contrib.tensorboard.plugins import projector\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "#from rouge import rouge\n",
        "#from rouge_tensor import rouge_l_fscore\n",
        "#import data\n",
        "#from replay_buffer import Transition\n",
        "\n",
        "FLAGS = tf.compat.v1.flags\n",
        "\n",
        "class SummarizationModel(object):\n",
        "  \"\"\"A class to represent a sequence-to-sequence model for text summarization. Supports both baseline mode, pointer-generator mode, and coverage\"\"\"\n",
        "\n",
        "  def __init__(self, hps, vocab):\n",
        "    self._hps = hps\n",
        "    self._vocab = vocab\n",
        "\n",
        "  def reward_function(self, reference, summary, measure='rouge_l/f_score'):\n",
        "    \"\"\"Calculate the reward between the reference and summary.\n",
        "    Args:\n",
        "      reference: A list of ids representing the ground-truth data\n",
        "      summary: A list of ids representing the model generated data\n",
        "    Returns:\n",
        "      A single value representing the evaluation value for reference and summary\n",
        "    \"\"\"\n",
        "    if 'rouge' in measure:\n",
        "      return rouge([summary],[reference])[measure]\n",
        "    else:\n",
        "      return sentence_bleu([reference.split()],summary.split(),weights=(0.25,0.25,0.25,0.25))\n",
        "\n",
        "  def variable_summaries(self, var_name, var):\n",
        "    \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\n",
        "    with tf.name_scope('summaries_{}'.format(var_name)):\n",
        "      mean = tf.reduce_mean(var)\n",
        "      tf.summary.scalar('mean', mean)\n",
        "      with tf.name_scope('stddev'):\n",
        "        stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
        "      tf.summary.scalar('stddev', stddev)\n",
        "      tf.summary.scalar('max', tf.reduce_max(var))\n",
        "      tf.summary.scalar('min', tf.reduce_min(var))\n",
        "      tf.summary.histogram('histogram', var)\n",
        "\n",
        "  def _add_placeholders(self):\n",
        "    \"\"\"Add placeholders to the graph. These are entry points for any input data.\"\"\"\n",
        "    hps = self._hps\n",
        "\n",
        "    # encoder part\n",
        "    self._enc_batch = tf.placeholder(tf.int32, [hps.batch_size, None], name='enc_batch')\n",
        "    self._enc_lens = tf.placeholder(tf.int32, [hps.batch_size], name='enc_lens')\n",
        "    self._enc_padding_mask = tf.placeholder(tf.float32, [hps.batch_size, None], name='enc_padding_mask')\n",
        "    self._eta = tf.placeholder(tf.float32, None, name='eta')\n",
        "    if FLAGS.embedding != \"\":\n",
        "      self.embedding_place = tf.placeholder(tf.float32, [self._vocab.size(), hps.emb_dim])\n",
        "    if FLAGS.pointer_gen:\n",
        "      self._enc_batch_extend_vocab = tf.placeholder(tf.int32, [hps.batch_size, None], name='enc_batch_extend_vocab')\n",
        "      self._max_art_oovs = tf.placeholder(tf.int32, [], name='max_art_oovs')\n",
        "    if FLAGS.ac_training: # added by yaserkl@vt.edu for the purpose of calculating rouge loss\n",
        "      self._q_estimates = tf.placeholder(tf.float32, [self._hps.batch_size,self._hps.k,self._hps.max_dec_steps, None], name='q_estimates')\n",
        "    if FLAGS.scheduled_sampling:\n",
        "      self._sampling_probability = tf.placeholder(tf.float32, None, name='sampling_probability')\n",
        "      self._alpha = tf.placeholder(tf.float32, None, name='alpha')\n",
        "\n",
        "    # decoder part\n",
        "    self._dec_batch = tf.placeholder(tf.int32, [hps.batch_size, hps.max_dec_steps], name='dec_batch')\n",
        "    self._target_batch = tf.placeholder(tf.int32, [hps.batch_size, hps.max_dec_steps], name='target_batch')\n",
        "    self._dec_padding_mask = tf.placeholder(tf.float32, [hps.batch_size, hps.max_dec_steps], name='dec_padding_mask')\n",
        "\n",
        "    if hps.mode == \"decode\":\n",
        "      if hps.coverage:\n",
        "        self.prev_coverage = tf.placeholder(tf.float32, [hps.batch_size, None], name='prev_coverage')\n",
        "      if hps.intradecoder:\n",
        "        self.prev_decoder_outputs = tf.placeholder(tf.float32, [None, hps.batch_size, hps.dec_hidden_dim], name='prev_decoder_outputs')\n",
        "      if hps.use_temporal_attention:\n",
        "        self.prev_encoder_es = tf.placeholder(tf.float32, [None, hps.batch_size, None], name='prev_encoder_es')\n",
        "\n",
        "  def _make_feed_dict(self, batch, just_enc=False):\n",
        "    \"\"\"Make a feed dictionary mapping parts of the batch to the appropriate placeholders.\n",
        "    Args:\n",
        "      batch: Batch object\n",
        "      just_enc: Boolean. If True, only feed the parts needed for the encoder.\n",
        "    \"\"\"\n",
        "    feed_dict = {}\n",
        "    feed_dict[self._enc_batch] = batch.enc_batch\n",
        "    feed_dict[self._enc_lens] = batch.enc_lens\n",
        "    feed_dict[self._enc_padding_mask] = batch.enc_padding_mask\n",
        "    if FLAGS.pointer_gen:\n",
        "      feed_dict[self._enc_batch_extend_vocab] = batch.enc_batch_extend_vocab\n",
        "      feed_dict[self._max_art_oovs] = batch.max_art_oovs\n",
        "    if not just_enc:\n",
        "      feed_dict[self._dec_batch] = batch.dec_batch\n",
        "      feed_dict[self._target_batch] = batch.target_batch\n",
        "      feed_dict[self._dec_padding_mask] = batch.dec_padding_mask\n",
        "    return feed_dict\n",
        "\n",
        "  def _add_encoder(self, emb_enc_inputs, seq_len):\n",
        "    \"\"\"Add a single-layer bidirectional LSTM encoder to the graph.\n",
        "    Args:\n",
        "      emb_enc_inputs: A tensor of shape [batch_size, <=max_enc_steps, emb_size].\n",
        "      seq_len: Lengths of emb_enc_inputs (before padding). A tensor of shape [batch_size].\n",
        "    Returns:\n",
        "      encoder_outputs:\n",
        "        A tensor of shape [batch_size, <=max_enc_steps, 2*hidden_dim]. It's 2*hidden_dim because it's the concatenation of the forwards and backwards states.\n",
        "      fw_state, bw_state:\n",
        "        Each are LSTMStateTuples of shape ([batch_size,hidden_dim],[batch_size,hidden_dim])\n",
        "    \"\"\"\n",
        "    with tf.variable_scope('encoder'):\n",
        "      cell_fw = tf.nn.rnn_cell.LSTMCell(self._hps.enc_hidden_dim, initializer=self.rand_unif_init, state_is_tuple=True)\n",
        "      cell_bw = tf.nn.rnn_cell.LSTMCell(self._hps.enc_hidden_dim, initializer=self.rand_unif_init, state_is_tuple=True)\n",
        "      (encoder_outputs, (fw_st, bw_st)) = tf.nn.bidirectional_dynamic_rnn(cell_fw, cell_bw, emb_enc_inputs, dtype=tf.float32, sequence_length=seq_len, swap_memory=True)\n",
        "      encoder_outputs = tf.concat(axis=2, values=encoder_outputs) # concatenate the forwards and backwards states\n",
        "    return encoder_outputs, fw_st, bw_st\n",
        "\n",
        "  def _reduce_states(self, fw_st, bw_st):\n",
        "    \"\"\"Add to the graph a linear layer to reduce the encoder's final FW and BW state into a single initial state for the decoder. This is needed because the encoder is bidirectional but the decoder is not.\n",
        "    Args:\n",
        "      fw_st: LSTMStateTuple with hidden_dim units.\n",
        "      bw_st: LSTMStateTuple with hidden_dim units.\n",
        "    Returns:\n",
        "      state: LSTMStateTuple with hidden_dim units.\n",
        "    \"\"\"\n",
        "    enc_hidden_dim = self._hps.enc_hidden_dim\n",
        "    dec_hidden_dim = self._hps.dec_hidden_dim\n",
        "\n",
        "    with tf.variable_scope('reduce_final_st'):\n",
        "\n",
        "      # Define weights and biases to reduce the cell and reduce the state\n",
        "      w_reduce_c = tf.get_variable('w_reduce_c', [enc_hidden_dim * 2, dec_hidden_dim], dtype=tf.float32, initializer=self.trunc_norm_init)\n",
        "      w_reduce_h = tf.get_variable('w_reduce_h', [enc_hidden_dim * 2, dec_hidden_dim], dtype=tf.float32, initializer=self.trunc_norm_init)\n",
        "      bias_reduce_c = tf.get_variable('bias_reduce_c', [dec_hidden_dim], dtype=tf.float32, initializer=self.trunc_norm_init)\n",
        "      bias_reduce_h = tf.get_variable('bias_reduce_h', [dec_hidden_dim], dtype=tf.float32, initializer=self.trunc_norm_init)\n",
        "\n",
        "      # Apply linear layer\n",
        "      old_c = tf.concat(axis=1, values=[fw_st.c, bw_st.c]) # Concatenation of fw and bw cell\n",
        "      old_h = tf.concat(axis=1, values=[fw_st.h, bw_st.h]) # Concatenation of fw and bw state\n",
        "      new_c = tf.nn.relu(tf.matmul(old_c, w_reduce_c) + bias_reduce_c) # Get new cell from old cell\n",
        "      new_h = tf.nn.relu(tf.matmul(old_h, w_reduce_h) + bias_reduce_h) # Get new state from old state\n",
        "      return tf.nn.rnn_cell.LSTMStateTuple(new_c, new_h) # Return new cell and state\n",
        "\n",
        "  def _add_decoder(self, emb_dec_inputs, embedding):\n",
        "    \"\"\"Add attention decoder to the graph. In train or eval mode, you call this once to get output on ALL steps. In decode (beam search) mode, you call this once for EACH decoder step.\n",
        "    Args:\n",
        "      emb_dec_inputs: inputs to the decoder (word embeddings). A list of tensors shape (batch_size, emb_dim)\n",
        "      embedding: embedding matrix (vocab_size, emb_dim)\n",
        "    Returns:\n",
        "      outputs: List of tensors; the outputs of the decoder\n",
        "      out_state: The final state of the decoder\n",
        "      attn_dists: A list of tensors; the attention distributions\n",
        "      p_gens: A list of tensors shape (batch_size, 1); the generation probabilities\n",
        "      coverage: A tensor, the current coverage vector\n",
        "    \"\"\"\n",
        "    hps = self._hps\n",
        "    cell = tf.nn.rnn_cell.LSTMCell(hps.dec_hidden_dim, state_is_tuple=True, initializer=self.rand_unif_init)\n",
        "\n",
        "    prev_coverage = self.prev_coverage if (hps.mode==\"decode\" and hps.coverage) else None # In decode mode, we run attention_decoder one step at a time and so need to pass in the previous step's coverage vector each time\n",
        "    prev_decoder_outputs = self.prev_decoder_outputs if (hps.intradecoder and hps.mode==\"decode\") else tf.stack([],axis=0)\n",
        "    prev_encoder_es = self.prev_encoder_es if (hps.use_temporal_attention and hps.mode==\"decode\") else tf.stack([],axis=0)\n",
        "    return attention_decoder(hps,\n",
        "      self._vocab.size(),\n",
        "      self._max_art_oovs,\n",
        "      self._enc_batch_extend_vocab,\n",
        "      emb_dec_inputs,\n",
        "      self._target_batch,\n",
        "      self._dec_in_state,\n",
        "      self._enc_states,\n",
        "      self._enc_padding_mask,\n",
        "      self._dec_padding_mask,\n",
        "      cell,\n",
        "      embedding,\n",
        "      self._sampling_probability if FLAGS.scheduled_sampling else 0,\n",
        "      self._alpha if FLAGS.E2EBackProp else 0,\n",
        "      self._vocab.word2id(UNKNOWN_TOKEN),\n",
        "      initial_state_attention=(hps.mode==\"decode\"),\n",
        "      pointer_gen=hps.pointer_gen,\n",
        "      use_coverage=hps.coverage,\n",
        "      prev_coverage=prev_coverage,\n",
        "      prev_decoder_outputs=prev_decoder_outputs,\n",
        "      prev_encoder_es = prev_encoder_es)\n",
        "\n",
        "  def _add_emb_vis(self, embedding_var):\n",
        "    \"\"\"Do setup so that we can view word embedding visualization in Tensorboard, as described here:\n",
        "    https://www.tensorflow.org/get_started/embedding_viz\n",
        "    Make the vocab metadata file, then make the projector config file pointing to it.\"\"\"\n",
        "    train_dir = os.path.join(FLAGS.log_root, \"train\")\n",
        "    vocab_metadata_path = os.path.join(train_dir, \"vocab_metadata.tsv\")\n",
        "    self._vocab.write_metadata(vocab_metadata_path) # write metadata file\n",
        "    summary_writer = tf.summary.FileWriter(train_dir)\n",
        "    config = projector.ProjectorConfig()\n",
        "    embedding = config.embeddings.add()\n",
        "    embedding.tensor_name = embedding_var.name\n",
        "    embedding.metadata_path = vocab_metadata_path\n",
        "    projector.visualize_embeddings(summary_writer, config)\n",
        "\n",
        "  def discount_rewards(self, r):\n",
        "    \"\"\" take a list of size max_dec_step * (batch_size, k) and return a list of the same size \"\"\"\n",
        "    discounted_r = []\n",
        "    running_add = tf.constant(0, tf.float32)\n",
        "    for t in reversed(range(0, len(r))):\n",
        "      running_add = running_add * self._hps.gamma + r[t] # rd_t = r_t + gamma * r_{t+1}\n",
        "      discounted_r.append(running_add)\n",
        "    discounted_r = tf.stack(discounted_r[::-1]) # (max_dec_step, batch_size, k)\n",
        "    normalized_discounted_r = tf.nn.l2_normalize(discounted_r, axis=0)\n",
        "    return tf.unstack(normalized_discounted_r) # list of max_dec_step * (batch_size, k)\n",
        "\n",
        "  def intermediate_rewards(self, r):\n",
        "    \"\"\" take a list of size max_dec_step * (batch_size, k) and return a list of the same size\n",
        "        uses the intermediate reward as proposed by: R_t = r_t - r_{t-1} \"\"\"\n",
        "    intermediate_r = []\n",
        "    intermediate_r.append(r[0])\n",
        "    for t in range(1, len(r)):\n",
        "      intermediate_r.append(r[t]-r[t-1])\n",
        "    return intermediate_r # list of max_dec_step * (batch_size, k)\n",
        "\n",
        "  def _add_seq2seq(self):\n",
        "    \"\"\"Add the whole sequence-to-sequence model to the graph.\"\"\"\n",
        "    hps = self._hps\n",
        "    vsize = self._vocab.size() # size of the vocabulary\n",
        "\n",
        "    with tf.variable_scope('seq2seq'):\n",
        "      # Some initializers\n",
        "      self.rand_unif_init = tf.random_uniform_initializer(-hps.rand_unif_init_mag, hps.rand_unif_init_mag, seed=123)\n",
        "      self.trunc_norm_init = tf.truncated_normal_initializer(stddev=hps.trunc_norm_init_std)\n",
        "\n",
        "      # Add embedding matrix (shared by the encoder and decoder inputs)\n",
        "      with tf.variable_scope('embedding'):\n",
        "        if FLAGS.embedding != \"\":\n",
        "          embedding = tf.Variable(self.embedding_place)\n",
        "        else:\n",
        "          embedding = tf.get_variable('embedding', [vsize, hps.emb_dim], dtype=tf.float32, initializer=self.trunc_norm_init)\n",
        "        ##if hps.mode==\"train\": self._add_emb_vis(embedding) # add to tensorboard\n",
        "        emb_enc_inputs = tf.nn.embedding_lookup(embedding, self._enc_batch) # tensor with shape (batch_size, max_enc_steps, emb_size)\n",
        "        emb_dec_inputs = [tf.nn.embedding_lookup(embedding, x) for x in tf.unstack(self._dec_batch, axis=1)] # list length max_dec_steps containing shape (batch_size, emb_size)\n",
        "\n",
        "      # Add the encoder.\n",
        "      enc_outputs, fw_st, bw_st = self._add_encoder(emb_enc_inputs, self._enc_lens)\n",
        "      self._enc_states = enc_outputs\n",
        "\n",
        "      # Our encoder is bidirectional and our decoder is unidirectional so we need to reduce the final encoder hidden state to the right size to be the initial decoder hidden state\n",
        "      self._dec_in_state = self._reduce_states(fw_st, bw_st)\n",
        "\n",
        "      # Add the decoder.\n",
        "      with tf.variable_scope('decoder'):\n",
        "        (self.decoder_outputs, self._dec_out_state, self.attn_dists, self.p_gens, self.coverage, self.vocab_scores,\n",
        "         self.final_dists, self.samples, self.greedy_search_samples, self.temporal_es,\n",
        "         self.sampling_rewards, self.greedy_rewards) = self._add_decoder(emb_dec_inputs, embedding)\n",
        "\n",
        "      if FLAGS.use_discounted_rewards and hps.rl_training and hps.mode in ['train', 'eval']:\n",
        "        # Get the sampled and greedy sentence from model output\n",
        "        # self.samples: (max_dec_steps, batch_size, k)\n",
        "        self.sampling_discounted_rewards = tf.stack(self.discount_rewards(tf.unstack(self.sampling_rewards))) # list of max_dec_steps * (batch_size, k)\n",
        "        self.greedy_discounted_rewards = tf.stack(self.discount_rewards(tf.unstack(self.greedy_rewards))) # list of max_dec_steps * (batch_size, k)\n",
        "      elif FLAGS.use_intermediate_rewards and hps.rl_training and hps.mode in ['train', 'eval']:\n",
        "        # Get the sampled and greedy sentence from model output\n",
        "        # self.samples: (max_dec_steps, batch_size, k)\n",
        "        self.sampling_discounted_rewards = tf.stack(self.intermediate_rewards(tf.unstack(self.sampling_rewards))) # list of max_dec_steps * (batch_size, k)\n",
        "        self.greedy_discounted_rewards = tf.stack(self.intermediate_rewards(tf.unstack(self.greedy_rewards))) # list of max_dec_steps * (batch_size, k)\n",
        "      elif hps.ac_training and hps.mode in ['train', 'eval']:\n",
        "        # Get the sampled and greedy sentence from model output\n",
        "        self.sampled_sentences = tf.transpose(tf.stack(self.samples), perm=[1,2,0]) # (batch_size, k, <=max_dec_steps) word indices\n",
        "        self.greedy_search_sentences = tf.transpose(tf.stack(self.greedy_search_samples), perm=[1,2,0]) # (batch_size, k, <=max_dec_steps) word indices\n",
        "\n",
        "    if hps.mode == \"decode\":\n",
        "      # We run decode beam search mode one decoder step at a time\n",
        "      assert len(self.final_dists)==1 # final_dists is a singleton list containing shape (batch_size, extended_vsize)\n",
        "      self.final_dists = self.final_dists[0]\n",
        "      topk_probs, self._topk_ids = tf.nn.top_k(self.final_dists, hps.batch_size*2) # take the k largest probs. note batch_size=beam_size in decode mode\n",
        "      self._topk_log_probs = tf.log(topk_probs)\n",
        "\n",
        "  def _add_shared_loss_op(self):\n",
        "    # Calculate the loss\n",
        "    with tf.variable_scope('shared_loss'):\n",
        "      # Calculate the loss per step\n",
        "      # This is fiddly; we use tf.gather_nd to pick out the probabilities of the gold target words\n",
        "      #### added by yaserkl@vt.edu: we just calculate these to monitor pgen_loss throughout time\n",
        "      loss_per_step = [] # will be list length max_dec_steps containing shape (batch_size)\n",
        "      batch_nums = tf.range(0, limit=self._hps.batch_size) # shape (batch_size)\n",
        "      for dec_step, dist in enumerate(self.final_dists):\n",
        "        targets = self._target_batch[:,dec_step] # The indices of the target words. shape (batch_size)\n",
        "        indices = tf.stack( (batch_nums, targets), axis=1) # shape (batch_size, 2)\n",
        "        gold_probs = tf.gather_nd(dist, indices) # shape (batch_size). prob of correct words on this step\n",
        "        losses = -tf.log(gold_probs)\n",
        "        loss_per_step.append(losses)\n",
        "      self._pgen_loss = _mask_and_avg(loss_per_step, self._dec_padding_mask)\n",
        "      self.variable_summaries('pgen_loss', self._pgen_loss)\n",
        "      # Adding Q-Estimation to CE loss in Actor-Critic Model\n",
        "      if self._hps.ac_training:\n",
        "        # Calculating Actor-Critic loss\n",
        "        # Here, we multiple the Q-estimation for each token to its respective probability\n",
        "        loss_per_step = [] # will be list length k each containing a list of shape <=max_dec_steps which each has the shape (batch_size)\n",
        "        q_loss_per_step = [] # will be list length k each containing a list of shape <=max_dec_steps which each has the shape (batch_size)\n",
        "        batch_nums = tf.range(0, limit=self._hps.batch_size) # shape (batch_size)\n",
        "        unstacked_q = tf.unstack(self._q_estimates, axis =1) # list of k with size (batch_size, <=max_dec_steps, vsize_extended)\n",
        "        for sample_id in range(self._hps.k):\n",
        "          loss_per_sample = [] # length <=max_dec_steps of batch_sizes\n",
        "          q_loss_per_sample = [] # length <=max_dec_steps of batch_sizes\n",
        "          q_val_per_sample = tf.unstack(unstacked_q[sample_id], axis =1) # list of <=max_dec_step (batch_size, vsize_extended)\n",
        "          for dec_step, (dist, q_value) in enumerate(zip(self.final_dists, q_val_per_sample)):\n",
        "            targets = tf.squeeze(self.samples[dec_step][:,sample_id]) # The indices of the sampled words. shape (batch_size)\n",
        "            indices = tf.stack((batch_nums, targets), axis=1) # shape (batch_size, 2)\n",
        "            gold_probs = tf.gather_nd(dist, indices) # shape (batch_size). prob of correct words on this step\n",
        "            losses = -tf.log(gold_probs)\n",
        "            dist_q_val = -tf.log(dist) * q_value\n",
        "            q_losses = tf.gather_nd(dist_q_val, indices) # shape (batch_size). prob of correct words on this step\n",
        "            loss_per_sample.append(losses)\n",
        "            q_loss_per_sample.append(q_losses)\n",
        "          loss_per_step.append(loss_per_sample)\n",
        "          q_loss_per_step.append(q_loss_per_sample)\n",
        "        with tf.variable_scope('reinforce_loss'):\n",
        "          #### this is the actual loss\n",
        "          self._rl_avg_logprobs = tf.reduce_mean([_mask_and_avg(loss_per_sample, self._dec_padding_mask) for loss_per_sample in loss_per_step])\n",
        "          self._rl_loss = tf.reduce_mean([_mask_and_avg(q_loss_per_sample, self._dec_padding_mask) for q_loss_per_sample in q_loss_per_step])\n",
        "          # Eq. 34 in https://arxiv.org/pdf/1805.09461.pdf\n",
        "          self._reinforce_shared_loss = self._eta * self._rl_loss + (tf.constant(1.,dtype=tf.float32) - self._eta) * self._pgen_loss # equation 16 in https://arxiv.org/pdf/1705.04304.pdf\n",
        "          #### the following is only for monitoring purposes\n",
        "          self.variable_summaries('reinforce_avg_logprobs', self._rl_avg_logprobs)\n",
        "          self.variable_summaries('reinforce_loss', self._rl_loss)\n",
        "          self.variable_summaries('reinforce_shared_loss', self._reinforce_shared_loss)\n",
        "\n",
        "      # Adding Self-Critic Reward to CE loss in Policy-Gradient Model\n",
        "      if self._hps.rl_training:\n",
        "        #### Calculating the reinforce loss according to Eq. 15 in https://arxiv.org/pdf/1705.04304.pdf\n",
        "        loss_per_step = [] # will be list length max_dec_steps*k containing shape (batch_size)\n",
        "        rl_loss_per_step = [] # will be list length max_dec_steps*k containing shape (batch_size)\n",
        "        batch_nums = tf.range(0, limit=self._hps.batch_size) # shape (batch_size)\n",
        "        self._sampled_rouges = []\n",
        "        self._greedy_rouges = []\n",
        "        self._reward_diff = []\n",
        "        for _ in range(self._hps.k):\n",
        "          if FLAGS.use_discounted_rewards or FLAGS.use_intermediate_rewards:\n",
        "            self._sampled_rouges.append(self.sampling_discounted_rewards[:, :, _]) # shape (max_enc_steps, batch_size)\n",
        "            self._greedy_rouges.append(self.greedy_discounted_rewards[:, :, _]) # shape (max_enc_steps, batch_size)\n",
        "          else:\n",
        "            # use the reward of last step, since we use the reward of the whole sentence in this case\n",
        "            self._sampled_rouges.append(self.sampling_rewards[:, _]) # shape (batch_size)\n",
        "            self._greedy_rouges.append(self.greedy_rewards[:, _]) # shape (batch_size)\n",
        "          if FLAGS.self_critic:\n",
        "            self._reward_diff.append(self._greedy_rouges[_]-self._sampled_rouges[_])\n",
        "          else:\n",
        "            self._reward_diff.append(self._sampled_rouges[_])\n",
        "        for dec_step, dist in enumerate(self.final_dists):\n",
        "          _targets = self.samples[dec_step] # The indices of the sampled words. shape (batch_size, k)\n",
        "          for _k, targets in enumerate(tf.unstack(_targets,axis=1)): # list of k samples of size (batch_size)\n",
        "            indices = tf.stack( (batch_nums, targets), axis=1) # shape (batch_size, 2)\n",
        "            gold_probs = tf.gather_nd(dist, indices) # shape (batch_size). prob of correct words on this step\n",
        "            losses = -tf.log(gold_probs)\n",
        "            loss_per_step.append(losses)\n",
        "            # Equation 15 in https://arxiv.org/pdf/1705.04304.pdf\n",
        "            # Equal reward for all tokens\n",
        "            if FLAGS.use_discounted_rewards or FLAGS.use_intermediate_rewards:\n",
        "              rl_losses = -tf.log(gold_probs) * self._reward_diff[_k][dec_step, :]  # positive values\n",
        "            else:\n",
        "              rl_losses = -tf.log(gold_probs) * self._reward_diff[_k] # positive values\n",
        "            rl_loss_per_step.append(rl_losses)\n",
        "\n",
        "        # new size: (k, max_dec_steps, batch_size)\n",
        "        rl_loss_per_step = tf.unstack(\n",
        "          tf.transpose(tf.reshape(rl_loss_per_step, [-1, self._hps.k, self._hps.batch_size]),perm=[1,0,2]))\n",
        "        loss_per_step = tf.unstack(\n",
        "          tf.transpose(tf.reshape(loss_per_step, [-1, self._hps.k, self._hps.batch_size]), perm=[1, 0, 2]))\n",
        "\n",
        "        if FLAGS.use_intermediate_rewards:\n",
        "          self._sampled_rouges = tf.reduce_sum(self._sampled_rouges, axis=1) # shape (k, batch_size)\n",
        "          self._greedy_rouges = tf.reduce_sum(self._greedy_rouges, axis=1) # shape (k, batch_size)\n",
        "          self._reward_diff = tf.reduce_sum(self._reward_diff, axis=1) # shape (k, batch_size)\n",
        "\n",
        "        with tf.variable_scope('reinforce_loss'):\n",
        "          self._rl_avg_logprobs = []\n",
        "          self._rl_loss = []\n",
        "\n",
        "          for _k in range(self._hps.k):\n",
        "            self._rl_avg_logprobs.append(_mask_and_avg(tf.unstack(loss_per_step[_k]), self._dec_padding_mask))\n",
        "            self._rl_loss.append(_mask_and_avg(tf.unstack(tf.reshape(rl_loss_per_step[_k], [self._hps.max_dec_steps, self._hps.batch_size])), self._dec_padding_mask))\n",
        "\n",
        "          self._rl_avg_logprobs = tf.reduce_mean(self._rl_avg_logprobs)\n",
        "          self._rl_loss = tf.reduce_mean(self._rl_loss)\n",
        "          # We multiply the ROUGE difference of sampling vs greedy sentence to the loss of all tokens in the sequence\n",
        "          # Eq. 16 in https://arxiv.org/pdf/1705.04304.pdf and Eq. 34 in https://arxiv.org/pdf/1805.09461.pdf\n",
        "          self._reinforce_shared_loss = self._eta * self._rl_loss + (tf.constant(1.,dtype=tf.float32) - self._eta) * self._pgen_loss\n",
        "          #### the following is only for monitoring purposes\n",
        "          self.variable_summaries('reinforce_avg_logprobs', self._rl_avg_logprobs)\n",
        "          self.variable_summaries('reinforce_loss', self._rl_loss)\n",
        "          self.variable_summaries('reinforce_sampled_r_value', tf.reduce_mean(self._sampled_rouges))\n",
        "          self.variable_summaries('reinforce_greedy_r_value', tf.reduce_mean(self._greedy_rouges))\n",
        "          self.variable_summaries('reinforce_r_diff', tf.reduce_mean(self._reward_diff))\n",
        "          self.variable_summaries('reinforce_shared_loss', self._reinforce_shared_loss)\n",
        "\n",
        "      # Calculate coverage loss from the attention distributions\n",
        "      if self._hps.coverage:\n",
        "        with tf.variable_scope('coverage_loss'):\n",
        "          self._coverage_loss = _coverage_loss(self.attn_dists, self._dec_padding_mask)\n",
        "          self.variable_summaries('coverage_loss', self._coverage_loss)\n",
        "        if self._hps.rl_training or self._hps.ac_training:\n",
        "          with tf.variable_scope('reinforce_loss'):\n",
        "            self._reinforce_cov_total_loss = self._reinforce_shared_loss + self._hps.cov_loss_wt * self._coverage_loss\n",
        "            self.variable_summaries('reinforce_coverage_loss', self._reinforce_cov_total_loss)\n",
        "        if self._hps.pointer_gen:\n",
        "          self._pointer_cov_total_loss = self._pgen_loss + self._hps.cov_loss_wt * self._coverage_loss\n",
        "          self.variable_summaries('pointer_coverage_loss', self._pointer_cov_total_loss)\n",
        "\n",
        "  def _add_shared_train_op(self):\n",
        "    \"\"\"Sets self._train_op, the op to run for training.\"\"\"\n",
        "    # Take gradients of the trainable variables w.r.t. the loss function to minimize\n",
        "    if self._hps.rl_training or self._hps.ac_training:\n",
        "      loss_to_minimize = self._reinforce_shared_loss\n",
        "      if self._hps.coverage:\n",
        "        loss_to_minimize = self._reinforce_cov_total_loss\n",
        "    else:\n",
        "      loss_to_minimize = self._pgen_loss\n",
        "      if self._hps.coverage:\n",
        "        loss_to_minimize = self._pointer_cov_total_loss\n",
        "\n",
        "    tvars = tf.trainable_variables()\n",
        "    gradients = tf.gradients(loss_to_minimize, tvars, aggregation_method=tf.AggregationMethod.EXPERIMENTAL_TREE)\n",
        "\n",
        "    # Clip the gradients\n",
        "    with tf.device(\"/gpu:{}\".format(self._hps.gpu_num)):\n",
        "      grads, global_norm = tf.clip_by_global_norm(gradients, self._hps.max_grad_norm)\n",
        "\n",
        "    # Add a summary\n",
        "    tf.summary.scalar('global_norm', global_norm)\n",
        "\n",
        "    # Apply adagrad optimizer\n",
        "    optimizer = tf.train.AdagradOptimizer(self._hps.lr, initial_accumulator_value=self._hps.adagrad_init_acc)\n",
        "    with tf.device(\"/gpu:{}\".format(self._hps.gpu_num)):\n",
        "      self._shared_train_op = optimizer.apply_gradients(zip(grads, tvars), global_step=self.global_step, name='train_step')\n",
        "\n",
        "  def build_graph(self):\n",
        "    \"\"\"Add the placeholders, model, global step, train_op and summaries to the graph\"\"\"\n",
        "    tf.compat.v1.logging.info('Building graph...')\n",
        "    t0 = time.time()\n",
        "    self.global_step = tf.Variable(0, name='global_step', trainable=False)\n",
        "    self._add_placeholders()\n",
        "    with tf.device(\"/gpu:{}\".format(self._hps.gpu_num)):\n",
        "      self._add_seq2seq()\n",
        "      if self._hps.mode in ['train', 'eval']:\n",
        "        self._add_shared_loss_op()\n",
        "      if self._hps.mode == 'train':\n",
        "        self._add_shared_train_op()\n",
        "      self._summaries = tf.summary.merge_all()\n",
        "    t1 = time.time()\n",
        "    tf.compat.v1.logging.info('Time to build graph: %i seconds', t1 - t0)\n",
        "\n",
        "  def collect_dqn_transitions(self, sess, batch, step, max_art_oovs):\n",
        "    \"\"\"Get decoders' output and calculate reward at each decoding step, Q-function, value-function, and Advantage function.\n",
        "    Args:\n",
        "      sess: seq2seq model session\n",
        "      batch: current batch\n",
        "      step: training step\n",
        "      max_art_oovs: number of OOV tokens in current batch.\n",
        "    Returns:\n",
        "      transitions:\n",
        "        Experiences collected from decoders' outputs. (batch_size, k, max_dec_steps)\n",
        "    \"\"\"\n",
        "\n",
        "    feed_dict = self._make_feed_dict(batch)\n",
        "    if self._hps.fixed_eta:\n",
        "      feed_dict[self._eta] = self._hps.eta\n",
        "    else:\n",
        "      feed_dict[self._eta] = min(step * self._hps.eta,1.)\n",
        "    if self._hps.scheduled_sampling:\n",
        "      if self._hps.fixed_sampling_probability:\n",
        "        feed_dict[self._sampling_probability] = self._hps.sampling_probability\n",
        "      else:\n",
        "        feed_dict[self._sampling_probability] = min(step * self._hps.sampling_probability,1.) # linear decay function\n",
        "      ranges = [np.exp(float(step) * self._hps.alpha),np.finfo(np.float64).max] # to avoid overflow\n",
        "      feed_dict[self._alpha] = np.log(ranges[np.argmin(ranges)]) # linear decay function\n",
        "\n",
        "    vsize_extended = self._vocab.size() + max_art_oovs\n",
        "    if self._hps.calculate_true_q:\n",
        "      self.advantages = np.zeros((self._hps.batch_size, self._hps.k, self._hps.max_dec_steps, vsize_extended),dtype=np.float32) # (batch_size, k, <=max_dec_steps,vocab_size)\n",
        "      self.q_values = np.zeros((self._hps.batch_size, self._hps.k, self._hps.max_dec_steps, vsize_extended),dtype=np.float32) # (batch_size, k, <=max_dec_steps,vocab_size)\n",
        "      self.r_values = np.zeros((self._hps.batch_size, self._hps.k, self._hps.max_dec_steps, vsize_extended),dtype=np.float32) # (batch_size, k, <=max_dec_steps,vocab_size)\n",
        "      self.v_values = np.zeros((self._hps.batch_size, self._hps.k, self._hps.max_dec_steps),dtype=np.float32) # (batch_size, k, <=max_dec_steps)\n",
        "    else:\n",
        "      self.r_values = np.zeros((self._hps.batch_size, self._hps.k, self._hps.max_dec_steps),dtype=np.float32) # (batch_size, k, <=max_dec_steps)\n",
        "    to_return = {\n",
        "      'sampled_sentences': self.sampled_sentences,\n",
        "      'greedy_search_sentences': self.greedy_search_sentences,\n",
        "      'decoder_outputs': self.decoder_outputs,\n",
        "    }\n",
        "    # Run the seq2seq model to get the decoders' output.\n",
        "    ret_dict = sess.run(to_return, feed_dict)\n",
        "\n",
        "\n",
        "    # Calculating reward, Q, V, and A values\n",
        "    _t = time.time()\n",
        "    ### TODO: do it in parallel???\n",
        "    for _n, (sampled_sentence, greedy_search_sentence, target_sentence) in enumerate(zip(ret_dict['sampled_sentences'],ret_dict['greedy_search_sentences'], batch.target_batch)): # run batch_size time\n",
        "      _gts = target_sentence\n",
        "      for i in range(self._hps.k):\n",
        "        _ss = greedy_search_sentence[i] # reward is calculated over the best action through greedy search\n",
        "        if self._hps.calculate_true_q:\n",
        "          # Collect Reward, Q, V, and A only when we want to train DDQN using true Q-estimation\n",
        "          A, Q, V, R = self.caluclate_advantage_function(_ss, _gts, vsize_extended)\n",
        "          self.r_values[_n,i,:,:] = R\n",
        "          self.advantages[_n,i,:,:] = A\n",
        "          self.q_values[_n,i,:,:] = Q\n",
        "          self.v_values[_n,i,:] = V\n",
        "        else:\n",
        "          # if using DDQN estimates, we only need to calculate the reward and later on estimate Q values.\n",
        "          self.r_values[_n, i, :] = self.caluclate_single_reward(_ss, _gts) # len max_dec_steps\n",
        "    tf.compat.v1.logging.info('seconds for dqn collection: {}'.format(time.time()-_t))\n",
        "    trasitions = self.prepare_dqn_transitions(self._hps, ret_dict['decoder_outputs'], ret_dict['greedy_search_sentences'], vsize_extended)\n",
        "    return trasitions\n",
        "\n",
        "  def caluclate_advantage_function(self, _ss, _gts, vsize_extended):\n",
        "    \"\"\"Collect R, Q, V, and A for the given sequence of ground-truth and generated summary\n",
        "    Args:\n",
        "      _ss: A list of generated tokens (max_dec_steps) \n",
        "      _gts: A list of ground-truth tokens (max_dec_steps)\n",
        "      vsize_extended: size of the extended vocab, vocab_size + max_art_oovs\n",
        "    Returns:\n",
        "      R: Reward values (max_dec_steps, vsize_extended)\n",
        "      Q: Q-values (max_dec_steps, vsize_extended)\n",
        "      V: Value function (max_dec_steps, vsize_extended)\n",
        "      A: Advantage values (max_dec_steps, vsize_extended)\n",
        "      \n",
        "    \"\"\"\n",
        "\n",
        "    R = np.zeros((self._hps.max_dec_steps, vsize_extended)) # shape (max_dec_steps, vocab_size)\n",
        "    Q = np.zeros((self._hps.max_dec_steps, vsize_extended)) # shape (max_dec_steps, vocab_size)\n",
        "    for t in range(self._hps.max_dec_steps,0,-1):\n",
        "      R[t-1][:] = self.reward(t, _ss, _gts, vsize_extended)\n",
        "      # We find true Q-values.\n",
        "      # Eq. 30 in https://arxiv.org/pdf/1805.09461.pdf\n",
        "      try:\n",
        "        Q[t-1][:] = R[t-1][:] + self._hps.gamma * Q[t,:].max()\n",
        "      except:\n",
        "        Q[t-1][:] = R[t-1][:]\n",
        "\n",
        "    V = np.reshape(np.mean(Q,axis=1),[-1,1])\n",
        "\n",
        "    A = Q - V\n",
        "    return A, Q, np.squeeze(V), R\n",
        "\n",
        "  def caluclate_single_reward(self, _ss, _gts):\n",
        "    \"\"\"Calculate the reward based on the reference and summary\n",
        "    Args:\n",
        "      _ss: List of model-generated tokens of size max_dec_steps\n",
        "      _gts: List of ground-truth tokens of size max_dec_steps\n",
        "    Returns:\n",
        "      reward:\n",
        "        List of the collected reward for each decoding step.\n",
        "    \"\"\"\n",
        "\n",
        "    return [self.calc_reward(t, _ss,_gts) for t in range(1,self._hps.max_dec_steps+1)]\n",
        "\n",
        "  def prepare_dqn_transitions(self, hps, decoder_states, greedy_samples, vsize_extended):\n",
        "    \"\"\"Prepare the experiences for this batch\n",
        "    Args:\n",
        "      hps: model paramters\n",
        "      decoder_states: decode output states (max_dec_steps, batch_size, hidden_dim)\n",
        "      greedy_samples: set of tokens selected through greedy selection, list of size batch_size each contains\n",
        "      max_dec_steps tokens.\n",
        "    Returns:\n",
        "      transitions:\n",
        "        List of experiences collected for this batch (batch_size, k, max_dec_steps)\n",
        "    \"\"\"\n",
        "    # all variables must have the shape (batch_size, k, <=max_dec_steps, feature_len)\n",
        "    decoder_states = np.transpose(np.stack(decoder_states),[1,0,2]) # now of shape (batch_size, <=max_dec_steps, hidden_dim)\n",
        "    greedy_samples = np.stack(greedy_samples) # now of shape (batch_size, <=max_dec_steps)\n",
        "\n",
        "    dec_length = decoder_states.shape[1]\n",
        "    hidden_dim = decoder_states.shape[-1]\n",
        "\n",
        "    # modifying decoder state tensor to shape (batch_size, k, <=max_dec_steps, hidden_dim)\n",
        "    _decoder_states = np.expand_dims(decoder_states, 1)\n",
        "    _decoder_states = np.concatenate([_decoder_states] * hps.k, axis=1) # shape (batch_size, k, <=max_dec_steps, hidden_dim)\n",
        "    # TODO: if wanna use time as a categorical feature\n",
        "    #features = np.concatenate([self.times, _decoder_states], axis=-1) # shape (batch_size, k, <=max_dec_steps, hidden_dim + <=max_dec_steps)\n",
        "    features = _decoder_states # shape (batch_size, k, <=max_dec_steps, hidden_dim)\n",
        "\n",
        "    q_func = lambda i,k,t: self.q_values[i,k,t] # (vsize_extended)\n",
        "    zero_func = lambda i, k, t: np.zeros((vsize_extended))\n",
        "    raction_func = lambda i,k,t,action: self.r_values[i,k,t,action]\n",
        "    r_func = lambda i,k,t,action: self.r_values[i,k,t]\n",
        "\n",
        "    if self._hps.calculate_true_q:\n",
        "      # We use the true q_values that we calculated to train DQN network.\n",
        "      pass_q_func = q_func\n",
        "      pass_r_func = raction_func\n",
        "    else:\n",
        "      # We update the q_values later, after collecting the q_estimates from DQN network.\n",
        "      pass_q_func = zero_func\n",
        "      pass_r_func = r_func\n",
        "\n",
        "    transitions = [] # (h_t, w_t, h_{t+1}, r_t, q_t, done)\n",
        "    for i in range(self._hps.batch_size):\n",
        "      for k in range(self._hps.k):\n",
        "        for t in range(self._hps.max_dec_steps):\n",
        "          action = greedy_samples[i,k,t]\n",
        "          done = (t==(self._hps.max_dec_steps-1) or action==3) # 3 is the id for [STOP] in our vocabularity to stop decoding\n",
        "          state = features[i, k, t]\n",
        "          if done:\n",
        "            state_prime = np.zeros((features.shape[-1]))\n",
        "            action_prime = 3 # 3 is the id for [STOP] in our vocabularity to stop decoding\n",
        "          else:\n",
        "            state_prime = features[i,k,t+1]\n",
        "            action_prime = greedy_samples[i,k,t+1]\n",
        "          transitions.append(Transition(state, action, state_prime, action_prime, pass_r_func(i,k,t,action), pass_q_func(i,k,t), done))\n",
        "\n",
        "    return transitions\n",
        "\n",
        "  def calc_reward(self, _ss, _gts): # optimizing based on ROUGE-L\n",
        "    \"\"\"This function will calculate partial reward, meaning we calculate the reward using\n",
        "    reward_function(_ss[0:t], _gts). Therefore if we have the following two inputs:\n",
        "    _ss = [A, B, C, D, E]\n",
        "    _gts = [A, B, D, E, F]\n",
        "    and we want to collect the reward based on ROUGE_L at time t = 2, it will be as follows:\n",
        "    ROUGE_L([A, B, C, [UNK], [UNK]], [A, B, D, E, F])\n",
        "    Note that we replace all tokens for time t>2 with [UNK]\n",
        "    Args:\n",
        "      t: decoder time step\n",
        "      _ss: List of model-generated tokens of size max_dec_steps\n",
        "      _gts: List of ground-truth tokens of size max_dec_steps\n",
        "    Returns:\n",
        "      reward: The calculated reward \n",
        "    \"\"\"\n",
        "\n",
        "    summary = ' '.join([str(k) for k in _ss])\n",
        "    reference = ' '.join([str(k) for k in _gts])\n",
        "    reward = self.reward_function(reference, summary, self._hps.reward_function)\n",
        "    return reward\n",
        "\n",
        "  def reward(self, t, _ss, _gts, vsize_extended): # shape (vocab_size)\n",
        "    \"\"\" A wrapper for calculating the reward. \"\"\"\n",
        "    first_case = np.append(_ss[0:t],[0]) # our special character is '[UNK]' which has the id of 0 in our vocabulary\n",
        "    special_reward = self.calc_reward(first_case, _gts)\n",
        "    reward = [special_reward for _ in range(vsize_extended)]\n",
        "    # change the ground-truth reward\n",
        "    second_case = np.append(_ss[0:t],[_gts[t-1]])\n",
        "    reward[_gts[t-1]] = self.calc_reward(second_case, _gts)\n",
        "\n",
        "    return reward\n",
        "\n",
        "  def run_train_steps(self, sess, batch, step, q_estimates=None):\n",
        "    \"\"\" Run train steps\n",
        "    Args:\n",
        "      sess: seq2seq session\n",
        "      batch: current batch\n",
        "      step: training step\n",
        "      q_estimates = if using Actor-Critic model, this variable will feed\n",
        "      the Q-estimates collected from Critic and use it to update the model\n",
        "      loss\n",
        "    \"\"\"\n",
        "    feed_dict = self._make_feed_dict(batch)\n",
        "    if self._hps.ac_training or self._hps.rl_training:\n",
        "      if self._hps.fixed_eta:\n",
        "        feed_dict[self._eta] = self._hps.eta\n",
        "      else:\n",
        "        feed_dict[self._eta] = min(step * self._hps.eta, 1.)\n",
        "    if self._hps.scheduled_sampling:\n",
        "      if self._hps.fixed_sampling_probability:\n",
        "        feed_dict[self._sampling_probability] = self._hps.sampling_probability\n",
        "      else:\n",
        "        feed_dict[self._sampling_probability] = min(step * self._hps.sampling_probability, 1.) # linear decay function\n",
        "      ranges = [np.exp(float(step) * self._hps.alpha), np.finfo(np.float64).max] # to avoid overflow\n",
        "      feed_dict[self._alpha] = np.log(ranges[np.argmin(ranges)]) # linear decay function\n",
        "    if self._hps.ac_training:\n",
        "      self.q_estimates = q_estimates\n",
        "      feed_dict[self._q_estimates]= self.q_estimates\n",
        "    to_return = {\n",
        "        'train_op': self._shared_train_op,\n",
        "        'summaries': self._summaries,\n",
        "        'pgen_loss': self._pgen_loss,\n",
        "        'global_step': self.global_step,\n",
        "        'decoder_outputs': self.decoder_outputs\n",
        "    }\n",
        "\n",
        "    if self._hps.rl_training:\n",
        "      to_return['sampled_sentence_r_values'] = self._sampled_rouges\n",
        "      to_return['greedy_sentence_r_values'] = self._greedy_rouges\n",
        "\n",
        "    if self._hps.coverage:\n",
        "      to_return['coverage_loss'] = self._coverage_loss\n",
        "      if self._hps.rl_training or self._hps.ac_training:\n",
        "        to_return['reinforce_cov_total_loss']= self._reinforce_cov_total_loss\n",
        "      if self._hps.pointer_gen:\n",
        "        to_return['pointer_cov_total_loss'] = self._pointer_cov_total_loss\n",
        "    if self._hps.rl_training or self._hps.ac_training:\n",
        "      to_return['shared_loss']= self._reinforce_shared_loss\n",
        "      to_return['rl_loss']= self._rl_loss\n",
        "      to_return['rl_avg_logprobs']= self._rl_avg_logprobs\n",
        "\n",
        "    # We feed the collected reward and feed it back to model to update the loss\n",
        "    return sess.run(to_return, feed_dict)\n",
        "\n",
        "  def run_eval_step(self, sess, batch, step, q_estimates=None):\n",
        "    \"\"\" Run eval steps, same as training with difference that we don't update the loss, here\n",
        "    Args:\n",
        "      sess: seq2seq session\n",
        "      batch: current batch\n",
        "      step: training step\n",
        "      q_estimates = if using Actor-Critic model, this variable will feed\n",
        "      the Q-estimates collected from Critic and use it to update the model\n",
        "      loss\n",
        "    \"\"\"\n",
        "    feed_dict = self._make_feed_dict(batch)\n",
        "    if self._hps.ac_training or self._hps.rl_training:\n",
        "      if self._hps.fixed_eta:\n",
        "        feed_dict[self._eta] = self._hps.eta\n",
        "      else:\n",
        "        feed_dict[self._eta] = min(step * self._hps.eta,1.)\n",
        "    if self._hps.scheduled_sampling:\n",
        "      if self._hps.fixed_sampling_probability:\n",
        "        feed_dict[self._sampling_probability] = self._hps.sampling_probability\n",
        "      else:\n",
        "        feed_dict[self._sampling_probability] = min(step * self._hps.sampling_probability,1.) # linear decay function\n",
        "      ranges = [np.exp(float(step) * self._hps.alpha),np.finfo(np.float64).max] # to avoid overflow\n",
        "      feed_dict[self._alpha] = np.log(ranges[np.argmin(ranges)]) # linear decay function\n",
        "    if self._hps.ac_training:\n",
        "      self.q_estimates = q_estimates\n",
        "      feed_dict[self._q_estimates]= self.q_estimates\n",
        "    to_return = {\n",
        "        'summaries': self._summaries,\n",
        "        'pgen_loss': self._pgen_loss,\n",
        "        'global_step': self.global_step,\n",
        "        'decoder_outputs': self.decoder_outputs\n",
        "    }\n",
        "\n",
        "    if self._hps.rl_training:\n",
        "      to_return['sampled_sentence_r_values'] = self._sampled_rouges\n",
        "      to_return['greedy_sentence_r_values'] = self._greedy_rouges\n",
        "\n",
        "    if self._hps.coverage:\n",
        "      to_return['coverage_loss'] = self._coverage_loss\n",
        "      if self._hps.rl_training or self._hps.ac_training:\n",
        "        to_return['reinforce_cov_total_loss']= self._reinforce_cov_total_loss\n",
        "      if self._hps.pointer_gen:\n",
        "        to_return['pointer_cov_total_loss'] = self._pointer_cov_total_loss\n",
        "    if self._hps.rl_training or self._hps.ac_training:\n",
        "      to_return['shared_loss']= self._reinforce_shared_loss\n",
        "      to_return['rl_loss']= self._rl_loss\n",
        "      to_return['rl_avg_logprobs']= self._rl_avg_logprobs\n",
        "\n",
        "    # We feed the collected reward and feed it back to model to update the loss\n",
        "    return sess.run(to_return, feed_dict)\n",
        "\n",
        "  def run_encoder(self, sess, batch):\n",
        "    \"\"\"For beam search decoding. Run the encoder on the batch and return the encoder states and decoder initial state.\n",
        "    Args:\n",
        "      sess: Tensorflow session.\n",
        "      batch: Batch object that is the same example repeated across the batch (for beam search)\n",
        "    Returns:\n",
        "      enc_states: The encoder states. A tensor of shape [batch_size, <=max_enc_steps, 2*hidden_dim].\n",
        "      dec_in_state: A LSTMStateTuple of shape ([1,hidden_dim],[1,hidden_dim])\n",
        "    \"\"\"\n",
        "    feed_dict = self._make_feed_dict(batch, just_enc=True) # feed the batch into the placeholders\n",
        "    (enc_states, dec_in_state, global_step) = sess.run([self._enc_states, self._dec_in_state, self.global_step], feed_dict) # run the encoder\n",
        "\n",
        "    # dec_in_state is LSTMStateTuple shape ([batch_size,hidden_dim],[batch_size,hidden_dim])\n",
        "    # Given that the batch is a single example repeated, dec_in_state is identical across the batch so we just take the top row.\n",
        "    dec_in_state = tf.nn.rnn_cell.LSTMStateTuple(dec_in_state.c[0], dec_in_state.h[0])\n",
        "    return enc_states, dec_in_state\n",
        "\n",
        "  def decode_onestep(self, sess, batch, latest_tokens, enc_states, dec_init_states, prev_coverage, prev_decoder_outputs, prev_encoder_es):\n",
        "    \"\"\"For beam search decoding. Run the decoder for one step.\n",
        "    Args:\n",
        "      sess: Tensorflow session.\n",
        "      batch: Batch object containing single example repeated across the batch\n",
        "      latest_tokens: Tokens to be fed as input into the decoder for this timestep\n",
        "      enc_states: The encoder states.\n",
        "      dec_init_states: List of beam_size LSTMStateTuples; the decoder states from the previous timestep\n",
        "      prev_coverage: List of np arrays. The coverage vectors from the previous timestep. List of None if not using coverage.\n",
        "    Returns:\n",
        "      ids: top 2k ids. shape [beam_size, 2*beam_size]\n",
        "      probs: top 2k log probabilities. shape [beam_size, 2*beam_size]\n",
        "      new_states: new states of the decoder. a list length beam_size containing\n",
        "        LSTMStateTuples each of shape ([hidden_dim,],[hidden_dim,])\n",
        "      attn_dists: List length beam_size containing lists length attn_length.\n",
        "      p_gens: Generation probabilities for this step. A list length beam_size. List of None if in baseline mode.\n",
        "      new_coverage: Coverage vectors for this step. A list of arrays. List of None if coverage is not turned on.\n",
        "    \"\"\"\n",
        "\n",
        "    beam_size = len(dec_init_states)\n",
        "\n",
        "    # Turn dec_init_states (a list of LSTMStateTuples) into a single LSTMStateTuple for the batch\n",
        "    cells = [np.expand_dims(state.c, axis=0) for state in dec_init_states]\n",
        "    hiddens = [np.expand_dims(state.h, axis=0) for state in dec_init_states]\n",
        "    new_c = np.concatenate(cells, axis=0)  # shape [batch_size,hidden_dim]\n",
        "    new_h = np.concatenate(hiddens, axis=0)  # shape [batch_size,hidden_dim]\n",
        "    new_dec_in_state = tf.nn.rnn_cell.LSTMStateTuple(new_c, new_h)\n",
        "\n",
        "    feed = {\n",
        "        self._enc_states: enc_states,\n",
        "        self._enc_padding_mask: batch.enc_padding_mask,\n",
        "        self._dec_in_state: new_dec_in_state,\n",
        "        self._dec_batch: np.transpose(np.array([latest_tokens])),\n",
        "        self._dec_padding_mask: np.ones((beam_size,1),dtype=np.float32)\n",
        "    }\n",
        "\n",
        "    to_return = {\n",
        "      \"ids\": self._topk_ids,\n",
        "      \"probs\": self._topk_log_probs,\n",
        "      \"states\": self._dec_out_state,\n",
        "      \"attn_dists\": self.attn_dists,\n",
        "      \"final_dists\": self.final_dists\n",
        "    }\n",
        "\n",
        "    if FLAGS.pointer_gen:\n",
        "      feed[self._enc_batch_extend_vocab] = batch.enc_batch_extend_vocab\n",
        "      feed[self._max_art_oovs] = batch.max_art_oovs\n",
        "      to_return['p_gens'] = self.p_gens\n",
        "\n",
        "    if self._hps.coverage:\n",
        "      feed[self.prev_coverage] = np.stack(prev_coverage, axis=0)\n",
        "      to_return['coverage'] = self.coverage\n",
        "\n",
        "    if FLAGS.ac_training or FLAGS.intradecoder:\n",
        "      to_return['output']=self.decoder_outputs\n",
        "    if FLAGS.intradecoder:\n",
        "      feed[self.prev_decoder_outputs]= prev_decoder_outputs\n",
        "    if FLAGS.use_temporal_attention:\n",
        "      to_return['temporal_e'] = self.temporal_es\n",
        "      feed[self.prev_encoder_es] = prev_encoder_es\n",
        "\n",
        "    results = sess.run(to_return, feed_dict=feed) # run the decoder step\n",
        "\n",
        "    # Convert results['states'] (a single LSTMStateTuple) into a list of LSTMStateTuple -- one for each hypothesis\n",
        "    new_states = [tf.nn.rnn_cell.LSTMStateTuple(results['states'].c[i, :], results['states'].h[i, :]) for i in range(beam_size)]\n",
        "\n",
        "    # Convert singleton list containing a tensor to a list of k arrays\n",
        "    assert len(results['attn_dists'])==1\n",
        "    attn_dists = results['attn_dists'][0].tolist()\n",
        "    final_dists = results['final_dists'][0].tolist()\n",
        "\n",
        "    if FLAGS.pointer_gen:\n",
        "      # Convert singleton list containing a tensor to a list of k arrays\n",
        "      assert len(results['p_gens'])==1\n",
        "      p_gens = results['p_gens'][0].tolist()\n",
        "    else:\n",
        "      p_gens = [None for _ in range(beam_size)]\n",
        "\n",
        "    if FLAGS.ac_training or FLAGS.intradecoder:\n",
        "      output = results['output'][0] # used for calculating the intradecoder at later steps and for calcualting q-estimate in Actor-Critic training.\n",
        "    else:\n",
        "      output = None\n",
        "    if FLAGS.use_temporal_attention:\n",
        "      temporal_e = results['temporal_e'][0] # used for calculating the attention at later steps\n",
        "    else:\n",
        "      temporal_e = None\n",
        "\n",
        "    # Convert the coverage tensor to a list length k containing the coverage vector for each hypothesis\n",
        "    if FLAGS.coverage:\n",
        "      new_coverage = results['coverage'].tolist()\n",
        "      assert len(new_coverage) == beam_size\n",
        "    else:\n",
        "      new_coverage = [None for _ in range(beam_size)]\n",
        "\n",
        "    return results['ids'], results['probs'], new_states, attn_dists, final_dists, p_gens, new_coverage, output, temporal_e\n",
        "\n",
        "def _mask_and_avg(values, padding_mask):\n",
        "  \"\"\"Applies mask to values then returns overall average (a scalar)\n",
        "  Args:\n",
        "    values: a list length max_dec_steps containing arrays shape (batch_size).\n",
        "    padding_mask: tensor shape (batch_size, max_dec_steps) containing 1s and 0s.\n",
        "  Returns:\n",
        "    a scalar\n",
        "  \"\"\"\n",
        "\n",
        "  dec_lens = tf.reduce_sum(padding_mask, axis=1) # shape batch_size. float32\n",
        "  values_per_step = [v * padding_mask[:,dec_step] for dec_step,v in enumerate(values)] # list of k\n",
        "  values_per_ex = sum(values_per_step)/dec_lens # shape (batch_size); normalized value for each batch member\n",
        "  return tf.reduce_mean(values_per_ex) # overall average\n",
        "\n",
        "def _coverage_loss(attn_dists, padding_mask):\n",
        "  \"\"\"Calculates the coverage loss from the attention distributions.\n",
        "  Args:\n",
        "    attn_dists: The attention distributions for each decoder timestep. A list length max_dec_steps containing shape (batch_size, attn_length)\n",
        "    padding_mask: shape (batch_size, max_dec_steps).\n",
        "  Returns:\n",
        "    coverage_loss: scalar\n",
        "  \"\"\"\n",
        "  coverage = tf.zeros_like(attn_dists[0]) # shape (batch_size, attn_length). Initial coverage is zero.\n",
        "  covlosses = [] # Coverage loss per decoder timestep. Will be list length max_dec_steps containing shape (batch_size).\n",
        "  for a in attn_dists:\n",
        "    covloss = tf.reduce_sum(tf.minimum(a, coverage), [1]) # calculate the coverage loss for this step\n",
        "    covlosses.append(covloss)\n",
        "    coverage += a # update the coverage vector\n",
        "  coverage_loss = _mask_and_avg(covlosses, padding_mask)\n",
        "  return coverage_loss"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5lP9ZHFMLlD"
      },
      "source": [
        "### Replay Buffer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfIt9CWWMN1n"
      },
      "source": [
        "try:\n",
        "  import queue\n",
        "except:\n",
        "  import Queue as queue\n",
        "from random import shuffle\n",
        "from random import seed\n",
        "seed(123)\n",
        "from threading import Thread\n",
        "import numpy as np\n",
        "import time\n",
        "# import tensorflow as tf\n",
        "try:\n",
        "  import Queue as Q  # ver. < 3.0\n",
        "except ImportError:\n",
        "  import queue as Q\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "PriorityQueue = Q.PriorityQueue\n",
        "\n",
        "\n",
        "# Custom prioriy queue that is able to clear the queue once it is full\n",
        "# and cut it to half. Therefore, everytime size of buffer is dqn_replay_buffer_size,\n",
        "# we will keep half of the most valuable states and remove the rest to provide\n",
        "# space for new experiences\n",
        "class CustomQueue(PriorityQueue):\n",
        "  '''\n",
        "  A custom queue subclass that provides a :meth:`clear` method.\n",
        "  '''\n",
        "  def __init__(self, size):\n",
        "    PriorityQueue.__init__(self, size)\n",
        "\n",
        "  def clear(self):\n",
        "    '''\n",
        "    Clears all items from the queue.\n",
        "    '''\n",
        "    with self.mutex:\n",
        "      unfinished = self.unfinished_tasks - len(self.queue)\n",
        "      if unfinished <= 0:\n",
        "        if unfinished < 0:\n",
        "          raise ValueError('task_done() called too many times')\n",
        "        self.all_tasks_done.notify_all()\n",
        "      self.queue = self.queue[0:len(self.queue)/2]\n",
        "      self.unfinished_tasks = unfinished + len(self.queue)\n",
        "      self.not_full.notify_all()\n",
        "\n",
        "  def isempty(self):\n",
        "    with self.mutex:\n",
        "      return len(self.queue) == 0\n",
        "\n",
        "  def isfull(self):\n",
        "    with self.mutex:\n",
        "      return len(self.queue) == self.maxsize\n",
        "\n",
        "class Transition(object):\n",
        "  \"\"\"\n",
        "  A class for holding the experiences collected from seq2seq model\n",
        "  \"\"\"\n",
        "  def __init__(self, state, action, state_prime, action_prime, reward, q_value, done):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        state: current decoder output state\n",
        "        action: the greedy action selected from current decoder output\n",
        "        state_prime: next decoder output state\n",
        "        reward: reward of the greedy action selected\n",
        "        q_value: Q-value of the greedy action selected\n",
        "        done: whether we reached End-Of-Sequence or not\n",
        "    \"\"\"\n",
        "    self.state = state # size: dqn_input_feature_len\n",
        "    self.action = action # size: 1\n",
        "    self.state_prime = state_prime # size: dqn_input_feature_len\n",
        "    self.action_prime = action_prime\n",
        "    self.reward = reward # size: vocab_size\n",
        "    self.q_value = q_value # size: vocab_size\n",
        "    self.done = done # true/false\n",
        "\n",
        "  def __cmp__(self, item):\n",
        "    \"\"\" PriorityQueue uses this functino to sort the rewards\n",
        "      Args:\n",
        "        We sort the queue such that items with higher rewards are in the head of max-heap\n",
        "    \"\"\"\n",
        "    return cmp(item.reward, self.reward) # bigger numbers have more priority\n",
        "\n",
        "class ReplayBatch(object):\n",
        "  \"\"\" A class for creating batches required for training DDQN. \"\"\"\n",
        "\n",
        "  def __init__(self, hps, example_list, dqn_batch_size, use_state_prime = False, max_art_oovs = 0):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "       hps: seq2seq model parameters\n",
        "       example_list: list of experiences\n",
        "       dqn_batch_size: DDQN batch size\n",
        "       use_state_prime: whether to use the next decoder state to make the batch or the current one\n",
        "       max_art_oovs: number of OOV tokens in current batch\n",
        "      Properties:\n",
        "        _x: The input to DDQN model for training, this is basically the decoder output (dqn_batch_size, dqn_input_feature_len)\n",
        "        _y: The Q-estimation (dqn_batch_size, vocab_size)\n",
        "        _y_extended: The Q-estimation (dqn_batch_size, vocab_size + max_art_oovs)\n",
        "    \"\"\"\n",
        "    self._x = np.zeros((dqn_batch_size, hps.dqn_input_feature_len))\n",
        "    self._y = np.zeros((dqn_batch_size, hps.vocab_size))\n",
        "    self._y_extended = np.zeros((dqn_batch_size, hps.vocab_size + max_art_oovs))\n",
        "    for i,e in enumerate(example_list):\n",
        "      if use_state_prime:\n",
        "        self._x[i,:]=e.state_prime\n",
        "      else:\n",
        "        self._x[i,:]=e.state\n",
        "        self._y[i,:]=normalize([e.q_value[0:hps.vocab_size]], axis=1, norm='l1')\n",
        "      if max_art_oovs == 0:\n",
        "        self._y_extended[i,:] = normalize([e.q_value[0:hps.vocab_size]], axis=1, norm='l1')\n",
        "      else:\n",
        "        self._y_extended[i,:] = e.q_value\n",
        "\n",
        "class ReplayBuffer(object):\n",
        "  \"\"\" A class for implementing the priority experience buffer. \"\"\"\n",
        "\n",
        "  BATCH_QUEUE_MAX = 100 # max number of batches the batch_queue can hold\n",
        "\n",
        "  def __init__(self, hps):\n",
        "    self._hps = hps\n",
        "    self._buffer = CustomQueue(self._hps.dqn_replay_buffer_size)\n",
        "\n",
        "    self._batch_queue = queue.Queue(self.BATCH_QUEUE_MAX)\n",
        "    self._example_queue = queue.Queue(self.BATCH_QUEUE_MAX * self._hps.dqn_batch_size)\n",
        "    self._num_example_q_threads = 1 # num threads to fill example queue\n",
        "    self._num_batch_q_threads = 1  # num threads to fill batch queue\n",
        "    self._bucketing_cache_size = 100 # how many batches-worth of examples to load into cache before bucketing\n",
        "\n",
        "    # Start the threads that load the queues\n",
        "    self._example_q_threads = []\n",
        "    for _ in range(self._num_example_q_threads):\n",
        "      self._example_q_threads.append(Thread(target=self.fill_example_queue))\n",
        "      self._example_q_threads[-1].daemon = True\n",
        "      self._example_q_threads[-1].start()\n",
        "    self._batch_q_threads = []\n",
        "    for _ in range(self._num_batch_q_threads):\n",
        "      self._batch_q_threads.append(Thread(target=self.fill_batch_queue))\n",
        "      self._batch_q_threads[-1].daemon = True\n",
        "      self._batch_q_threads[-1].start()\n",
        "\n",
        "    # Start a thread that watches the other threads and restarts them if they're dead\n",
        "    self._watch_thread = Thread(target=self.watch_threads)\n",
        "    self._watch_thread.daemon = True\n",
        "    self._watch_thread.start()\n",
        "\n",
        "  def next_batch(self):\n",
        "    \"\"\"Return a Batch from the batch queue.\n",
        "    If mode='decode' then each batch contains a single example repeated beam_size-many times; this is necessary for beam search.\n",
        "    Returns:\n",
        "      batch: a Batch object, or None if we're in single_pass mode and we've exhausted the dataset.\n",
        "    \"\"\"\n",
        "    # If the batch queue is empty, print a warning\n",
        "    if self._batch_queue.qsize() == 0:\n",
        "      tf.compat.v1.logging.warning('Bucket input queue is empty when calling next_batch. Bucket queue size: %i, Input queue size: %i', self._batch_queue.qsize(), self._example_queue.qsize())\n",
        "      return None\n",
        "\n",
        "    batch = self._batch_queue.get() # get the next Batch\n",
        "    return batch\n",
        "\n",
        "  @staticmethod\n",
        "  def create_batch(_hps, batch, batch_size, use_state_prime=False, max_art_oovs=0):\n",
        "    \"\"\" Create a DDQN-compatible batch from the input transitions\n",
        "      Args:\n",
        "        _hps: seq2seq model parameters\n",
        "        batch: a list of Transitions\n",
        "        dqn_batch_size: DDQN batch size\n",
        "        use_state_prime: whether to use the next decoder state to make the batch or the current one\n",
        "        max_art_oovs: number of OOV tokens in current batch\n",
        "      Returns:\n",
        "        An object of ReplayBatch class\n",
        "    \"\"\"\n",
        "\n",
        "    return ReplayBatch(_hps, batch, batch_size, use_state_prime, max_art_oovs)\n",
        "\n",
        "  def fill_example_queue(self):\n",
        "    \"\"\"Reads data from file and processes into Examples which are then placed into the example queue.\"\"\"\n",
        "    while True:\n",
        "      try:\n",
        "        input_gen = self._example_generator().next()\n",
        "      except StopIteration: # if there are no more examples:\n",
        "        tf.compat.v1.logging.info(\"The example generator for this example queue filling thread has exhausted data.\")\n",
        "        raise Exception(\"single_pass mode is off but the example generator is out of data; error.\")\n",
        "      self._example_queue.put(input_gen) # place the pair in the example queue.\n",
        "\n",
        "  def fill_batch_queue(self):\n",
        "    \"\"\"Takes Examples out of example queue, sorts them by encoder sequence length, processes into Batches and places them in the batch queue.\"\"\"\n",
        "    while True:\n",
        "      # Get bucketing_cache_size-many batches of Examples into a list, then sort\n",
        "      inputs = []\n",
        "      for _ in range(self._hps.dqn_batch_size * self._bucketing_cache_size):\n",
        "        inputs.append(self._example_queue.get())\n",
        "\n",
        "      # feed back all the samples to the buffer\n",
        "      self.add(inputs)\n",
        "\n",
        "      # Group the sorted Examples into batches, optionally shuffle the batches, and place in the batch queue.\n",
        "      batches = []\n",
        "      for i in range(0, len(inputs), self._hps.dqn_batch_size):\n",
        "        batches.append(inputs[i:i + self._hps.dqn_batch_size])\n",
        "        shuffle(batches)\n",
        "      for b in batches:  # each b is a list of Example objects\n",
        "        self._batch_queue.put(ReplayBatch(self._hps, b, self._hps.dqn_batch_size))\n",
        "\n",
        "  def watch_threads(self):\n",
        "    \"\"\"Watch example queue and batch queue threads and restart if dead.\"\"\"\n",
        "    while True:\n",
        "      time.sleep(60)\n",
        "      for idx,t in enumerate(self._example_q_threads):\n",
        "        if not t.is_alive(): # if the thread is dead\n",
        "          tf.compat.v1.logging.error('Found example queue thread dead. Restarting.')\n",
        "          new_t = Thread(target=self.fill_example_queue)\n",
        "          self._example_q_threads[idx] = new_t\n",
        "          new_t.daemon = True\n",
        "          new_t.start()\n",
        "      for idx,t in enumerate(self._batch_q_threads):\n",
        "        if not t.is_alive(): # if the thread is dead\n",
        "          tf.compat.v1.logging.error('Found batch queue thread dead. Restarting.')\n",
        "          new_t = Thread(target=self.fill_batch_queue)\n",
        "          self._batch_q_threads[idx] = new_t\n",
        "          new_t.daemon = True\n",
        "          new_t.start()\n",
        "\n",
        "  def add(self, items):\n",
        "    \"\"\" Adding a list of experiences to the buffer. When buffer is full,\n",
        "      we get rid of half of the least important experiences and keep the rest.\n",
        "      Args:\n",
        "        items: A list of experiences of size (batch_size, k, max_dec_steps, hidden_dim)\n",
        "    \"\"\"\n",
        "    for item in items:\n",
        "      if not self._buffer.isfull():\n",
        "        self._buffer.put_nowait(item)\n",
        "      else:\n",
        "        print('Replay Buffer is full, getting rid of unimportant transitions...')\n",
        "        self._buffer.clear()\n",
        "        self._buffer.put_nowait(item)\n",
        "    print('ReplayBatch size: {}'.format(self._buffer.qsize()))\n",
        "    print('ReplayBatch example queue size: {}'.format(self._example_queue.qsize()))\n",
        "    print('ReplayBatch batch queue size: {}'.format(self._batch_queue.qsize()))\n",
        "\n",
        "  def _buffer_len(self):\n",
        "    return self._buffer.qsize()\n",
        "\n",
        "  def _example_generator(self):\n",
        "    while True:\n",
        "      if not self._buffer.isempty():\n",
        "        item = self._buffer.get_nowait()\n",
        "        self._buffer.task_done()\n",
        "        yield item"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl42_ExqL17l"
      },
      "source": [
        "### Beam Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMIXJiEIL3-l"
      },
      "source": [
        "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
        "# Modifications Copyright 2017 Abigail See\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "\"\"\"This file contains code to run beam search decoding\"\"\"\n",
        "\n",
        "# import tensorflow as tf\n",
        "import numpy as np\n",
        "#import data\n",
        "#from replay_buffer import Transition, ReplayBuffer\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "FLAGS = tf.compat.v1.flags\n",
        "\n",
        "class Hypothesis(object):\n",
        "  \"\"\"Class to represent a hypothesis during beam search. Holds all the information needed for the hypothesis.\"\"\"\n",
        "\n",
        "  def __init__(self, tokens, log_probs, state, decoder_output, encoder_mask, attn_dists, p_gens, coverage):\n",
        "    \"\"\"Hypothesis constructor.\n",
        "    Args:\n",
        "      tokens: List of integers. The ids of the tokens that form the summary so far.\n",
        "      log_probs: List, same length as tokens, of floats, giving the log probabilities of the tokens so far.\n",
        "      state: Current state of the decoder, a LSTMStateTuple.\n",
        "      attn_dists: List, same length as tokens, of numpy arrays with shape (attn_length). These are the attention distributions so far.\n",
        "      p_gens: List, same length as tokens, of floats, or None if not using pointer-generator model. The values of the generation probability so far.\n",
        "      coverage: Numpy array of shape (attn_length), or None if not using coverage. The current coverage vector.\n",
        "    \"\"\"\n",
        "    self.tokens = tokens\n",
        "    self.log_probs = log_probs\n",
        "    self.state = state\n",
        "    self.decoder_output = decoder_output\n",
        "    self.encoder_mask = encoder_mask\n",
        "    self.attn_dists = attn_dists\n",
        "    self.p_gens = p_gens\n",
        "    self.coverage = coverage\n",
        "\n",
        "  def extend(self, token, log_prob, state, decoder_output, encoder_mask, attn_dist, p_gen, coverage):\n",
        "    \"\"\"Return a NEW hypothesis, extended with the information from the latest step of beam search.\n",
        "    Args:\n",
        "      token: Integer. Latest token produced by beam search.\n",
        "      log_prob: Float. Log prob of the latest token.\n",
        "      state: Current decoder state, a LSTMStateTuple.\n",
        "      attn_dist: Attention distribution from latest step. Numpy array shape (attn_length).\n",
        "      p_gen: Generation probability on latest step. Float.\n",
        "      coverage: Latest coverage vector. Numpy array shape (attn_length), or None if not using coverage.\n",
        "    Returns:\n",
        "      New Hypothesis for next step.\n",
        "    \"\"\"\n",
        "    if FLAGS.avoid_trigrams and self._has_trigram(self.tokens + [token]):\n",
        "        log_prob = -np.infty\n",
        "    return Hypothesis(tokens = self.tokens + [token],\n",
        "                      log_probs = self.log_probs + [log_prob],\n",
        "                      state = state,\n",
        "                      decoder_output= self.decoder_output + [decoder_output] if decoder_output is not None else [],\n",
        "                      encoder_mask = self.encoder_mask + [encoder_mask] if encoder_mask is not None else [],\n",
        "                      attn_dists = self.attn_dists + [attn_dist],\n",
        "                      p_gens = self.p_gens + [p_gen],\n",
        "                      coverage = coverage)\n",
        "\n",
        "  def _find_ngrams(self, input_list, n):\n",
        "      return zip(*[input_list[i:] for i in range(n)])\n",
        "\n",
        "  def _has_trigram(self, tokens):\n",
        "      tri_grams = self._find_ngrams(tokens, 3)\n",
        "      cnt = Counter(tri_grams)\n",
        "      return not all((cnt[g] == 1 for g in cnt))\n",
        "\n",
        "  @property\n",
        "  def latest_token(self):\n",
        "    return self.tokens[-1]\n",
        "\n",
        "  @property\n",
        "  def log_prob(self):\n",
        "    # the log probability of the hypothesis so far is the sum of the log probabilities of the tokens so far\n",
        "    return sum(self.log_probs)\n",
        "\n",
        "  @property\n",
        "  def avg_log_prob(self):\n",
        "    # normalize log probability by number of tokens (otherwise longer sequences always have lower probability)\n",
        "    return self.log_prob / len(self.tokens)\n",
        "\n",
        "\n",
        "def run_beam_search(sess, model, vocab, batch, dqn = None, dqn_sess = None, dqn_graph = None):\n",
        "  \"\"\"Performs beam search decoding on the given example.\n",
        "  Args:\n",
        "    sess: a tf.Session\n",
        "    model: a seq2seq model\n",
        "    vocab: Vocabulary object\n",
        "    batch: Batch object that is the same example repeated across the batch\n",
        "  Returns:\n",
        "    best_hyp: Hypothesis object; the best hypothesis found by beam search.\n",
        "  \"\"\"\n",
        "  # Run the encoder to get the encoder hidden states and decoder initial state\n",
        "  enc_states, dec_in_state = model.run_encoder(sess, batch)\n",
        "  # dec_in_state is a LSTMStateTuple\n",
        "  # enc_states has shape [batch_size, <=max_enc_steps, 2*hidden_dim].\n",
        "\n",
        "  # Initialize beam_size-many hyptheses\n",
        "  hyps = [Hypothesis(tokens=[vocab.word2id(START_DECODING)],\n",
        "                     log_probs=[0.0],\n",
        "                     state=dec_in_state,\n",
        "                     decoder_output = [np.zeros([FLAGS.dec_hidden_dim])],\n",
        "                     encoder_mask = [np.zeros([batch.enc_batch.shape[1]])],\n",
        "                     attn_dists=[],\n",
        "                     p_gens=[],\n",
        "                     coverage=np.zeros([batch.enc_batch.shape[1]]) # zero vector of length attention_length\n",
        "                     ) for _ in range(FLAGS.beam_size)]\n",
        "  results = [] # this will contain finished hypotheses (those that have emitted the [STOP] token)\n",
        "\n",
        "  steps = 0\n",
        "  while steps < FLAGS.max_dec_steps and len(results) < FLAGS.beam_size:\n",
        "    latest_tokens = [h.latest_token for h in hyps] # latest token produced by each hypothesis\n",
        "    latest_tokens = [t if t in range(vocab.size()) else vocab.word2id(UNKNOWN_TOKEN) for t in latest_tokens] # change any in-article temporary OOV ids to [UNK] id, so that we can lookup word embeddings\n",
        "    states = [h.state for h in hyps] # list of current decoder states of the hypotheses\n",
        "    prev_coverage = [h.coverage for h in hyps] # list of coverage vectors (or None)\n",
        "    decoder_outputs = np.array([h.decoder_output for h in hyps]).swapaxes(0, 1) # shape (?, batch_size, dec_hidden_dim)\n",
        "    encoder_es = np.array([h.encoder_mask for h in hyps]).swapaxes(0, 1)  # shape (?, batch_size, enc_hidden_dim)\n",
        "    # Run one step of the decoder to get the new info\n",
        "    (topk_ids, topk_log_probs, new_states, attn_dists, final_dists, p_gens, new_coverage, decoder_output, encoder_e) = model.decode_onestep(sess=sess,\n",
        "                        batch=batch,\n",
        "                        latest_tokens=latest_tokens,\n",
        "                        enc_states=enc_states,\n",
        "                        dec_init_states=states,\n",
        "                        prev_coverage=prev_coverage,\n",
        "                        prev_decoder_outputs= decoder_outputs if FLAGS.intradecoder else tf.stack([], axis=0),\n",
        "                        prev_encoder_es = encoder_es if FLAGS.use_temporal_attention else tf.stack([], axis=0))\n",
        "\n",
        "    if FLAGS.ac_training:\n",
        "      with dqn_graph.as_default():\n",
        "        dqn_results = dqn.run_test_steps(dqn_sess, x=decoder_output)\n",
        "        q_estimates = dqn_results['estimates'] # shape (len(transitions), vocab_size)\n",
        "        # we use the q_estimate of UNK token for all the OOV tokens\n",
        "        q_estimates = np.concatenate([q_estimates,np.reshape(q_estimates[:,0],[-1,1])*np.ones((FLAGS.beam_size,batch.max_art_oovs))],axis=-1)\n",
        "        # normalized q_estimate\n",
        "        q_estimates = normalize(q_estimates, axis=1, norm='l1')\n",
        "        combined_estimates = final_dists * q_estimates\n",
        "        combined_estimates = normalize(combined_estimates, axis=1, norm='l1')\n",
        "        # overwriting topk ids and probs\n",
        "        topk_ids = np.argsort(combined_estimates,axis=-1)[:,-FLAGS.beam_size*2:][:,::-1]\n",
        "        topk_probs = [combined_estimates[i,_] for i,_ in enumerate(topk_ids)]\n",
        "        topk_log_probs = np.log(topk_probs)\n",
        "\n",
        "    # Extend each hypothesis and collect them all in all_hyps\n",
        "    all_hyps = []\n",
        "    num_orig_hyps = 1 if steps == 0 else len(hyps) # On the first step, we only had one original hypothesis (the initial hypothesis). On subsequent steps, all original hypotheses are distinct.\n",
        "    for i in range(num_orig_hyps):\n",
        "      h, new_state, attn_dist, p_gen, new_coverage_i = hyps[i], new_states[i], attn_dists[i], p_gens[i], new_coverage[i]  # take the ith hypothesis and new decoder state info\n",
        "      decoder_output_i = None\n",
        "      encoder_mask_i = None\n",
        "      if FLAGS.intradecoder:\n",
        "        decoder_output_i = decoder_output[i]\n",
        "      if FLAGS.use_temporal_attention:\n",
        "        encoder_mask_i = encoder_e[i]\n",
        "      for j in range(FLAGS.beam_size * 2):  # for each of the top 2*beam_size hyps:\n",
        "        # Extend the ith hypothesis with the jth option\n",
        "        new_hyp = h.extend(token=topk_ids[i, j],\n",
        "                           log_prob=topk_log_probs[i, j],\n",
        "                           state=new_state,\n",
        "                           decoder_output = decoder_output_i,\n",
        "                           encoder_mask = encoder_mask_i,\n",
        "                           attn_dist=attn_dist,\n",
        "                           p_gen=p_gen,\n",
        "                           coverage=new_coverage_i)\n",
        "        all_hyps.append(new_hyp)\n",
        "\n",
        "    # Filter and collect any hypotheses that have produced the end token.\n",
        "    hyps = [] # will contain hypotheses for the next step\n",
        "    for h in sort_hyps(all_hyps): # in order of most likely h\n",
        "      if h.latest_token == vocab.word2id(STOP_DECODING): # if stop token is reached...\n",
        "        # If this hypothesis is sufficiently long, put in results. Otherwise discard.\n",
        "        if steps >= FLAGS.min_dec_steps:\n",
        "          results.append(h)\n",
        "      else: # hasn't reached stop token, so continue to extend this hypothesis\n",
        "        hyps.append(h)\n",
        "      if len(hyps) == FLAGS.beam_size or len(results) == FLAGS.beam_size:\n",
        "        # Once we've collected beam_size-many hypotheses for the next step, or beam_size-many complete hypotheses, stop.\n",
        "        break\n",
        "\n",
        "    steps += 1\n",
        "\n",
        "  # At this point, either we've got beam_size results, or we've reached maximum decoder steps\n",
        "\n",
        "  if len(results)==0: # if we don't have any complete results, add all current hypotheses (incomplete summaries) to results\n",
        "    results = hyps\n",
        "\n",
        "  # Sort hypotheses by average log probability\n",
        "  hyps_sorted = sort_hyps(results)\n",
        "\n",
        "  # Return the hypothesis with highest average log prob\n",
        "  return hyps_sorted[0]\n",
        "\n",
        "def sort_hyps(hyps):\n",
        "  \"\"\"Return a list of Hypothesis objects, sorted by descending average log probability\"\"\"\n",
        "  return sorted(hyps, key=lambda h: h.avg_log_prob, reverse=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HArp8MJDMePU"
      },
      "source": [
        "### Util"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDHyrNwaMfVK"
      },
      "source": [
        "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
        "# Modifications Copyright 2017 Abigail See\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "\"\"\"This file contains some utility functions\"\"\"\n",
        "\n",
        "# import tensorflow as tf\n",
        "import time\n",
        "import os\n",
        "FLAGS = tf.compat.v1.flags\n",
        "\n",
        "def get_config():\n",
        "  \"\"\"Returns config for tf.session\"\"\"\n",
        "  config = tf.ConfigProto(allow_soft_placement=True)\n",
        "  #config = tf.ConfigProto(log_device_placement=True)\n",
        "  config.gpu_options.allow_growth=True\n",
        "  return config\n",
        "\n",
        "def load_ckpt(saver, sess, ckpt_dir=\"train\"):\n",
        "  \"\"\"Load checkpoint from the ckpt_dir (if unspecified, this is train dir) and restore it to saver and sess, waiting 10 secs in the case of failure. Also returns checkpoint name.\"\"\"\n",
        "  while True:\n",
        "    try:\n",
        "      latest_filename = \"checkpoint_best\" if ckpt_dir==\"eval\" else None\n",
        "      ckpt_dir = os.path.join(FLAGS.log_root, ckpt_dir)\n",
        "      ckpt_state = tf.train.get_checkpoint_state(ckpt_dir, latest_filename=latest_filename)\n",
        "      tf.compat.v1.logging.info('Loading checkpoint %s', ckpt_state.model_checkpoint_path)\n",
        "      saver.restore(sess, ckpt_state.model_checkpoint_path)\n",
        "      return ckpt_state.model_checkpoint_path\n",
        "    except:\n",
        "      tf.compat.v1.logging.info(\"Failed to load checkpoint from %s. Sleeping for %i secs...\", ckpt_dir, 10)\n",
        "      time.sleep(10)\n",
        "\n",
        "def load_dqn_ckpt(saver, sess):\n",
        "  \"\"\"Load checkpoint from the ckpt_dir (if unspecified, this is train dir) and restore it to saver and sess, waiting 10 secs in the case of failure. Also returns checkpoint name.\"\"\"\n",
        "  while True:\n",
        "    try:\n",
        "      ckpt_dir = os.path.join(FLAGS.log_root, \"dqn\", \"train\")\n",
        "      ckpt_state = tf.train.get_checkpoint_state(ckpt_dir)\n",
        "      tf.compat.v1.logging.info('Loading checkpoint %s', ckpt_state.model_checkpoint_path)\n",
        "      saver.restore(sess, ckpt_state.model_checkpoint_path)\n",
        "      return ckpt_state.model_checkpoint_path\n",
        "    except:\n",
        "      tf.compat.v1.logging.info(\"Failed to load checkpoint from %s. Sleeping for %i secs...\", ckpt_dir, 10)\n",
        "      time.sleep(10)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyX9o0teI4fb"
      },
      "source": [
        "### Decode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8QzCLjuI6_j"
      },
      "source": [
        "https://github.com/yaserkl/RLSeq2Seq/blob/master/src/decode.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-vKdSWVJC2b"
      },
      "source": [
        "from tensorflow.python.framework import ops\n",
        "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
        "# Modifications Copyright 2017 Abigail See\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "\"\"\"This file contains code to run beam search decoding, including running ROUGE evaluation and producing JSON datafiles for the in-browser attention visualizer, which can be found here https://github.com/abisee/attn_vis\"\"\"\n",
        "\n",
        "import os\n",
        "import time\n",
        "# import tensorflow as tf\n",
        "#import beam_search\n",
        "#import data\n",
        "import json\n",
        "import pyrouge\n",
        "#import util\n",
        "import logging\n",
        "#from unidecode import unidecode\n",
        "\n",
        "FLAGS = tf.compat.v1.flags\n",
        "\n",
        "SECS_UNTIL_NEW_CKPT = 60  # max number of seconds before loading new checkpoint\n",
        "\n",
        "article = []\n",
        "reference = []\n",
        "summary = []\n",
        "\n",
        "class BeamSearchDecoder(object):\n",
        "  \"\"\"Beam search decoder.\"\"\"\n",
        "\n",
        "  def __init__(self, model, batcher, vocab, dqn = None):\n",
        "    \"\"\"Initialize decoder.\n",
        "    Args:\n",
        "      model: a Seq2SeqAttentionModel object.\n",
        "      batcher: a Batcher object.\n",
        "      vocab: Vocabulary object\n",
        "    \"\"\"\n",
        "    self._model = model\n",
        "    self._model.build_graph()\n",
        "    self._batcher = batcher\n",
        "    self._vocab = vocab\n",
        "    self._saver = tf.train.Saver() # we use this to load checkpoints for decoding\n",
        "    self._sess = tf.Session(config=get_config())\n",
        "\n",
        "    if FLAGS.ac_training:\n",
        "      self._dqn = dqn\n",
        "      self._dqn_graph = tf.Graph()\n",
        "      with self._dqn_graph.as_default():\n",
        "        self._dqn.build_graph()\n",
        "        self._dqn_saver = tf.train.Saver() # we use this to load checkpoints for decoding\n",
        "        self._dqn_sess = tf.Session(config=get_config())\n",
        "        _ = load_dqn_ckpt(self._dqn_saver, self._dqn_sess)\n",
        "\n",
        "    # Load an initial checkpoint to use for decoding\n",
        "    ckpt_path = load_ckpt(self._saver, self._sess, FLAGS.decode_from)\n",
        "\n",
        "    if FLAGS.single_pass:\n",
        "      # Make a descriptive decode directory name\n",
        "      ckpt_name = \"{}-ckpt-\".format(FLAGS.decode_from) + ckpt_path.split('-')[\n",
        "        -1]  # this is something of the form \"ckpt-123456\"\n",
        "      self._decode_dir = os.path.join(FLAGS.log_root, get_decode_dir_name(ckpt_name))\n",
        "    else: # Generic decode dir name\n",
        "      self._decode_dir = os.path.join(FLAGS.log_root, \"decode\")\n",
        "\n",
        "    # Make the decode dir if necessary\n",
        "    if not os.path.exists(self._decode_dir): os.mkdir(self._decode_dir)\n",
        "\n",
        "    if FLAGS.single_pass:\n",
        "      # Make the dirs to contain output written in the correct format for pyrouge\n",
        "      self._rouge_ref_dir = os.path.join(self._decode_dir, \"reference\")\n",
        "      if not os.path.exists(self._rouge_ref_dir): os.mkdir(self._rouge_ref_dir)\n",
        "      self._rouge_dec_dir = os.path.join(self._decode_dir, \"decoded\")\n",
        "      if not os.path.exists(self._rouge_dec_dir): os.mkdir(self._rouge_dec_dir)\n",
        "\n",
        "  def decode(self):\n",
        "    \"\"\"Decode examples until data is exhausted (if FLAGS.single_pass) and return, or decode indefinitely, loading latest checkpoint at regular intervals\"\"\"\n",
        "    t0 = time.time()\n",
        "    counter = FLAGS.decode_after\n",
        "    while True:\n",
        "\n",
        "      \n",
        "      #ops.reset_default_graph()\n",
        "      batch = self._batcher.next_batch()  # 1 example repeated across batch\n",
        "      if batch is None: # finished decoding dataset in single_pass mode\n",
        "        assert FLAGS.single_pass, \"Dataset exhausted, but we are not in single_pass mode\"\n",
        "        tf.compat.v1.logging.info(\"Decoder has finished reading dataset for single_pass.\")\n",
        "        tf.compat.v1.logging.info(\"Output has been saved in %s and %s. Now starting ROUGE eval...\", self._rouge_ref_dir, self._rouge_dec_dir)\n",
        "        results_dict = rouge_eval(self._rouge_ref_dir, self._rouge_dec_dir)\n",
        "        rouge_log(results_dict, self._decode_dir)\n",
        "        return\n",
        "\n",
        "\n",
        "      original_article = batch.original_articles[0]  # string\n",
        "      original_abstract = batch.original_abstracts[0]  # string\n",
        "      original_abstract_sents = batch.original_abstracts_sents[0]  # list of strings\n",
        "\n",
        "      article_withunks = show_art_oovs(original_article, self._vocab) # string\n",
        "      abstract_withunks = show_abs_oovs(original_abstract, self._vocab, (batch.art_oovs[0] if FLAGS.pointer_gen else None)) # string\n",
        "\n",
        "      # Run beam search to get best Hypothesis\n",
        "      if FLAGS.ac_training:\n",
        "        best_hyp = run_beam_search(self._sess, self._model, self._vocab, batch, self._dqn, self._dqn_sess, self._dqn_graph)\n",
        "      else:\n",
        "        best_hyp = run_beam_search(self._sess, self._model, self._vocab, batch)\n",
        "      # Extract the output ids from the hypothesis and convert back to words\n",
        "      output_ids = [int(t) for t in best_hyp.tokens[1:]]\n",
        "      decoded_words = outputids2words(output_ids, self._vocab, (batch.art_oovs[0] if FLAGS.pointer_gen else None))\n",
        "      print(decoded_words)\n",
        "      # Remove the [STOP] token from decoded_words, if necessary\n",
        "      try:\n",
        "        fst_stop_idx = decoded_words.index(STOP_DECODING) # index of the (first) [STOP] symbol\n",
        "        decoded_words = decoded_words[:fst_stop_idx]\n",
        "      except ValueError:\n",
        "        decoded_words = decoded_words\n",
        "        \n",
        "      decoded_output = ' '.join(decoded_words) # single string\n",
        "        \n",
        "      if FLAGS.single_pass:#me when \n",
        "        self.write_for_rouge(original_abstract_sents, decoded_words, counter) # write ref summary and decoded summary to file, to eval with pyrouge later\n",
        "        \n",
        "        print(\"file written\")\n",
        "        article.append(article_withunks)\n",
        "        reference.append(abstract_withunks)\n",
        "        summary.append(decoded_output)\n",
        "        \n",
        "        counter += 1 # this is how many examples we've decoded\n",
        "        tf.compat.v1.logging.info(\"sentence summarized \" + str(counter))\n",
        "        if counter == 100 :\n",
        "            tf.compat.v1.logging.info(\"Counter 100 stopped.\")\n",
        "            return\n",
        "      else:\n",
        "        print_results(article_withunks, abstract_withunks, decoded_output) # log output to screen\n",
        "        self.write_for_attnvis(article_withunks, abstract_withunks, decoded_words, best_hyp.attn_dists, best_hyp.p_gens) # write info to .json file for visualization tool\n",
        "\n",
        "        # Check if SECS_UNTIL_NEW_CKPT has elapsed; if so return so we can load a new checkpoint\n",
        "        t1 = time.time()\n",
        "        if t1-t0 > SECS_UNTIL_NEW_CKPT:\n",
        "          tf.compat.v1.logging.info('We\\'ve been decoding with same checkpoint for %i seconds. Time to load new checkpoint', t1-t0)\n",
        "          _ = load_ckpt(self._saver, self._sess, FLAGS.decode_from)\n",
        "          t0 = time.time()\n",
        "\n",
        "  def remove_non_ascii(self, text):\n",
        "    #try:\n",
        "    #  return unicode(unidecode(unicode(text, encoding=\"utf-8\")))\n",
        "    #except:\n",
        "    return text #str(unidecode(text))\n",
        "\n",
        "  def write_for_rouge(self, reference_sents, decoded_words, ex_index):\n",
        "    \"\"\"Write output to file in correct format for eval with pyrouge. This is called in single_pass mode.\n",
        "    Args:\n",
        "      reference_sents: list of strings\n",
        "      decoded_words: list of strings\n",
        "      ex_index: int, the index with which to label the files\n",
        "    \"\"\"\n",
        "    # First, divide decoded output into sentences\n",
        "    decoded_sents = []\n",
        "    while len(decoded_words) > 0:\n",
        "      try:\n",
        "        fst_period_idx = decoded_words.index(\".\")\n",
        "      except ValueError: # there is text remaining that doesn't end in \".\"\n",
        "        fst_period_idx = len(decoded_words)\n",
        "      sent = decoded_words[:fst_period_idx+1] # sentence up to and including the period\n",
        "      decoded_words = decoded_words[fst_period_idx+1:] # everything else\n",
        "      decoded_sents.append(' '.join(sent))\n",
        "\n",
        "    # pyrouge calls a perl script that puts the data into HTML files.\n",
        "    # Therefore we need to make our output HTML safe.\n",
        "    decoded_sents = [self.remove_non_ascii(make_html_safe(w)) for w in decoded_sents]\n",
        "    reference_sents = [self.remove_non_ascii(make_html_safe(w)) for w in reference_sents]\n",
        "\n",
        "    # Write to file\n",
        "    ref_file = os.path.join(self._rouge_ref_dir, \"%06d_reference.txt\" % ex_index)\n",
        "    decoded_file = os.path.join(self._rouge_dec_dir, \"%06d_decoded.txt\" % ex_index)\n",
        "\n",
        "    with open(ref_file, \"w\") as f:\n",
        "      for idx,sent in enumerate(reference_sents):\n",
        "        f.write(sent) if idx==len(reference_sents)-1 else f.write(sent+\"\\n\")\n",
        "    with open(decoded_file, \"w\") as f:\n",
        "      for idx,sent in enumerate(decoded_sents):\n",
        "        f.write(sent) if idx==len(decoded_sents)-1 else f.write(sent+\"\\n\")\n",
        "\n",
        "    tf.compat.v1.logging.info(\"Wrote example %i to file\" % ex_index)\n",
        "\n",
        "  def write_for_attnvis(self, article, abstract, decoded_words, attn_dists, p_gens):\n",
        "    \"\"\"Write some data to json file, which can be read into the in-browser attention visualizer tool:\n",
        "      https://github.com/abisee/attn_vis\n",
        "    Args:\n",
        "      article: The original article string.\n",
        "      abstract: The human (correct) abstract string.\n",
        "      attn_dists: List of arrays; the attention distributions.\n",
        "      decoded_words: List of strings; the words of the generated summary.\n",
        "      p_gens: List of scalars; the p_gen values. If not running in pointer-generator mode, list of None.\n",
        "    \"\"\"\n",
        "    article_lst = article.split() # list of words\n",
        "    decoded_lst = decoded_words # list of decoded words\n",
        "    to_write = {\n",
        "        'article_lst': [make_html_safe(t) for t in article_lst],\n",
        "        'decoded_lst': [make_html_safe(t) for t in decoded_lst],\n",
        "        'abstract_str': make_html_safe(abstract),\n",
        "        'attn_dists': attn_dists\n",
        "    }\n",
        "    if FLAGS.pointer_gen:\n",
        "      to_write['p_gens'] = p_gens\n",
        "    output_fname = os.path.join(self._decode_dir, 'attn_vis_data.json')\n",
        "    with open(output_fname, 'w') as output_file:\n",
        "      json.dump(to_write, output_file)\n",
        "    tf.compat.v1.logging.info('Wrote visualization data to %s', output_fname)\n",
        "\n",
        "\n",
        "def print_results(article, abstract, decoded_output):\n",
        "  \"\"\"Prints the article, the reference summmary and the decoded summary to screen\"\"\"\n",
        "  print(\"\")\n",
        "  tf.compat.v1.logging.info('ARTICLE:  %s', article)\n",
        "  tf.compat.v1.logging.info('REFERENCE SUMMARY: %s', abstract)\n",
        "  tf.compat.v1.logging.info('GENERATED SUMMARY: %s', decoded_output)\n",
        "  print(\"\")\n",
        "\n",
        "\n",
        "def make_html_safe(s):\n",
        "  try:\n",
        "    \"\"\"Replace any angled brackets in string s to avoid interfering with HTML attention visualizer.\"\"\"\n",
        "    s.replace(\"<\", \"&lt;\")\n",
        "    s.replace(\">\", \"&gt;\")\n",
        "  except:\n",
        "    pass\n",
        "  return s\n",
        "\n",
        "\n",
        "def rouge_eval(ref_dir, dec_dir):\n",
        "  \"\"\"Evaluate the files in ref_dir and dec_dir with pyrouge, returning results_dict\"\"\"\n",
        "  r = pyrouge.Rouge155()\n",
        "  r.model_filename_pattern = '#ID#_reference.txt'\n",
        "  r.system_filename_pattern = '(\\d+)_decoded.txt'\n",
        "  r.model_dir = ref_dir\n",
        "  r.system_dir = dec_dir\n",
        "  logging.getLogger('global').setLevel(logging.WARNING) # silence pyrouge logging\n",
        "  rouge_results = r.convert_and_evaluate()\n",
        "  return r.output_to_dict(rouge_results)\n",
        "\n",
        "\n",
        "def rouge_log(results_dict, dir_to_write):\n",
        "  \"\"\"Log ROUGE results to screen and write to file.\n",
        "  Args:\n",
        "    results_dict: the dictionary returned by pyrouge\n",
        "    dir_to_write: the directory where we will write the results to\"\"\"\n",
        "  log_str = \"\"\n",
        "  for x in [\"1\",\"2\",\"l\"]:\n",
        "    log_str += \"\\nROUGE-%s:\\n\" % x\n",
        "    for y in [\"f_score\", \"recall\", \"precision\"]:\n",
        "      key = \"rouge_%s_%s\" % (x,y)\n",
        "      key_cb = key + \"_cb\"\n",
        "      key_ce = key + \"_ce\"\n",
        "      val = results_dict[key]\n",
        "      val_cb = results_dict[key_cb]\n",
        "      val_ce = results_dict[key_ce]\n",
        "      log_str += \"%s: %.4f with confidence interval (%.4f, %.4f)\\n\" % (key, val, val_cb, val_ce)\n",
        "  tf.compat.v1.logging.info(log_str) # log to screen\n",
        "  results_file = os.path.join(dir_to_write, \"ROUGE_results.txt\")\n",
        "  tf.compat.v1.logging.info(\"Writing final ROUGE results to %s...\", results_file)\n",
        "  with open(results_file, \"w\") as f:\n",
        "    f.write(log_str)\n",
        "\n",
        "def get_decode_dir_name(ckpt_name):\n",
        "  \"\"\"Make a descriptive name for the decode dir, including the name of the checkpoint we use to decode. This is called in single_pass mode.\"\"\"\n",
        "\n",
        "  if \"train\" in FLAGS.data_path: dataset = \"train\"\n",
        "  elif \"val\" in FLAGS.data_path: dataset = \"val\"\n",
        "  elif \"test\" in FLAGS.data_path: dataset = \"test\"\n",
        "  else: raise ValueError(\"FLAGS.data_path %s should contain one of train, val or test\" % (FLAGS.data_path))\n",
        "  dirname = \"decode_%s_%s_%imaxenc_%ibeam_%imindec_%imaxdec\" % (dataset, FLAGS.decode_from, FLAGS.max_enc_steps, FLAGS.beam_size, FLAGS.min_dec_steps, FLAGS.max_dec_steps)\n",
        "  if ckpt_name is not None:\n",
        "    dirname += \"_%s\" % ckpt_name\n",
        "  return dirname"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CT_2nWdJNnD"
      },
      "source": [
        "### DQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VomJ-_qOJPLx"
      },
      "source": [
        "https://github.com/yaserkl/RLSeq2Seq/blob/master/src/dqn.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmnGbytcJPb7"
      },
      "source": [
        "# import tensorflow as tf\n",
        "#import tensorlayer as tl\n",
        "import numpy as np\n",
        "\n",
        "class DQN(object):\n",
        "    def __init__(self, hps, name_variable):\n",
        "        self._hps = hps\n",
        "        self._name_variable = name_variable\n",
        "\n",
        "    def variable_summaries(self, var_name, var):\n",
        "        \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\n",
        "        with tf.name_scope('summaries_{}'.format(var_name)):\n",
        "            mean = tf.reduce_mean(var)\n",
        "            tf.summary.scalar('mean', mean)\n",
        "            with tf.name_scope('stddev'):\n",
        "                stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
        "            tf.summary.scalar('stddev', stddev)\n",
        "            tf.summary.scalar('max', tf.reduce_max(var))\n",
        "            tf.summary.scalar('min', tf.reduce_min(var))\n",
        "            tf.summary.histogram('histogram', var)\n",
        "\n",
        "    def _add_placeholders(self):\n",
        "        \"\"\"Add placeholders to the graph. These are entry points for any input data.\"\"\"\n",
        "        self._x = tf.placeholder(tf.float32, [None, self._hps.dqn_input_feature_len], name='x') # size (dataset_len, input_feature_len)\n",
        "        self._y = tf.placeholder(tf.float32, [None, self._hps.vocab_size], name='y') # size (dataset_len, 1)\n",
        "        self._train_step = tf.placeholder(tf.int32, None,name='train_step')\n",
        "\n",
        "    def _make_feed_dict(self, batch):\n",
        "        feed_dict = {}\n",
        "        feed_dict[self._x] = batch._x\n",
        "        feed_dict[self._y] = batch._y\n",
        "        return feed_dict\n",
        "\n",
        "    def _add_tf_layers(self):\n",
        "        \"\"\" Based on the dqn_layers flag, it creates multiple dense layers to do the regression. \"\"\"\n",
        "\n",
        "        h = tf.layers.dense(self._x, units = self._hps.dqn_input_feature_len, activation=tf.nn.relu, name='{}_input_layer'.format(self._name_variable))\n",
        "        for i, layer in enumerate(self._hps.dqn_layers.split(',')):\n",
        "            h = tf.layers.dense(h, units = int(layer), activation = tf.nn.relu, name='{}_h_{}'.format(self._name_variable, i))\n",
        "\n",
        "        self.advantage_layer = tf.layers.dense(h, units = self._hps.vocab_size, activation = tf.nn.softmax, name='{}_advantage'.format(self._name_variable))\n",
        "        if self._hps.dueling_net:\n",
        "            # in dueling net, we have two extra output layers; one for value function estimation\n",
        "            # and the other for advantage estimation, we then use the difference between these two layers\n",
        "            # to calculate the q-estimation\n",
        "            self_layer = tf.layers.dense(h, units = 1, activation = tf.identity, name='{}_value'.format(self._name_variable))\n",
        "            normalized_al = self.advantage_layer-tf.reshape(tf.reduce_mean(self.advantage_layer,axis=1),[-1,1]) # equation 9 in https://arxiv.org/pdf/1511.06581.pdf\n",
        "            value_extended = tf.concat([self_layer] * self._hps.vocab_size, axis=1)\n",
        "            self.output = value_extended + normalized_al\n",
        "        else:\n",
        "            self.output = self.advantage_layer\n",
        "\n",
        "    def _add_train_op(self):\n",
        "        # In regression, the objective loss is Mean Squared Error (MSE).\n",
        "        self.loss = tf.losses.mean_squared_error(labels = self._y, predictions = self.output)\n",
        "\n",
        "        tvars = tf.trainable_variables()\n",
        "        gradients = tf.gradients(self.loss, tvars, aggregation_method=tf.AggregationMethod.EXPERIMENTAL_TREE)\n",
        "\n",
        "        # Clip the gradients\n",
        "        with tf.device(\"/gpu:{}\".format(self._hps.dqn_gpu_num)):\n",
        "            grads, global_norm = tf.clip_by_global_norm(gradients, self._hps.max_grad_norm)\n",
        "\n",
        "        # Add a summary\n",
        "        tf.summary.scalar('global_norm', global_norm)\n",
        "\n",
        "        # Apply adagrad optimizer\n",
        "        optimizer = tf.train.AdamOptimizer(self._hps.lr)\n",
        "        with tf.device(\"/gpu:{}\".format(self._hps.dqn_gpu_num)):\n",
        "            self.train_op = optimizer.apply_gradients(zip(grads, tvars), global_step=self.global_step, name='train_step')\n",
        "\n",
        "        self.variable_summaries('dqn_loss',self.loss)\n",
        "\n",
        "    def _add_update_weights_op(self):\n",
        "        \"\"\" Updates the weight of the target network based on the current network. \"\"\"\n",
        "        self.model_trainables = tf.trainable_variables(scope='{}_relay_network'.format(self._name_variable)) # target variables\n",
        "        self._new_trainables = [tf.placeholder(tf.float32, None,name='trainables_{}'.format(i)) for i in range(len(self.model_trainables))]\n",
        "        self.assign_ops = []\n",
        "        if self._hps.dqn_polyak_averaging: # target parameters are slowly updating using: \\phi_target = \\tau * \\phi_target + (1-\\tau) * \\phi_target\n",
        "            tau = (tf.cast(self._train_step,tf.float32) % self._hps.dqn_target_update)/float(self._hps.dqn_target_update)\n",
        "            for i, mt in enumerate(self.model_trainables):\n",
        "                nt = self._new_trainables[i]\n",
        "                self.assign_ops.append(mt.assign(tau * mt + (1-tau) * nt))\n",
        "        else:\n",
        "          if self._train_step % self._hps.dqn_target_update == 0:\n",
        "            for i, mt in enumerate(self.model_trainables):\n",
        "                nt = self._new_trainables[i]\n",
        "                self.assign_ops.append(mt.assign(nt))\n",
        "\n",
        "    def build_graph(self):\n",
        "        with tf.variable_scope('{}_relay_network'.format(self._name_variable)), tf.device(\"/gpu:{}\".format(self._hps.dqn_gpu_num)):\n",
        "            self.global_step = tf.Variable(0, name='global_step', trainable=False)\n",
        "            self._add_placeholders()\n",
        "            self._add_tf_layers()\n",
        "            self._add_train_op()\n",
        "            self._add_update_weights_op()\n",
        "            self._summaries = tf.summary.merge_all()\n",
        "\n",
        "    def run_train_steps(self, sess, batch):\n",
        "        feed_dict = self._make_feed_dict(batch)\n",
        "        to_return = {'train_op': self.train_op,\n",
        "        'summaries': self._summaries,\n",
        "        'loss': self.loss,\n",
        "        'global_step': self.global_step}\n",
        "        return sess.run(to_return, feed_dict)\n",
        "\n",
        "    def run_test_steps(self, sess, x, y=None, return_loss=False, return_best_action=False):\n",
        "        # when return_loss is True, the model will return the loss of the prediction\n",
        "        # return_loss should be False, during estimation (decoding)\n",
        "        feed_dict = {self._x:x}\n",
        "        to_return = {'estimates': self.output}\n",
        "        if return_loss:\n",
        "            feed_dict.update({self._y:y})\n",
        "            to_return.update({'loss': self.loss})\n",
        "        output = sess.run(to_return, feed_dict)\n",
        "        if return_best_action:\n",
        "            output['best_action']=np.argmax(output['estimates'],axis=1)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def run_update_weights(self, sess, train_step, weights):\n",
        "        feed_dict = {self._train_step:train_step}\n",
        "        for i, w in enumerate(weights):\n",
        "            feed_dict.update({self._new_trainables[i]:w})\n",
        "        _ = sess.run(self.assign_ops, feed_dict)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BUkkzzj20LP"
      },
      "source": [
        "### zaksum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydqQhOWz213h"
      },
      "source": [
        "#https://pymotw.com/2/xml/etree/ElementTree/create.html\n",
        "\n",
        "from xml.etree import ElementTree\n",
        "from xml.dom import minidom\n",
        "from functools import reduce\n",
        "\n",
        "def prettify(elem):\n",
        "    \"\"\"Return a pretty-printed XML string for the Element.\n",
        "    \"\"\"\n",
        "    rough_string = ElementTree.tostring(elem, 'utf-8')\n",
        "    reparsed = minidom.parseString(rough_string)\n",
        "    return reparsed.toprettyxml(indent=\"  \")\n",
        "  \n",
        "from xml.etree.ElementTree import Element, SubElement, Comment\n",
        "\n",
        "\n",
        "def zaksum(article , reference , summary_array , directory_path):\n",
        "  top = Element('ZakSum')\n",
        "\n",
        "  comment = Comment('Generated by Amr Zaki without scores')\n",
        "  top.append(comment)\n",
        "\n",
        "  i=0\n",
        "  for summ in summary_array:\n",
        "    example = SubElement(top, 'example')\n",
        "    article_element   = SubElement(example, 'article')\n",
        "    article_element.text = article[i]\n",
        "\n",
        "    reference_element = SubElement(example, 'reference')\n",
        "    reference_element.text = reference[i]\n",
        "\n",
        "    summary_element   = SubElement(example, 'summary')\n",
        "    summary_element.text = summ\n",
        "    i+=1\n",
        "    \n",
        "  with open(directory_path, mode=\"w\") as f:\n",
        "    f.write(prettify(top))\n",
        "    #rough_string = ElementTree.tostring(top, 'utf-8')\n",
        "    #f.write(rough_string)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7ViuuP3IIeL"
      },
      "source": [
        "### Run Main "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvV0aTajHL1U"
      },
      "source": [
        "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
        "# Modifications Copyright 2017 Abigail See\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "\"\"\"This is the top-level file to train, evaluate or test your summarization model\"\"\"\n",
        "\n",
        "import time\n",
        "import os\n",
        "# import tensorflow as tf\n",
        "from collections import namedtuple\n",
        "#from data import Vocab\n",
        "#from batcher import Batcher\n",
        "#from model import SummarizationModel\n",
        "#from decode import BeamSearchDecoder\n",
        "#import util as util\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from tensorflow.python import debug as tf_debug\n",
        "#from replay_buffer import ReplayBuffer\n",
        "#from dqn import DQN\n",
        "from threading import Thread\n",
        "from tensorflow.python.ops import variable_scope\n",
        "from tensorflow.python.ops import array_ops\n",
        "from tensorflow.python.ops import gen_array_ops\n",
        "from tensorflow.python.ops import math_ops\n",
        "from tensorflow.python.ops.distributions import bernoulli\n",
        "\n",
        "\n",
        "#FLAGS = tf.app.flags.FLAGS\n",
        "#FLAGS.remove_flag_values(FLAGS.flag_values_dict()) #https://stackoverflow.com/questions/49916921/how-to-clear-tf-flags\n",
        "\n",
        "\n",
        "#https://stackoverflow.com/questions/40559667/how-to-redirect-tensorflow-logging-to-a-file\n",
        "import logging\n",
        "\n",
        "# get TF logger\n",
        "log = logging.getLogger('tensorflow')\n",
        "log.setLevel(logging.DEBUG)\n",
        "\n",
        "# create formatter and add it to the handlers\n",
        "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# create file handler which logs even debug messages\n",
        "fh = logging.FileHandler(tensorflow_log_file)\n",
        "fh.setLevel(logging.DEBUG)\n",
        "fh.setFormatter(formatter)\n",
        "log.addHandler(fh)\n",
        "\n",
        "\n",
        "class Seq2Seq(object):\n",
        "\n",
        "  def calc_running_avg_loss(self, loss, running_avg_loss, step, decay=0.99):\n",
        "    \"\"\"Calculate the running average loss via exponential decay.\n",
        "    This is used to implement early stopping w.r.t. a more smooth loss curve than the raw loss curve.\n",
        "    Args:\n",
        "      loss: loss on the most recent eval step\n",
        "      running_avg_loss: running_avg_loss so far\n",
        "      summary_writer: FileWriter object to write for tensorboard\n",
        "      step: training iteration step\n",
        "      decay: rate of exponential decay, a float between 0 and 1. Larger is smoother.\n",
        "    Returns:\n",
        "      running_avg_loss: new running average loss\n",
        "    \"\"\"\n",
        "    if running_avg_loss == 0:  # on the first iteration just take the loss\n",
        "      running_avg_loss = loss\n",
        "    else:\n",
        "      running_avg_loss = running_avg_loss * decay + (1 - decay) * loss\n",
        "    running_avg_loss = min(running_avg_loss, 12)  # clip\n",
        "    loss_sum = tf.Summary()\n",
        "    \n",
        "    tag_name = 'running_avg_loss/decay=%f' % (decay)\n",
        "    loss_sum.value.add(tag=tag_name, simple_value=running_avg_loss)\n",
        "    self.summary_writer.add_summary(loss_sum, step)\n",
        "    tf.compat.v1.logging.info('running_avg_loss: %f', running_avg_loss)\n",
        "    return running_avg_loss\n",
        "\n",
        "  def restore_best_model(self):\n",
        "    \"\"\"Load bestmodel file from eval directory, add variables for adagrad, and save to train directory\"\"\"\n",
        "    tf.compat.v1.logging.info(\"Restoring bestmodel for training...\")\n",
        "\n",
        "    # Initialize all vars in the model\n",
        "    #sess = tf.InteractiveSession(config=get_config())#me\n",
        "    sess = tf.Session(config=get_config())\n",
        "    print(\"Initializing all variables...\")\n",
        "    sess.run(tf.initialize_all_variables())\n",
        "    #tf.reset_default_graph() #me\n",
        "    # Restore the best model from eval dir\n",
        "    saver = tf.train.Saver([v for v in tf.all_variables() if \"Adagrad\" not in v.name])\n",
        "    print(\"Restoring all non-adagrad variables from best model in eval dir...\")\n",
        "    curr_ckpt = load_ckpt(saver, sess, \"eval\")\n",
        "    print(\"Restored %s.\" % curr_ckpt)\n",
        "\n",
        "    # Save this model to train dir and quit\n",
        "    new_model_name = curr_ckpt.split(\"/\")[-1].replace(\"bestmodel\", \"model\")\n",
        "    new_fname = os.path.join(FLAGS.log_root, \"train\", new_model_name)\n",
        "    print(\"Saving model to %s...\" % (new_fname))\n",
        "    \n",
        "    with open(log_file , \"a\") as logger_file:\n",
        "      logger_file.write(\"Saving model to %s...\" % (new_fname)+\"\\n\")\n",
        "\n",
        "    new_saver = tf.train.Saver() # this saver saves all variables that now exist, including Adagrad variables\n",
        "    new_saver.save(sess, new_fname)\n",
        "    print(\"Saved.\")\n",
        "    exit()\n",
        "\n",
        "  def restore_best_eval_model(self):\n",
        "    # load best evaluation loss so far\n",
        "    best_loss = None\n",
        "    best_step = None\n",
        "    # goes through all event files and select the best loss achieved and return it\n",
        "    event_files = sorted(glob('{}/eval/events*'.format(FLAGS.log_root)))\n",
        "    for ef in event_files:\n",
        "      try:\n",
        "        for e in tf.train.summary_iterator(ef):\n",
        "          for v in e.summary.value:\n",
        "            step = e.step\n",
        "            if 'running_avg_loss/decay' in v.tag:\n",
        "              running_avg_loss = v.simple_value\n",
        "              if best_loss is None or running_avg_loss < best_loss:\n",
        "                best_loss = running_avg_loss\n",
        "                best_step = step\n",
        "      except:\n",
        "        continue\n",
        "    tf.compat.v1.logging.info('resotring best loss from the current logs: {}\\tstep: {}'.format(best_loss, best_step))\n",
        "    return best_loss\n",
        "\n",
        "  def convert_to_coverage_model(self):\n",
        "    \"\"\"Load non-coverage checkpoint, add initialized extra variables for coverage, and save as new checkpoint\"\"\"\n",
        "    tf.compat.v1.logging.info(\"converting non-coverage model to coverage model..\")\n",
        "\n",
        "    # initialize an entire coverage model from scratch\n",
        "    sess = tf.Session(config=get_config())\n",
        "    print(\"initializing everything...\")\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    # load all non-coverage weights from checkpoint\n",
        "    saver = tf.train.Saver([v for v in tf.global_variables() if \"coverage\" not in v.name and \"Adagrad\" not in v.name])\n",
        "    print(\"restoring non-coverage variables...\")\n",
        "    curr_ckpt = load_ckpt(saver, sess)\n",
        "    print(\"restored.\")\n",
        "\n",
        "    # save this model and quit\n",
        "    new_fname = curr_ckpt + '_cov_init'\n",
        "    print(\"saving model to %s...\" % (new_fname))\n",
        "    new_saver = tf.train.Saver() # this one will save all variables that now exist\n",
        "    new_saver.save(sess, new_fname)\n",
        "    print(\"saved.\")\n",
        "    exit()\n",
        "\n",
        "  def convert_to_reinforce_model(self,word_vector):\n",
        "    \"\"\"Load non-reinforce checkpoint, add initialized extra variables for reinforce, and save as new checkpoint\"\"\"\n",
        "    tf.compat.v1.logging.info(\"converting non-reinforce model to reinforce model..\")\n",
        "\n",
        "    # initialize an entire reinforce model from scratch\n",
        "    sess = tf.Session(config=get_config())\n",
        "    print(\"initializing everything...\")\n",
        "    sess.run(tf.global_variables_initializer(),feed_dict={self.model.embedding_place:word_vector})\n",
        "\n",
        "    # load all non-reinforce weights from checkpoint\n",
        "    saver = tf.train.Saver([v for v in tf.global_variables() if \"reinforce\" not in v.name and \"Adagrad\" not in v.name])\n",
        "    print(\"restoring non-reinforce variables...\")\n",
        "    curr_ckpt = load_ckpt(saver, sess)\n",
        "    print(\"restored.\")\n",
        "\n",
        "    # save this model and quit\n",
        "    new_fname = curr_ckpt + '_rl_init'\n",
        "    print(\"saving model to %s...\" % (new_fname))\n",
        "    new_saver = tf.train.Saver() # this one will save all variables that now exist\n",
        "    new_saver.save(sess, new_fname)\n",
        "    print(\"saved.\")\n",
        "    exit()\n",
        "\n",
        "  def setup_training(self):\n",
        "    \"\"\"Does setup before starting training (run_training)\"\"\"    \n",
        "    train_dir = os.path.join(FLAGS.log_root, \"train\")\n",
        "    if not os.path.exists(train_dir): os.makedirs(train_dir)\n",
        "    if FLAGS.ac_training:\n",
        "      dqn_train_dir = os.path.join(FLAGS.log_root, \"dqn\", \"train\")\n",
        "      if not os.path.exists(dqn_train_dir): os.makedirs(dqn_train_dir)\n",
        "    #replaybuffer_pcl_path = os.path.join(FLAGS.log_root, \"replaybuffer.pcl\")\n",
        "    #if not os.path.exists(dqn_target_train_dir): os.makedirs(dqn_target_train_dir)\n",
        "\n",
        "    self.model.build_graph() # build the graph\n",
        "\n",
        "    # Loads pre-trained word-embedding. By default the model learns the embedding.\n",
        "    if FLAGS.embedding:\n",
        "      self.vocab.LoadWordEmbedding(FLAGS.embedding, FLAGS.emb_dim)\n",
        "      word_vector = self.vocab.getWordEmbedding()\n",
        "      \n",
        "    if FLAGS.convert_to_reinforce_model:\n",
        "      assert (FLAGS.rl_training or FLAGS.ac_training), \"To convert your pointer model to a reinforce model, run with convert_to_reinforce_model=True and either rl_training=True or ac_training=True\"\n",
        "      self.convert_to_reinforce_model(word_vector)\n",
        "    if FLAGS.convert_to_coverage_model:\n",
        "      assert FLAGS.coverage, \"To convert your non-coverage model to a coverage model, run with convert_to_coverage_model=True and coverage=True\"\n",
        "      self.convert_to_coverage_model()\n",
        "    if FLAGS.restore_best_model:\n",
        "      self.restore_best_model()\n",
        "    saver = tf.train.Saver(max_to_keep=3) # keep 3 checkpoints at a time\n",
        "\n",
        "    self.sv = tf.train.Supervisor(logdir=train_dir,\n",
        "                       is_chief=True,\n",
        "                       saver=saver,\n",
        "                       summary_op=None,\n",
        "                       save_summaries_secs=60, # save summaries for tensorboard every 60 secs\n",
        "                       save_model_secs=60, # checkpoint every 60 secs\n",
        "                       global_step=self.model.global_step,\n",
        "                       init_feed_dict= {self.model.embedding_place:word_vector} if FLAGS.embedding else None\n",
        "                       )\n",
        "    self.summary_writer = self.sv.summary_writer\n",
        "    self.sess = self.sv.prepare_or_wait_for_session(config=get_config())\n",
        "    if FLAGS.ac_training:\n",
        "      tf.compat.v1.logging.info('DDQN building graph')\n",
        "      t1 = time.time()\n",
        "      # We create a separate graph for DDQN\n",
        "      self.dqn_graph = tf.Graph()\n",
        "      with self.dqn_graph.as_default():\n",
        "        self.dqn.build_graph() # build dqn graph\n",
        "        tf.compat.v1.logging.info('building current network took {} seconds'.format(time.time()-t1))\n",
        "\n",
        "        self.dqn_target.build_graph() # build dqn target graph\n",
        "        tf.compat.v1.logging.info('building target network took {} seconds'.format(time.time()-t1))\n",
        "\n",
        "        dqn_saver = tf.train.Saver(max_to_keep=3) # keep 3 checkpoints at a time\n",
        "        self.dqn_sv = tf.train.Supervisor(logdir=dqn_train_dir,\n",
        "                           is_chief=True,\n",
        "                           saver=dqn_saver,\n",
        "                           summary_op=None,\n",
        "                           save_summaries_secs=60, # save summaries for tensorboard every 60 secs\n",
        "                           save_model_secs=60, # checkpoint every 60 secs\n",
        "                           global_step=self.dqn.global_step,\n",
        "                           )\n",
        "        self.dqn_summary_writer = self.dqn_sv.summary_writer\n",
        "        self.dqn_sess = self.dqn_sv.prepare_or_wait_for_session(config=get_config())\n",
        "      ''' #### TODO: try loading a previously saved replay buffer\n",
        "      # right now this doesn't work due to running DQN on a thread\n",
        "      if os.path.exists(replaybuffer_pcl_path):\n",
        "        tf.compat.v1.logging.info('Loading Replay Buffer...')\n",
        "        try:\n",
        "          self.replay_buffer = pickle.load(open(replaybuffer_pcl_path, \"rb\"))\n",
        "          tf.compat.v1.logging.info('Replay Buffer loaded...')\n",
        "        except:\n",
        "          tf.compat.v1.logging.info('Couldn\\'t load Replay Buffer file...')\n",
        "          self.replay_buffer = ReplayBuffer(self.dqn_hps)\n",
        "      else:\n",
        "        self.replay_buffer = ReplayBuffer(self.dqn_hps)\n",
        "      tf.compat.v1.logging.info(\"Building DDQN took {} seconds\".format(time.time()-t1))\n",
        "      '''\n",
        "      self.replay_buffer = ReplayBuffer(self.dqn_hps)\n",
        "    tf.compat.v1.logging.info(\"Preparing or waiting for session...\")\n",
        "    tf.compat.v1.logging.info(\"Created session.\")\n",
        "    try:\n",
        "      self.run_training() # this is an infinite loop until interrupted\n",
        "    except (KeyboardInterrupt, SystemExit):\n",
        "      tf.compat.v1.logging.info(\"Caught keyboard interrupt on worker. Stopping supervisor...\")\n",
        "      self.sv.stop()\n",
        "      if FLAGS.ac_training:\n",
        "        self.dqn_sv.stop()\n",
        "\n",
        "  def run_training(self):\n",
        "    \"\"\"Repeatedly runs training iterations, logging loss to screen and writing summaries\"\"\"\n",
        "    tf.compat.v1.logging.info(\"Starting run_training\")\n",
        "    \n",
        "    with open(log_file , \"a\") as logger_file:\n",
        "      logger_file.write(\"starting run_training..\\n\")\n",
        "    \n",
        "    if FLAGS.debug: # start the tensorflow debugger\n",
        "      self.sess = tf_debug.LocalCLIDebugWrapperSession(self.sess)\n",
        "      self.sess.add_tensor_filter(\"has_inf_or_nan\", tf_debug.has_inf_or_nan)\n",
        "\n",
        "    self.train_step = 0\n",
        "    if FLAGS.ac_training:\n",
        "      # DDQN training is done asynchronously along with model training\n",
        "      tf.compat.v1.logging.info('Starting DQN training thread...')\n",
        "      self.dqn_train_step = 0\n",
        "      self.thrd_dqn_training = Thread(target=self.dqn_training)\n",
        "      self.thrd_dqn_training.daemon = True\n",
        "      self.thrd_dqn_training.start()\n",
        "\n",
        "      watcher = Thread(target=self.watch_threads)\n",
        "      watcher.daemon = True\n",
        "      watcher.start()\n",
        "    # starting the main thread\n",
        "    tf.compat.v1.logging.info('Starting Seq2Seq training...')\n",
        "    \n",
        "    with open(log_file , \"a\") as logger_file:\n",
        "      logger_file.write(\"Starting Seq2Seq training...\\n\")\n",
        "      \n",
        "    while True: # repeats until interrupted\n",
        "      batch = self.batcher.next_batch()\n",
        "      t0=time.time()\n",
        "      if FLAGS.ac_training:\n",
        "        # For DDQN, we first collect the model output to calculate the reward and Q-estimates\n",
        "        # Then we fix the estimation either using our target network or using the true Q-values\n",
        "        # This process will usually take time and we are working on improving it.\n",
        "        transitions = self.model.collect_dqn_transitions(self.sess, batch, self.train_step, batch.max_art_oovs) # len(batch_size * k * max_dec_steps)\n",
        "        tf.compat.v1.logging.info('Q-values collection time: {}'.format(time.time()-t0))\n",
        "        # whenever we are working with the DDQN, we switch using DDQN graph rather than default graph\n",
        "        with self.dqn_graph.as_default():\n",
        "          batch_len = len(transitions)\n",
        "          # we use current decoder state to predict q_estimates, use_state_prime = False\n",
        "          b = ReplayBuffer.create_batch(self.dqn_hps, transitions,len(transitions), use_state_prime = False, max_art_oovs = batch.max_art_oovs)\n",
        "          # we also get the next decoder state to correct the estimation, use_state_prime = True\n",
        "          b_prime = ReplayBuffer.create_batch(self.dqn_hps, transitions,len(transitions), use_state_prime = True, max_art_oovs = batch.max_art_oovs)\n",
        "          # use current DQN to estimate values from current decoder state\n",
        "          dqn_results = self.dqn.run_test_steps(sess=self.dqn_sess, x= b._x, return_best_action=True)\n",
        "          q_estimates = dqn_results['estimates'] # shape (len(transitions), vocab_size)\n",
        "          dqn_best_action = dqn_results['best_action']\n",
        "          #dqn_q_estimate_loss = dqn_results['loss']\n",
        "\n",
        "          # use target DQN to estimate values for the next decoder state\n",
        "          dqn_target_results = self.dqn_target.run_test_steps(self.dqn_sess, x= b_prime._x)\n",
        "          q_vals_new_t = dqn_target_results['estimates'] # shape (len(transitions), vocab_size)\n",
        "\n",
        "          # we need to expand the q_estimates to match the input batch max_art_oov\n",
        "          # we use the q_estimate of UNK token for all the OOV tokens\n",
        "          q_estimates = np.concatenate([q_estimates,\n",
        "            np.reshape(q_estimates[:,0],[-1,1])*np.ones((len(transitions),batch.max_art_oovs))],axis=-1)\n",
        "          # modify Q-estimates using the result collected from current and target DQN.\n",
        "          # check algorithm 5 in the paper for more info: https://arxiv.org/pdf/1805.09461.pdf\n",
        "          for i, tr in enumerate(transitions):\n",
        "            if tr.done:\n",
        "              q_estimates[i][tr.action] = tr.reward\n",
        "            else:\n",
        "              q_estimates[i][tr.action] = tr.reward + FLAGS.gamma * q_vals_new_t[i][dqn_best_action[i]]\n",
        "          # use scheduled sampling to whether use true Q-values or DDQN estimation\n",
        "          if FLAGS.dqn_scheduled_sampling:\n",
        "            q_estimates = self.scheduled_sampling(batch_len, FLAGS.sampling_probability, b._y_extended, q_estimates)\n",
        "          if not FLAGS.calculate_true_q:\n",
        "            # when we are not training DDQN based on true Q-values,\n",
        "            # we need to update Q-values in our transitions based on the q_estimates we collected from DQN current network.\n",
        "            for trans, q_val in zip(transitions,q_estimates):\n",
        "              trans.q_values = q_val # each have the size vocab_extended\n",
        "          q_estimates = np.reshape(q_estimates, [FLAGS.batch_size, FLAGS.k, FLAGS.max_dec_steps, -1]) # shape (batch_size, k, max_dec_steps, vocab_size_extended)\n",
        "        # Once we are done with modifying Q-values, we can use them to train the DDQN model.\n",
        "        # In this paper, we use a priority experience buffer which always selects states with higher quality\n",
        "        # to train the DDQN. The following line will add batch_size * max_dec_steps experiences to the replay buffer.\n",
        "        # As mentioned before, the DDQN training is asynchronous. Therefore, once the related queues for DDQN training\n",
        "        # are full, the DDQN will start the training.\n",
        "        self.replay_buffer.add(transitions)\n",
        "        # If dqn_pretrain flag is on, it means that we use a fixed Actor to only collect experiences for\n",
        "        # DDQN pre-training\n",
        "        if FLAGS.dqn_pretrain:\n",
        "          tf.compat.v1.logging.info('RUNNNING DQN PRETRAIN: Adding data to relplay buffer only...')\n",
        "          continue\n",
        "        # if not, use the q_estimation to update the loss.\n",
        "        try:\n",
        "          results = self.model.run_train_steps(self.sess, batch, self.train_step, q_estimates)\n",
        "        except:\n",
        "          continue\n",
        "      else:\n",
        "        try:\n",
        "          results = self.model.run_train_steps(self.sess, batch, self.train_step)\n",
        "        except:\n",
        "          continue\n",
        "      t1=time.time()\n",
        "      # get the summaries and iteration number so we can write summaries to tensorboard\n",
        "      summaries = results['summaries'] # we will write these summaries to tensorboard using summary_writer\n",
        "      self.train_step = results['global_step'] # we need this to update our running average loss\n",
        "      tf.compat.v1.logging.info('seconds for training step {}: {}'.format(self.train_step, t1-t0))\n",
        "\n",
        "      printer_helper = {}\n",
        "      printer_helper['pgen_loss']= results['pgen_loss']\n",
        "      if FLAGS.coverage:\n",
        "        printer_helper['coverage_loss'] = results['coverage_loss']\n",
        "        if FLAGS.rl_training or FLAGS.ac_training:\n",
        "          printer_helper['rl_cov_total_loss']= results['reinforce_cov_total_loss']\n",
        "        else:\n",
        "          printer_helper['pointer_cov_total_loss'] = results['pointer_cov_total_loss']\n",
        "      if FLAGS.rl_training or FLAGS.ac_training:\n",
        "        printer_helper['shared_loss'] = results['shared_loss']\n",
        "        printer_helper['rl_loss'] = results['rl_loss']\n",
        "        printer_helper['rl_avg_logprobs'] = results['rl_avg_logprobs']\n",
        "      if FLAGS.rl_training:\n",
        "        printer_helper['sampled_r'] = np.mean(results['sampled_sentence_r_values'])\n",
        "        printer_helper['greedy_r'] = np.mean(results['greedy_sentence_r_values'])\n",
        "        printer_helper['r_diff'] = printer_helper['greedy_r'] - printer_helper['sampled_r']\n",
        "      if FLAGS.ac_training:\n",
        "        printer_helper['dqn_loss'] = np.mean(self.avg_dqn_loss) if len(self.avg_dqn_loss)>0 else 0\n",
        "\n",
        "      for (k,v) in printer_helper.items():\n",
        "        if not np.isfinite(v):\n",
        "          raise Exception(\"{} is not finite. Stopping.\".format(k))\n",
        "        tf.compat.v1.logging.info('{}: {}\\t'.format(k,v))\n",
        "        with open(log_file , \"a\") as logger_file:\n",
        "          logger_file.write(str(k )+\" : \" +str( v) +\"\\n\")\n",
        "          \n",
        "      with open(log_file , \"a\") as logger_file:\n",
        "          logger_file.write('-------------------------------------------')\n",
        "      tf.compat.v1.logging.info('-------------------------------------------')\n",
        "      \n",
        "      tf.compat.v1.logging.info('add_summary')\n",
        "      self.summary_writer.add_summary(summaries, self.train_step) # write the summaries\n",
        "      if self.train_step % 100 == 0: # flush the summary writer every so often\n",
        "        self.summary_writer.flush()\n",
        "      if FLAGS.ac_training:\n",
        "        self.dqn_summary_writer.flush()\n",
        "      ###if self.train_step > FLAGS.max_iter: break\n",
        "\n",
        "  def dqn_training(self):\n",
        "    \"\"\" training the DDQN network.\"\"\"\n",
        "    try:\n",
        "      while True:\n",
        "        if self.dqn_train_step == FLAGS.dqn_pretrain_steps: raise SystemExit()\n",
        "        _t = time.time()\n",
        "        self.avg_dqn_loss = []\n",
        "        avg_dqn_target_loss = []\n",
        "        # Get a batch of size dqn_batch_size from replay buffer to train the model\n",
        "        dqn_batch = self.replay_buffer.next_batch()\n",
        "        if dqn_batch is None:\n",
        "          tf.compat.v1.logging.info('replay buffer not loaded enough yet...')\n",
        "          time.sleep(60)\n",
        "          continue\n",
        "        # Run train step for Current DQN model and collect the results\n",
        "        dqn_results = self.dqn.run_train_steps(self.dqn_sess, dqn_batch)\n",
        "        # Run test step for Target DQN model and collect the results and monitor the difference in loss between the two\n",
        "        dqn_target_results = self.dqn_target.run_test_steps(self.dqn_sess, x=dqn_batch._x, y=dqn_batch._y, return_loss=True)\n",
        "        self.dqn_train_step = dqn_results['global_step']\n",
        "        self.dqn_summary_writer.add_summary(dqn_results['summaries'], self.dqn_train_step) # write the summaries\n",
        "        self.avg_dqn_loss.append(dqn_results['loss'])\n",
        "        avg_dqn_target_loss.append(dqn_target_results['loss'])\n",
        "        self.dqn_train_step = self.dqn_train_step + 1\n",
        "        tf.compat.v1.logging.info('seconds for training dqn model: {}'.format(time.time()-_t))\n",
        "        # UPDATING TARGET DDQN NETWORK WITH CURRENT MODEL\n",
        "        with self.dqn_graph.as_default():\n",
        "          current_model_weights = self.dqn_sess.run([self.dqn.model_trainables])[0] # get weights of current model\n",
        "          self.dqn_target.run_update_weights(self.dqn_sess, self.dqn_train_step, current_model_weights) # update target model weights with current model weights\n",
        "        tf.compat.v1.logging.info('DQN loss at step {}: {}'.format(self.dqn_train_step, np.mean(self.avg_dqn_loss)))\n",
        "        tf.compat.v1.logging.info('DQN Target loss at step {}: {}'.format(self.dqn_train_step, np.mean(avg_dqn_target_loss)))\n",
        "        # sleeping is required if you want the keyboard interuption to work\n",
        "        time.sleep(FLAGS.dqn_sleep_time)\n",
        "    except (KeyboardInterrupt, SystemExit):\n",
        "      tf.compat.v1.logging.info(\"Caught keyboard interrupt on worker. Stopping supervisor...\")\n",
        "      self.sv.stop()\n",
        "      self.dqn_sv.stop()\n",
        "\n",
        "  def watch_threads(self):\n",
        "    \"\"\"Watch example queue and batch queue threads and restart if dead.\"\"\"\n",
        "    while True:\n",
        "      time.sleep(60)\n",
        "      if not self.thrd_dqn_training.is_alive(): # if the thread is dead\n",
        "        tf.compat.v1.logging.error('Found DQN Learning thread dead. Restarting.')\n",
        "        self.thrd_dqn_training = Thread(target=self.dqn_training)\n",
        "        self.thrd_dqn_training.daemon = True\n",
        "        self.thrd_dqn_training.start()\n",
        "\n",
        "  def run_eval(self):\n",
        "    \"\"\"Repeatedly runs eval iterations, logging to screen and writing summaries. Saves the model with the best loss seen so far.\"\"\"\n",
        "    self.model.build_graph() # build the graph\n",
        "    saver = tf.train.Saver(max_to_keep=3) # we will keep 3 best checkpoints at a time\n",
        "    sess = tf.Session(config=get_config())\n",
        "\n",
        "    if FLAGS.embedding:\n",
        "      sess.run(tf.global_variables_initializer(),feed_dict={self.model.embedding_place:self.word_vector})\n",
        "    eval_dir = os.path.join(FLAGS.log_root, \"eval\") # make a subdir of the root dir for eval data\n",
        "    bestmodel_save_path = os.path.join(eval_dir, 'bestmodel') # this is where checkpoints of best models are saved\n",
        "    self.summary_writer = tf.summary.FileWriter(eval_dir)\n",
        "\n",
        "    if FLAGS.ac_training:\n",
        "      tf.compat.v1.logging.info('DDQN building graph')\n",
        "      t1 = time.time()\n",
        "      dqn_graph = tf.Graph()\n",
        "      with dqn_graph.as_default():\n",
        "        self.dqn.build_graph() # build dqn graph\n",
        "        tf.compat.v1.logging.info('building current network took {} seconds'.format(time.time()-t1))\n",
        "        self.dqn_target.build_graph() # build dqn target graph\n",
        "        tf.compat.v1.logging.info('building target network took {} seconds'.format(time.time()-t1))\n",
        "        dqn_saver = tf.train.Saver(max_to_keep=3) # keep 3 checkpoints at a time\n",
        "        dqn_sess = tf.Session(config=get_config())\n",
        "      dqn_train_step = 0\n",
        "      replay_buffer = ReplayBuffer(self.dqn_hps)\n",
        "\n",
        "    running_avg_loss = 0 # the eval job keeps a smoother, running average loss to tell it when to implement early stopping\n",
        "    best_loss = self.restore_best_eval_model()  # will hold the best loss achieved so far\n",
        "    train_step = 0\n",
        "\n",
        "    while True:\n",
        "      _ = load_ckpt(saver, sess) # load a new checkpoint\n",
        "      if FLAGS.ac_training:\n",
        "        _ = load_dqn_ckpt(dqn_saver, dqn_sess) # load a new checkpoint\n",
        "      processed_batch = 0\n",
        "      avg_losses = []\n",
        "      # evaluate for 100 * batch_size before comparing the loss\n",
        "      # we do this due to memory constraint, best to run eval on different machines with large batch size\n",
        "      while processed_batch < 100*FLAGS.batch_size:\n",
        "        processed_batch += FLAGS.batch_size\n",
        "        batch = self.batcher.next_batch() # get the next batch\n",
        "        if FLAGS.ac_training:\n",
        "          t0 = time.time()\n",
        "          transitions = self.model.collect_dqn_transitions(sess, batch, train_step, batch.max_art_oovs) # len(batch_size * k * max_dec_steps)\n",
        "          tf.compat.v1.logging.info('Q values collection time: {}'.format(time.time()-t0))\n",
        "          with dqn_graph.as_default():\n",
        "            # if using true Q-value to train DQN network,\n",
        "            # we do this as the pre-training for the DQN network to get better estimates\n",
        "            batch_len = len(transitions)\n",
        "            b = ReplayBuffer.create_batch(self.dqn_hps, transitions,len(transitions), use_state_prime = True, max_art_oovs = batch.max_art_oovs)\n",
        "            b_prime = ReplayBuffer.create_batch(self.dqn_hps, transitions,len(transitions), use_state_prime = True, max_art_oovs = batch.max_art_oovs)\n",
        "            dqn_results = self.dqn.run_test_steps(sess=dqn_sess, x= b._x, return_best_action=True)\n",
        "            q_estimates = dqn_results['estimates'] # shape (len(transitions), vocab_size)\n",
        "            dqn_best_action = dqn_results['best_action']\n",
        "\n",
        "            tf.compat.v1.logging.info('running test step on dqn_target')\n",
        "            dqn_target_results = self.dqn_target.run_test_steps(dqn_sess, x= b_prime._x)\n",
        "            q_vals_new_t = dqn_target_results['estimates'] # shape (len(transitions), vocab_size)\n",
        "\n",
        "            # we need to expand the q_estimates to match the input batch max_art_oov\n",
        "            q_estimates = np.concatenate([q_estimates,np.zeros((len(transitions),batch.max_art_oovs))],axis=-1)\n",
        "\n",
        "            tf.compat.v1.logging.info('fixing the action q-estimates')\n",
        "            for i, tr in enumerate(transitions):\n",
        "              if tr.done:\n",
        "                q_estimates[i][tr.action] = tr.reward\n",
        "              else:\n",
        "                q_estimates[i][tr.action] = tr.reward + FLAGS.gamma * q_vals_new_t[i][dqn_best_action[i]]\n",
        "            if FLAGS.dqn_scheduled_sampling:\n",
        "              tf.compat.v1.logging.info('scheduled sampling on q-estimates')\n",
        "              q_estimates = self.scheduled_sampling(batch_len, FLAGS.sampling_probability, b._y_extended, q_estimates)\n",
        "            if not FLAGS.calculate_true_q:\n",
        "              # when we are not training DQN based on true Q-values\n",
        "              # we need to update Q-values in our transitions based on this q_estimates we collected from DQN current network.\n",
        "              for trans, q_val in zip(transitions,q_estimates):\n",
        "                trans.q_values = q_val # each have the size vocab_extended\n",
        "            q_estimates = np.reshape(q_estimates, [FLAGS.batch_size, FLAGS.k, FLAGS.max_dec_steps, -1]) # shape (batch_size, k, max_dec_steps, vocab_size_extended)\n",
        "          tf.compat.v1.logging.info('run eval step on seq2seq model.')\n",
        "          t0=time.time()\n",
        "          results = self.model.run_eval_step(sess, batch, train_step, q_estimates)\n",
        "          t1=time.time()\n",
        "        else:\n",
        "          tf.compat.v1.logging.info('run eval step on seq2seq model.')\n",
        "          t0=time.time()\n",
        "          results = self.model.run_eval_step(sess, batch, train_step)\n",
        "          t1=time.time()\n",
        "\n",
        "        tf.compat.v1.logging.info('experiment: {}'.format(FLAGS.exp_name))\n",
        "        tf.compat.v1.logging.info('processed_batch: {}, seconds for batch: {}'.format(processed_batch, t1-t0))\n",
        "\n",
        "        printer_helper = {}\n",
        "        loss = printer_helper['pgen_loss']= results['pgen_loss']\n",
        "        if FLAGS.coverage:\n",
        "          printer_helper['coverage_loss'] = results['coverage_loss']\n",
        "          if FLAGS.rl_training or FLAGS.ac_training:\n",
        "            printer_helper['rl_cov_total_loss']= results['reinforce_cov_total_loss']\n",
        "          loss = printer_helper['pointer_cov_total_loss'] = results['pointer_cov_total_loss']\n",
        "        if FLAGS.rl_training or FLAGS.ac_training:\n",
        "          printer_helper['shared_loss'] = results['shared_loss']\n",
        "          printer_helper['rl_loss'] = results['rl_loss']\n",
        "          printer_helper['rl_avg_logprobs'] = results['rl_avg_logprobs']\n",
        "        if FLAGS.rl_training:\n",
        "          printer_helper['sampled_r'] = np.mean(results['sampled_sentence_r_values'])\n",
        "          printer_helper['greedy_r'] = np.mean(results['greedy_sentence_r_values'])\n",
        "          printer_helper['r_diff'] = printer_helper['greedy_r'] - printer_helper['sampled_r']\n",
        "        if FLAGS.ac_training:\n",
        "          printer_helper['dqn_loss'] = np.mean(self.avg_dqn_loss) if len(self.avg_dqn_loss) > 0 else 0\n",
        "\n",
        "        for (k,v) in printer_helper.items():\n",
        "          if not np.isfinite(v):\n",
        "            raise Exception(\"{} is not finite. Stopping.\".format(k))\n",
        "          tf.compat.v1.logging.info('{}: {}\\t'.format(k,v))\n",
        "\n",
        "        # add summaries\n",
        "        summaries = results['summaries']\n",
        "        train_step = results['global_step']\n",
        "        self.summary_writer.add_summary(summaries, train_step)\n",
        "\n",
        "        # calculate running avg loss\n",
        "        avg_losses.append(self.calc_running_avg_loss(np.asscalar(loss), running_avg_loss, train_step))\n",
        "        tf.compat.v1.logging.info('-------------------------------------------')\n",
        "\n",
        "      running_avg_loss = np.mean(avg_losses)\n",
        "      tf.compat.v1.logging.info('==========================================')\n",
        "      tf.compat.v1.logging.info('best_loss: {}\\trunning_avg_loss: {}\\t'.format(best_loss, running_avg_loss))\n",
        "      tf.compat.v1.logging.info('==========================================')\n",
        "\n",
        "      # If running_avg_loss is best so far, save this checkpoint (early stopping).\n",
        "      # These checkpoints will appear as bestmodel-<iteration_number> in the eval dir\n",
        "      if best_loss is None or running_avg_loss < best_loss:\n",
        "        tf.compat.v1.logging.info('Found new best model with %.3f running_avg_loss. Saving to %s', running_avg_loss, bestmodel_save_path)\n",
        "        saver.save(sess, bestmodel_save_path, global_step=train_step, latest_filename='checkpoint_best')\n",
        "        best_loss = running_avg_loss\n",
        "\n",
        "      # flush the summary writer every so often\n",
        "      if train_step % 100 == 0:\n",
        "        self.summary_writer.flush()\n",
        "      #time.sleep(600) # run eval every 10 minute\n",
        "\n",
        "  def main(self):\n",
        "    #if len(unused_argv) != 1: # prints a message if you've entered flags incorrectly\n",
        "    #  raise Exception(\"Problem with flags: %s\" % unused_argv)\n",
        "\n",
        "    #tf.reset_default_graph()\n",
        "\n",
        "    #FLAGS.log_root = os.path.join(FLAGS.log_root, FLAGS.exp_name)\n",
        "    tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO) # choose what level of logging you want\n",
        "    tf.compat.v1.logging.info('Starting seq2seq_attention in %s mode...', (FLAGS.mode))\n",
        "\n",
        "    # Change log_root to FLAGS.log_root/FLAGS.exp_name and create the dir if necessary\n",
        "    #flags = getattr(FLAGS,\"__flags\")\n",
        "\n",
        "    if not os.path.exists(FLAGS.log_root):\n",
        "      if FLAGS.mode==\"train\":\n",
        "        os.makedirs(FLAGS.log_root)\n",
        "      else:\n",
        "        raise Exception(\"Logdir %s doesn't exist. Run in train mode to create it.\" % (FLAGS.log_root))\n",
        "\n",
        "    fw = open('{}/config.txt'.format(FLAGS.log_root), 'w')\n",
        "    #for k, v in flags.items():\n",
        "    #  fw.write('{}\\t{}\\n'.format(k, v))\n",
        "    #fw.close()\n",
        "\n",
        "    self.vocab = Vocab(FLAGS.vocab_path, FLAGS.vocab_size) # create a vocabulary\n",
        "\n",
        "    # If in decode mode, set batch_size = beam_size\n",
        "    # Reason: in decode mode, we decode one example at a time.\n",
        "    # On each step, we have beam_size-many hypotheses in the beam, so we need to make a batch of these hypotheses.\n",
        "    if FLAGS.mode == 'decode':\n",
        "      FLAGS.batch_size = FLAGS.beam_size\n",
        "\n",
        "    # If single_pass=True, check we're in decode mode\n",
        "    if FLAGS.single_pass and FLAGS.mode!='decode':\n",
        "      raise Exception(\"The single_pass flag should only be True in decode mode\")\n",
        "\n",
        "    # Make a namedtuple hps, containing the values of the hyperparameters that the model needs\n",
        "\n",
        "    hparam_list = ['mode', 'lr', 'gpu_num',\n",
        "    #'sampled_greedy_flag', \n",
        "    'gamma', 'eta', \n",
        "    'fixed_eta', 'reward_function', 'intradecoder', \n",
        "    'use_temporal_attention', 'ac_training','rl_training', 'matrix_attention', 'calculate_true_q',\n",
        "    'enc_hidden_dim', 'dec_hidden_dim', 'k', \n",
        "    'scheduled_sampling', 'sampling_probability','fixed_sampling_probability',\n",
        "    'alpha', 'hard_argmax', 'greedy_scheduled_sampling',\n",
        "    'adagrad_init_acc', 'rand_unif_init_mag', \n",
        "    'trunc_norm_init_std', 'max_grad_norm', \n",
        "    'emb_dim', 'batch_size', 'max_dec_steps', 'max_enc_steps',\n",
        "    'dqn_scheduled_sampling', 'dqn_sleep_time', 'E2EBackProp',\n",
        "    'coverage', 'cov_loss_wt', 'pointer_gen']\n",
        "    hps_dict = {}\n",
        "    \n",
        "    flag_members = [attr for attr in dir(FLAGS) if not callable(getattr(FLAGS, attr)) and not attr.startswith(\"__\")]\n",
        "    for m in flag_members:\n",
        "        hps_dict[m] = getattr(FLAGS, m)\n",
        "        \n",
        "    if FLAGS.ac_training:\n",
        "      hps_dict.update({'dqn_input_feature_len':(FLAGS.dec_hidden_dim)})\n",
        "    self.hps = namedtuple(\"HParams\", hps_dict.keys())(**hps_dict)\n",
        "    # creating all the required parameters for DDQN model.\n",
        "    if FLAGS.ac_training:\n",
        "      hparam_list = ['lr', 'dqn_gpu_num', \n",
        "      'dqn_layers', \n",
        "      'dqn_replay_buffer_size', \n",
        "      'dqn_batch_size', \n",
        "      'dqn_target_update',\n",
        "      'dueling_net',\n",
        "      'dqn_polyak_averaging',\n",
        "      'dqn_sleep_time',\n",
        "      'dqn_scheduled_sampling',\n",
        "      'max_grad_norm']\n",
        "      hps_dict = {}\n",
        "      \n",
        "      flag_members = [attr for attr in dir(FLAGS) if not callable(getattr(FLAGS, attr)) and not attr.startswith(\"__\")]\n",
        "      for m in flag_members:\n",
        "        hps_dict[m] = getattr(FLAGS, m)\n",
        "    \n",
        "      hps_dict.update({'dqn_input_feature_len':(FLAGS.dec_hidden_dim)})\n",
        "      hps_dict.update({'vocab_size':self.vocab.size()})\n",
        "      self.dqn_hps = namedtuple(\"HParams\", hps_dict.keys())(**hps_dict)\n",
        "\n",
        "    # Create a batcher object that will create minibatches of data\n",
        "    self.batcher = Batcher(FLAGS.data_path, FLAGS.csv, self.vocab, self.hps, single_pass=FLAGS.single_pass, decode_after=FLAGS.decode_after)\n",
        "\n",
        "    #tf.random.set_seed(111) # a seed value for randomness\n",
        "\n",
        "    if self.hps.mode == 'train':\n",
        "      print(\"creating model...\")\n",
        "      self.model = SummarizationModel(self.hps, self.vocab)\n",
        "      if FLAGS.ac_training:\n",
        "        # current DQN with paramters \\Psi\n",
        "        self.dqn = DQN(self.dqn_hps,'current')\n",
        "        # target DQN with paramters \\Psi^{\\prime}\n",
        "        self.dqn_target = DQN(self.dqn_hps,'target')\n",
        "      self.setup_training()\n",
        "    elif self.hps.mode == 'eval':\n",
        "      self.model = SummarizationModel(self.hps, self.vocab)\n",
        "      if FLAGS.ac_training:\n",
        "        self.dqn = DQN(self.dqn_hps,'current')\n",
        "        self.dqn_target = DQN(self.dqn_hps,'target')\n",
        "      self.run_eval()\n",
        "    elif self.hps.mode == 'decode':\n",
        "      decode_model_hps = self.hps  # This will be the hyperparameters for the decoder model\n",
        "      decode_model_hps = self.hps._replace(max_dec_steps=1) # The model is configured with max_dec_steps=1 because we only ever run one step of the decoder at a time (to do beam search). Note that the batcher is initialized with max_dec_steps equal to e.g. 100 because the batches need to contain the full summaries\n",
        "      model = SummarizationModel(decode_model_hps, self.vocab)\n",
        "      if FLAGS.ac_training:\n",
        "        # We need our target DDQN network for collecting Q-estimation at each decoder step.\n",
        "        dqn_target = DQN(self.dqn_hps,'target')\n",
        "      else:\n",
        "        dqn_target = None\n",
        "      decoder = BeamSearchDecoder(model, self.batcher, self.vocab, dqn = dqn_target)\n",
        "      decoder.decode() # decode indefinitely (unless single_pass=True, in which case deocde the dataset exactly once)\n",
        "    else:\n",
        "      raise ValueError(\"The 'mode' flag must be one of train/eval/decode\")\n",
        "\n",
        "  # Scheduled sampling used for either selecting true Q-estimates or the DDQN estimation\n",
        "  # based on https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/ScheduledEmbeddingTrainingHelper\n",
        "  def scheduled_sampling(self, batch_size, sampling_probability, true, estimate):\n",
        "    with variable_scope.variable_scope(\"ScheduledEmbedding\"):\n",
        "      # Return -1s where we do not sample, and sample_ids elsewhere\n",
        "      select_sampler = bernoulli.Bernoulli(probs=sampling_probability, dtype=tf.bool)\n",
        "      select_sample = select_sampler.sample(sample_shape=batch_size)\n",
        "      sample_ids = array_ops.where(\n",
        "                  select_sample,\n",
        "                  tf.range(batch_size),\n",
        "                  gen_array_ops.fill([batch_size], -1))\n",
        "      where_sampling = math_ops.cast(\n",
        "          array_ops.where(sample_ids > -1), tf.int32)\n",
        "      where_not_sampling = math_ops.cast(\n",
        "          array_ops.where(sample_ids <= -1), tf.int32)\n",
        "      _estimate = array_ops.gather_nd(estimate, where_sampling)\n",
        "      _true = array_ops.gather_nd(true, where_not_sampling)\n",
        "\n",
        "      base_shape = array_ops.shape(true)\n",
        "      result1 = array_ops.scatter_nd(indices=where_sampling, updates=_estimate, shape=base_shape)\n",
        "      result2 = array_ops.scatter_nd(indices=where_not_sampling, updates=_true, shape=base_shape)\n",
        "      result = result1 + result2\n",
        "      return result1 + result2\n",
        "\n",
        "def main():\n",
        "  seq2seq = Seq2Seq()\n",
        "  seq2seq.main()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yn3MxAybHj68"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbiV0YM0O0MO"
      },
      "source": [
        "### Build dict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2_-bx_XXEaS"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import collections\n",
        "\n",
        "def build_dict(train_article_list,VOCAB_SIZE):\n",
        "    vocab_counter = collections.Counter()\n",
        "\n",
        "    progress = ProgressBar(len(train_article_list ), fmt=ProgressBar.FULL)\n",
        "    for sentence in train_article_list :\n",
        "        words = list()\n",
        "        for word in word_tokenize(sentence):\n",
        "            words.append(word)\n",
        "        vocab_counter.update(words)\n",
        "        progress.current += 1\n",
        "        progress()\n",
        "    progress.done()\n",
        "    \n",
        "    print (\"Writing vocab file...\")\n",
        "    with open(os.path.join(pickle_path, \"vocab\"), 'w', encoding=\"utf-8\") as writer:\n",
        "      for word, count in vocab_counter.most_common(VOCAB_SIZE):\n",
        "        writer.write(word + ' ' + str(count) + '\\n')\n",
        "    print (\"Finished writing vocab file\")\n",
        "    return "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WnTaVf6jQwy",
        "outputId": "23129b85-2c9b-4318-e116-3141def8ceed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "reviews = pd.read_csv(default_path + \"train.csv\")\n",
        "reviews.shape\n",
        "reviews.isnull().sum()\n",
        "reviews = reviews.dropna()\n",
        "reviews = reviews.reset_index(drop=True)\n",
        "reviews.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            headline  \\\n",
              "0  EXCLUSIVE: दिल्ली में डीजल टैक्सियों पर बैन से...   \n",
              "1  जॉर्डन: राष्ट्रपति मुखर्जी ने 86 करोड़ डॉलर के...   \n",
              "2  UN में पाकिस्तान की राजदूत मलीहा लोधी ने कराई ...   \n",
              "3  38 देशों में पीएम नरेंद्र मोदी बायोपिक को रिली...   \n",
              "4           13 अगस्त 2011: दिनभर की बड़ी खबरें पढ़ें   \n",
              "\n",
              "                                             article  \n",
              "0  दिल्ली में सुप्रीम कोर्ट के डीज़ल टैक्सियों को...  \n",
              "1  जॉर्डन के ऐतिहासिक दौरे पर पहुंचे राष्ट्रपति प...  \n",
              "2  पाकिस्तानी नेताओं को विवादित और हास्यास्पद बया...  \n",
              "3  पीएम नरेंद्र मोदी बायोपिक में विवेक ओबेरॉय ने ...  \n",
              "4  देश, दुनिया, महानगर, खेल, आर्थिक और बॉलीवुड मे...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-51383ca1-8bec-4145-be17-c8e5e61e715b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>article</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>EXCLUSIVE: दिल्ली में डीजल टैक्सियों पर बैन से...</td>\n",
              "      <td>दिल्ली में सुप्रीम कोर्ट के डीज़ल टैक्सियों को...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>जॉर्डन: राष्ट्रपति मुखर्जी ने 86 करोड़ डॉलर के...</td>\n",
              "      <td>जॉर्डन के ऐतिहासिक दौरे पर पहुंचे राष्ट्रपति प...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>UN में पाकिस्तान की राजदूत मलीहा लोधी ने कराई ...</td>\n",
              "      <td>पाकिस्तानी नेताओं को विवादित और हास्यास्पद बया...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>38 देशों में पीएम नरेंद्र मोदी बायोपिक को रिली...</td>\n",
              "      <td>पीएम नरेंद्र मोदी बायोपिक में विवेक ओबेरॉय ने ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13 अगस्त 2011: दिनभर की बड़ी खबरें पढ़ें</td>\n",
              "      <td>देश, दुनिया, महानगर, खेल, आर्थिक और बॉलीवुड मे...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51383ca1-8bec-4145-be17-c8e5e61e715b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-51383ca1-8bec-4145-be17-c8e5e61e715b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-51383ca1-8bec-4145-be17-c8e5e61e715b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oILyfJvtOKBX",
        "outputId": "6f34392d-40c0-4984-ec2b-3acd5b5ec161",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Text = []\n",
        "Summary = []\n",
        "\n",
        "progress = ProgressBar(len(reviews), fmt=ProgressBar.FULL)\n",
        "\n",
        "for index , row in reviews.iterrows():\n",
        "  Text.append(row[\"article\"])\n",
        "  Summary.append(row[\"headline\"])\n",
        "  progress.current += 1\n",
        "  progress()\n",
        "progress.done()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[========================================] 266593/266593 (100%)      0 to go\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_uuQ4DQbLLj"
      },
      "source": [
        "build_dict(reviews.article,200000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lA1gzm7P-Ly"
      },
      "source": [
        "df= None\n",
        "Text= None\n",
        "Summary= None\n",
        "Data= None"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ww6wYED7O5Z0"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoSZqBs7P5Pe"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "reviews = pd.read_csv(default_path + \"train.csv\")\n",
        "reviews.shape\n",
        "reviews.isnull().sum()\n",
        "reviews = reviews.dropna()\n",
        "reviews = reviews.reset_index(drop=True)\n",
        "reviews.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()"
      ],
      "metadata": {
        "id": "_jz8ygZxSdBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uz_50XkKdQWw"
      },
      "source": [
        "#import sys\n",
        "#reload(sys)\n",
        "#sys.setdefaultencoding('utf-8')\n",
        "\n",
        "class flags_:\n",
        "  pass\n",
        "FLAGS = flags_()\n",
        "\n",
        "article = []\n",
        "reference = []\n",
        "summary = []\n",
        "\n",
        "default_path = \"drive/My Drive/hindi_dataset/\"\n",
        "data_path = \"drive/My Drive/Colab Notebooks/Model 4_5/arabic_finished_files_200k_correct/\" #not used\n",
        "\n",
        "# Where to find data\n",
        "FLAGS.data_path = data_path + 'chunked/train_*' #not used\n",
        "FLAGS.vocab_path = default_path + 'pickles/vocab'\n",
        "\n",
        "# Important settings\n",
        "FLAGS.mode = 'train' \n",
        "FLAGS.single_pass = False  #true --> decode      false--> train\n",
        "FLAGS.decode_after = 0\n",
        "FLAGS.decode_from = 'train'\n",
        "\n",
        "if FLAGS.mode =='train':\n",
        "  FLAGS.csv = reviews[1000:] #train\n",
        "elif FLAGS.mode =='decode':\n",
        "  FLAGS.csv = reviews[:1000] #test #reviews[-1000:] #test\n",
        "  \n",
        "# Where to save output\n",
        "FLAGS.log_root = default_path +'logs_6_12'  \n",
        "FLAGS.exp_name = 'scheduled-sampling-hardargmax-greedy'\n",
        "\n",
        "# batcher parameter#, for consistent results#, set all these parameters to 1\n",
        "FLAGS.example_queue_threads = 4\n",
        "FLAGS.batch_queue_threads   = 2\n",
        "FLAGS.bucketing_cache_size  = 100\n",
        "\n",
        "# Hyperparameters\n",
        "\n",
        "FLAGS.enc_hidden_dim= 256##, 'dimension of RNN hidden states')\n",
        "FLAGS.dec_hidden_dim= 256##, 'dimension of RNN hidden states')\n",
        "FLAGS.emb_dim= 150 # 'dimension of word embeddings')\n",
        "FLAGS.batch_size=20# , 'minibatch size')\n",
        "FLAGS.max_enc_steps= 400 #100#, 'max timesteps of encoder (max source text tokens)')\n",
        "FLAGS.max_dec_steps= 15 #20#, 'max timesteps of decoder (max summary tokens)')\n",
        "FLAGS.beam_size= 35##, 'beam size for beam search decoding.')\n",
        "FLAGS.min_dec_steps= 20 #20##, 'Minimum sequence length of generated summary. Applies only for beam search decoding mode')\n",
        "FLAGS.max_iter= 20000  #40000##, 'max number of iterations')\n",
        "FLAGS.vocab_size= 50000##, 'Size of vocabulary. These will be read from the vocabulary file in order. If the vocabulary file contains fewer words than this number#, or if this number is set to 0#, will take all words in the vocabulary file.')\n",
        "FLAGS.lr= 0.15##, 'learning rate')\n",
        "FLAGS.adagrad_init_acc= 0.1##, 'initial accumulator value for Adagrad')\n",
        "FLAGS.rand_unif_init_mag= 0.02##, 'magnitude for lstm cells random uniform inititalization')\n",
        "FLAGS.trunc_norm_init_std= 1e-4##, 'std of trunc norm init#, used for initializing everything else')\n",
        "FLAGS.max_grad_norm= 5.0##, 'for gradient clipping')\n",
        "FLAGS.embedding= default_path +\"model_hindi.model\" #False#None##, 'path to the pre-trained embedding file')\n",
        "FLAGS.gpu_num= 0##, 'which gpu to use to train the model')\n",
        "\n",
        "# Pointer-generator or baseline model\n",
        "FLAGS.pointer_gen= True##, 'If True#, use pointer-generator model. If False#, use baseline model.')\n",
        "FLAGS.avoid_trigrams= True##, 'Avoids trigram during decoding')\n",
        "FLAGS.share_decoder_weights= False##, 'Share output matrix projection with word embedding') # Eq 13. in https://arxiv.org/pdf/1705.04304.pdf\n",
        "\n",
        "# Pointer-generator with Self-Critic policy gradient: https://arxiv.org/pdf/1705.04304.pdf\n",
        "FLAGS.rl_training= False #True#, 'Use policy-gradient training by collecting rewards at the end of sequence.')\n",
        "FLAGS.self_critic= True#, 'Uses greedy sentence reward as baseline.')\n",
        "FLAGS.use_discounted_rewards= False#, 'Whether to use discounted rewards.')\n",
        "FLAGS.use_intermediate_rewards= False#, 'Whether to use intermediate rewards.')\n",
        "FLAGS.convert_to_reinforce_model= False #True#, 'Convert a pointer model to a reinforce model. Turn this on and run in train mode.\n",
        "#Your current training model will be copied to a new version (same name with _cov_init appended) \n",
        "#that will be ready to run with coverage flag turned on#, for the coverage training stage.')\n",
        "FLAGS.intradecoder= True#, #%# 'Use intradecoder attention or not')\n",
        "FLAGS.use_temporal_attention=  True# #%#, 'Whether to use temporal attention or not')\n",
        "FLAGS.matrix_attention= False#, 'Use matrix attention#, Eq. 2 https://arxiv.org/pdf/1705.04304.pdf')\n",
        "FLAGS.eta= 2.5E-05#, 'RL/MLE scaling factor#, 1 means use RL loss#, 0 means use MLE loss')\n",
        "FLAGS.fixed_eta= False#, 'Use fixed value for eta or adaptive based on global step')\n",
        "FLAGS.gamma= 0.99#, 'discount factor')\n",
        "FLAGS.reward_function= 'rouge_l/f_score'#, 'either bleu or one of the rouge measures (rouge_1/f_score#,rouge_2/f_score#,rouge_l/f_score)')\n",
        "\n",
        "# parameters of DDQN model\n",
        "FLAGS.ac_training= False#, 'Use Actor-Critic learning by DDQN.')\n",
        "FLAGS.dqn_scheduled_sampling= True #, 'Whether to use scheduled sampling to use estimates of dqn model vs the actual q-estimates values')\n",
        "FLAGS.dqn_layers= '512,256,128'#, 'DQN dense hidden layer size#, will create three dense layers with 512#, 256#, and 128 size')\n",
        "FLAGS.dqn_replay_buffer_size= 100000#, 'Size of the replay buffer')\n",
        "FLAGS.dqn_batch_size= 100#, 'Batch size for training the DDQN model')\n",
        "FLAGS.dqn_target_update= 10000#, 'Update target Q network every 10000 steps')\n",
        "FLAGS.dqn_sleep_time= 2#, 'Train DDQN model every 2 seconds')\n",
        "FLAGS.dqn_gpu_num= 0#, 'GPU number to train the DDQN')\n",
        "FLAGS.dueling_net= True#, 'Whether to use Duelling Network to train the model') # https://arxiv.org/pdf/1511.06581.pdf\n",
        "FLAGS.dqn_polyak_averaging= True#, 'Whether to use polyak averaging to update the target network parameters')\n",
        "FLAGS.calculate_true_q= False#, \"Whether to use true Q-values to train DQN or use DQN's estimates to train it\")\n",
        "FLAGS.dqn_pretrain= False#, \"Pretrain the DDQN network with fixed Actor model\")\n",
        "FLAGS.dqn_pretrain_steps= 10000#, 'Number of steps to pre-train the DDQN')\n",
        "\n",
        "#scheduled sampling parameters#, https://arxiv.org/pdf/1506.03099.pdf\n",
        "# At each time step t and for each sequence in the batch#, we get the input to next decoding step by either\n",
        "#   (1) sampling from the final distribution at (t-1)#, or\n",
        "#   (2) reading from input_decoder_embedding.\n",
        "# We do (1) with probability sampling_probability and (2) with 1 - sampling_probability.\n",
        "# Using sampling_probability=0.0 is equivalent to using only the ground truth data (no sampling).\n",
        "# Using sampling_probability=1.0 is equivalent to doing inference by only relying on the sampled token generated at each decoding step\n",
        "FLAGS.scheduled_sampling= True#, 'whether to do scheduled sampling or not')\n",
        "FLAGS.decay_function= 'linear'#,'linear#, exponential#, inv_sigmoid') #### TODO: implement this\n",
        "FLAGS.sampling_probability= 2.5E-05#, 'epsilon value for choosing ground-truth or model output')\n",
        "FLAGS.fixed_sampling_probability= False#, 'Whether to use fixed sampling probability or adaptive based on global step')\n",
        "FLAGS.hard_argmax= True#, 'Whether to use soft argmax or hard argmax')\n",
        "FLAGS.greedy_scheduled_sampling= True#, 'Whether to use greedy approach or sample for the output#, if True it uses greedy')\n",
        "FLAGS.E2EBackProp= False#, 'Whether to use E2EBackProp algorithm to solve exposure bias')\n",
        "FLAGS.alpha= 1#, 'soft argmax argument')\n",
        "FLAGS.k= 1#, 'number of samples')\n",
        "FLAGS.scheduled_sampling_final_dist= True#, 'Whether to use final distribution or vocab distribution for scheduled sampling')\n",
        "\n",
        "# Coverage hyperparameters\n",
        "FLAGS.coverage= False#, 'Use coverage mechanism. Note#, the experiments reported in the ACL paper train WITHOUT coverage until converged#, and then train for a short phase WITH coveragFLAGS.e afterwards. i.e. to reproduce the results in the ACL paper#, turn this off for most of training then turn on for a short phase at the end.')\n",
        "FLAGS.cov_loss_wt= 1.0#, 'Weight of coverage loss (lambda in the paper). If zero#, then no incentive to minimize coverage loss.')\n",
        "\n",
        "# Utility flags#, for restoring and changing checkpoints\n",
        "FLAGS.convert_to_coverage_model= False#, 'Convert a non-coverage model to a coverage model. Turn this on and run in train mode. Your current training model will be copied to a new version (same name with _cov_init appended) that will be ready to run with coverage flag turned on#, for the coverage training stage.')\n",
        "FLAGS.restore_best_model= False#, 'Restore the best model in the eval/ dir and save it in the train/ dir#, ready to be used for further training. Useful for early stopping#, or if your training checkpoint has become corrupted with e.g. NaN values.')\n",
        "\n",
        "# Debugging. See https://www.tensorflow.org/programmers_guide/debugger\n",
        "FLAGS.debug= False#, \"Run in tensorflow's debug mode (watches for NaN/inf values)\")\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq2seq = Seq2Seq()\n",
        "seq2seq.main()"
      ],
      "metadata": {
        "id": "k9yCpYzLKCuv",
        "outputId": "55487d71-f622-452b-8da8-d9a81a4caf69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting seq2seq_attention in train mode...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Duplicate: a\n",
            "Duplicate: the\n",
            "Duplicate: we\n",
            "Duplicate: it\n",
            "Duplicate: up\n",
            "Duplicate: this\n",
            "Duplicate: am\n",
            "Duplicate: my\n",
            "Duplicate: he\n",
            "Duplicate: day\n",
            "Duplicate: police\n",
            "Duplicate: no\n",
            "Duplicate: party\n",
            "Duplicate: new\n",
            "Duplicate: you\n",
            "Duplicate: to\n",
            "Duplicate: one\n",
            "Duplicate: us\n",
            "Duplicate: in\n",
            "Duplicate: and\n",
            "Duplicate: all\n",
            "Duplicate: world\n",
            "Duplicate: what\n",
            "Duplicate: live\n",
            "Duplicate: for\n",
            "Duplicate: happy\n",
            "Duplicate: watch\n",
            "Duplicate: so\n",
            "Duplicate: if\n",
            "Duplicate: love\n",
            "Duplicate: s\n",
            "Duplicate: govt\n",
            "Duplicate: m\n",
            "Duplicate: i\n",
            "Duplicate: update\n",
            "Duplicate: there\n",
            "Duplicate: they\n",
            "Duplicate: beingsalmankhan\n",
            "Duplicate: here\n",
            "Duplicate: when\n",
            "Duplicate: office\n",
            "Duplicate: she\n",
            "Duplicate: today\n",
            "Duplicate: on\n",
            "Duplicate: more\n",
            "Duplicate: thank\n",
            "Duplicate: fire\n",
            "Duplicate: t\n",
            "Duplicate: our\n",
            "Duplicate: but\n",
            "Duplicate: will\n",
            "Duplicate: bollywood\n",
            "Duplicate: watch\n",
            "Duplicate: now\n",
            "Duplicate: it\n",
            "Duplicate: home\n",
            "Duplicate: as\n",
            "Duplicate: b\n",
            "Duplicate: pm\n",
            "Duplicate: state\n",
            "Duplicate: is\n",
            "Duplicate: how\n",
            "Duplicate: u\n",
            "Duplicate: team\n",
            "Duplicate: cricket\n",
            "Duplicate: pak\n",
            "Duplicate: go\n",
            "Duplicate: first\n",
            "Duplicate: court\n",
            "Duplicate: with\n",
            "Duplicate: people\n",
            "Duplicate: do\n",
            "Duplicate: just\n",
            "Duplicate: that\n",
            "Duplicate: ji\n",
            "Duplicate: house\n",
            "Duplicate: charges\n",
            "Duplicate: d\n",
            "Duplicate: an\n",
            "Duplicate: government\n",
            "Duplicate: video\n",
            "Duplicate: two\n",
            "Duplicate: birthday\n",
            "Duplicate: live\n",
            "Duplicate: former\n",
            "Duplicate: r\n",
            "Duplicate: sir\n",
            "Duplicate: let\n",
            "Duplicate: why\n",
            "Duplicate: singh\n",
            "Duplicate: his\n",
            "Duplicate: may\n",
            "Duplicate: road\n",
            "Duplicate: result\n",
            "Duplicate: video\n",
            "Duplicate: n\n",
            "Duplicate: is\n",
            "Duplicate: at\n",
            "Duplicate: security\n",
            "Duplicate: women\n",
            "Duplicate: of\n",
            "Duplicate: national\n",
            "Duplicate: best\n",
            "Duplicate: election\n",
            "Duplicate: vs\n",
            "Duplicate: please\n",
            "Duplicate: film\n",
            "Duplicate: not\n",
            "Duplicate: style\n",
            "Duplicate: after\n",
            "Duplicate: news\n",
            "Duplicate: high\n",
            "Duplicate: special\n",
            "Duplicate: have\n",
            "Duplicate: c\n",
            "Duplicate: visuals\n",
            "Duplicate: hospital\n",
            "Duplicate: good\n",
            "Duplicate: your\n",
            "Duplicate: week\n",
            "Duplicate: main\n",
            "Duplicate: play\n",
            "Duplicate: times\n",
            "Duplicate: total\n",
            "Duplicate: results\n",
            "Duplicate: chief\n",
            "Duplicate: trailer\n",
            "Duplicate: from\n",
            "Duplicate: link\n",
            "Duplicate: list\n",
            "Duplicate: year\n",
            "Duplicate: assembly\n",
            "Duplicate: salmankhan\n",
            "Duplicate: can\n",
            "Duplicate: power\n",
            "Duplicate: rs\n",
            "Duplicate: follow\n",
            "Duplicate: file\n",
            "Duplicate: india\n",
            "Duplicate: strong\n",
            "Duplicate: airport\n",
            "Duplicate: test\n",
            "Duplicate: x\n",
            "Duplicate: act\n",
            "Duplicate: se\n",
            "Duplicate: big\n",
            "Duplicate: great\n",
            "Duplicate: star\n",
            "Duplicate: minister\n",
            "Duplicate: super\n",
            "Duplicate: well\n",
            "Duplicate: life\n",
            "Duplicate: man\n",
            "Duplicate: get\n",
            "Duplicate: who\n",
            "Duplicate: anushkasharma\n",
            "Duplicate: me\n",
            "Duplicate: media\n",
            "Duplicate: aaj\n",
            "Duplicate: hope\n",
            "Duplicate: colorstv\n",
            "Duplicate: make\n",
            "Duplicate: president\n",
            "Duplicate: mi\n",
            "Duplicate: district\n",
            "Duplicate: delhi\n",
            "Duplicate: school\n",
            "Duplicate: temple\n",
            "Duplicate: kya\n",
            "Duplicate: hi\n",
            "Duplicate: india\n",
            "Duplicate: khan\n",
            "Duplicate: review\n",
            "Duplicate: aap\n",
            "Duplicate: ca\n",
            "Duplicate: over\n",
            "Duplicate: job\n",
            "Duplicate: board\n",
            "Duplicate: some\n",
            "Duplicate: city\n",
            "Duplicate: health\n",
            "Duplicate: very\n",
            "Duplicate: international\n",
            "Duplicate: heading\n",
            "Duplicate: light\n",
            "Duplicate: time\n",
            "Duplicate: who\n",
            "Duplicate: thanks\n",
            "Duplicate: movie\n",
            "Duplicate: three\n",
            "Duplicate: look\n",
            "Duplicate: air\n",
            "Duplicate: welcome\n",
            "Duplicate: class\n",
            "Duplicate: toc\n",
            "Duplicate: the\n",
            "Duplicate: photo\n",
            "Duplicate: station\n",
            "Duplicate: these\n",
            "Duplicate: director\n",
            "Duplicate: last\n",
            "Duplicate: v\n",
            "Duplicate: book\n",
            "Duplicate: new\n",
            "Duplicate: of\n",
            "Duplicate: service\n",
            "Duplicate: actor\n",
            "Duplicate: loc\n",
            "Duplicate: justice\n",
            "Duplicate: business\n",
            "Duplicate: its\n",
            "Duplicate: group\n",
            "Duplicate: case\n",
            "Duplicate: yes\n",
            "Duplicate: vs\n",
            "Duplicate: weekend\n",
            "Duplicate: officer\n",
            "Duplicate: congratulations\n",
            "Duplicate: stay\n",
            "Duplicate: senior\n",
            "Duplicate: full\n",
            "Duplicate: ye\n",
            "Duplicate: are\n",
            "Duplicate: family\n",
            "Duplicate: app\n",
            "Duplicate: led\n",
            "Duplicate: heavy\n",
            "Duplicate: also\n",
            "Duplicate: hair\n",
            "Duplicate: official\n",
            "Duplicate: floor\n",
            "Duplicate: read\n",
            "Duplicate: pic\n",
            "Duplicate: bhai\n",
            "Duplicate: captain\n",
            "Duplicate: public\n",
            "Duplicate: medical\n",
            "Duplicate: directed\n",
            "Duplicate: exam\n",
            "Duplicate: k\n",
            "Duplicate: out\n",
            "Duplicate: railway\n",
            "Duplicate: investigation\n",
            "Duplicate: votes\n",
            "Duplicate: by\n",
            "Duplicate: don\n",
            "Duplicate: only\n",
            "Duplicate: even\n",
            "Duplicate: such\n",
            "Duplicate: mumbai\n",
            "Duplicate: proud\n",
            "Duplicate: express\n",
            "Duplicate: next\n",
            "Duplicate: view\n",
            "Duplicate: army\n",
            "Duplicate: hai\n",
            "Duplicate: music\n",
            "Duplicate: dharmamovies\n",
            "Duplicate: match\n",
            "Duplicate: had\n",
            "Duplicate: pay\n",
            "Duplicate: exclusive\n",
            "Duplicate: her\n",
            "Duplicate: ind\n",
            "Duplicate: services\n",
            "Duplicate: force\n",
            "Duplicate: singh\n",
            "Duplicate: cr\n",
            "Duplicate: four\n",
            "Duplicate: black\n",
            "Duplicate: dear\n",
            "Duplicate: h\n",
            "Duplicate: ek\n",
            "Duplicate: candidate\n",
            "Duplicate: youth\n",
            "Duplicate: states\n",
            "Duplicate: update\n",
            "Duplicate: bank\n",
            "Duplicate: was\n",
            "Duplicate: sector\n",
            "Duplicate: boss\n",
            "Duplicate: kumar\n",
            "Duplicate: final\n",
            "Duplicate: in\n",
            "Duplicate: press\n",
            "Duplicate: open\n",
            "Duplicate: development\n",
            "Duplicate: see\n",
            "Duplicate: fan\n",
            "Duplicate: priyanka\n",
            "Duplicate: space\n",
            "Duplicate: looking\n",
            "Duplicate: photo\n",
            "Duplicate: opposition\n",
            "Duplicate: law\n",
            "Duplicate: story\n",
            "Duplicate: another\n",
            "Duplicate: most\n",
            "Duplicate: out\n",
            "Duplicate: while\n",
            "Duplicate: yeh\n",
            "Duplicate: boss\n",
            "Duplicate: zeemusiccompany\n",
            "Duplicate: post\n",
            "Duplicate: wish\n",
            "Duplicate: keep\n",
            "Duplicate: card\n",
            "Duplicate: top\n",
            "Duplicate: series\n",
            "Duplicate: many\n",
            "Duplicate: war\n",
            "Duplicate: be\n",
            "Duplicate: show\n",
            "Duplicate: title\n",
            "Duplicate: updates\n",
            "Duplicate: hero\n",
            "Duplicate: water\n",
            "Duplicate: starplus\n",
            "Duplicate: nation\n",
            "Duplicate: border\n",
            "Duplicate: faroutakhtar\n",
            "Duplicate: march\n",
            "Duplicate: khan\n",
            "Duplicate: education\n",
            "Duplicate: every\n",
            "Duplicate: katrinakaif\n",
            "Duplicate: mobile\n",
            "Duplicate: note\n",
            "Duplicate: mother\n",
            "Duplicate: normal\n",
            "Duplicate: miss\n",
            "Duplicate: never\n",
            "Duplicate: like\n",
            "Duplicate: saddened\n",
            "Duplicate: tak\n",
            "Duplicate: gold\n",
            "Duplicate: sachin\n",
            "Duplicate: search\n",
            "Duplicate: name\n",
            "Duplicate: above\n",
            "Duplicate: bigg\n",
            "Duplicate: tax\n",
            "Duplicate: ii\n",
            "Duplicate: bat\n",
            "Duplicate: father\n",
            "Duplicate: voting\n",
            "Duplicate: global\n",
            "Duplicate: source\n",
            "Duplicate: men\n",
            "Duplicate: w\n",
            "Duplicate: films\n",
            "Duplicate: award\n",
            "Duplicate: deeply\n",
            "Duplicate: meeting\n",
            "Duplicate: central\n",
            "Duplicate: finally\n",
            "Duplicate: check\n",
            "Duplicate: always\n",
            "Duplicate: building\n",
            "Duplicate: ali\n",
            "Duplicate: being\n",
            "Duplicate: xi\n",
            "Duplicate: tendulkar\n",
            "Duplicate: committee\n",
            "Duplicate: you\n",
            "Duplicate: students\n",
            "Duplicate: rescue\n",
            "Duplicate: action\n",
            "Duplicate: song\n",
            "Duplicate: did\n",
            "Duplicate: find\n",
            "Duplicate: ipl\n",
            "Duplicate: ca\n",
            "Duplicate: both\n",
            "Duplicate: wicket\n",
            "Duplicate: fans\n",
            "Duplicate: sports\n",
            "Duplicate: god\n",
            "Duplicate: exp\n",
            "Duplicate: cabinet\n",
            "Duplicate: foreign\n",
            "Duplicate: instagram\n",
            "Duplicate: coming\n",
            "Duplicate: conference\n",
            "Duplicate: whatsapp\n",
            "Duplicate: social\n",
            "Duplicate: updates\n",
            "Duplicate: should\n",
            "Duplicate: hotel\n",
            "Duplicate: not\n",
            "Duplicate: meet\n",
            "Duplicate: kapoor\n",
            "Duplicate: ram\n",
            "Duplicate: up\n",
            "Duplicate: ministers\n",
            "Duplicate: and\n",
            "Duplicate: death\n",
            "Duplicate: traffic\n",
            "Duplicate: biz\n",
            "Duplicate: ke\n",
            "Duplicate: bill\n",
            "Duplicate: isro\n",
            "Duplicate: everyone\n",
            "Duplicate: step\n",
            "Duplicate: control\n",
            "Duplicate: posted\n",
            "Duplicate: delhi\n",
            "Duplicate: where\n",
            "Duplicate: cinema\n",
            "Duplicate: major\n",
            "Duplicate: gaya\n",
            "Duplicate: photos\n",
            "Duplicate: tomorrow\n",
            "Duplicate: pok\n",
            "Duplicate: budget\n",
            "Duplicate: twitter\n",
            "Duplicate: alert\n",
            "Duplicate: credit\n",
            "Duplicate: hum\n",
            "Duplicate: phone\n",
            "Duplicate: trust\n",
            "Duplicate: reddy\n",
            "Duplicate: sorry\n",
            "Duplicate: now\n",
            "Duplicate: ios\n",
            "Duplicate: for\n",
            "Duplicate: nothing\n",
            "Duplicate: sitting\n",
            "Duplicate: encounter\n",
            "Duplicate: mishra\n",
            "Duplicate: ranbirkapoor\n",
            "Duplicate: entertainment\n",
            "Duplicate: wishing\n",
            "Duplicate: am\n",
            "Duplicate: college\n",
            "Duplicate: jail\n",
            "Duplicate: mission\n",
            "Duplicate: produced\n",
            "Duplicate: take\n",
            "Duplicate: red\n",
            "Duplicate: head\n",
            "Duplicate: anupampkher\n",
            "Duplicate: mohan\n",
            "Duplicate: art\n",
            "Duplicate: videos\n",
            "Duplicate: mark\n",
            "Duplicate: poco\n",
            "Duplicate: all\n",
            "Duplicate: no\n",
            "Duplicate: kartik\n",
            "Duplicate: idea\n",
            "Duplicate: aur\n",
            "Duplicate: must\n",
            "Duplicate: bachchan\n",
            "Duplicate: ground\n",
            "Duplicate: their\n",
            "Duplicate: viral\n",
            "Duplicate: news\n",
            "Duplicate: part\n",
            "Duplicate: land\n",
            "Duplicate: back\n",
            "Duplicate: peace\n",
            "Duplicate: games\n",
            "Duplicate: train\n",
            "Duplicate: condolences\n",
            "Duplicate: my\n",
            "Duplicate: sun\n",
            "Duplicate: colors\n",
            "Duplicate: box\n",
            "Duplicate: ab\n",
            "Duplicate: to\n",
            "Duplicate: taapsee\n",
            "Duplicate: centre\n",
            "Duplicate: near\n",
            "Duplicate: anilkapoor\n",
            "Duplicate: ho\n",
            "Duplicate: so\n",
            "Duplicate: indian\n",
            "Duplicate: shraddhakapoor\n",
            "Duplicate: ki\n",
            "Duplicate: economic\n",
            "Duplicate: sad\n",
            "Duplicate: dekhiye\n",
            "Duplicate: iii\n",
            "Duplicate: skfilmsofficial\n",
            "Duplicate: because\n",
            "Duplicate: awards\n",
            "Duplicate: flash\n",
            "Duplicate: loved\n",
            "Duplicate: since\n",
            "Duplicate: parineetichopra\n",
            "Duplicate: answer\n",
            "Duplicate: those\n",
            "Duplicate: de\n",
            "Duplicate: catch\n",
            "Duplicate: earthquake\n",
            "Duplicate: tonight\n",
            "Duplicate: kapil\n",
            "Duplicate: really\n",
            "Duplicate: sit\n",
            "Duplicate: come\n",
            "Duplicate: would\n",
            "Duplicate: srk\n",
            "Duplicate: venue\n",
            "Duplicate: wedding\n",
            "Duplicate: aap\n",
            "Duplicate: queen\n",
            "Duplicate: met\n",
            "Duplicate: want\n",
            "Duplicate: baby\n",
            "Duplicate: o\n",
            "Duplicate: human\n",
            "Duplicate: viral\n",
            "Duplicate: defence\n",
            "Duplicate: got\n",
            "Duplicate: pro\n",
            "Duplicate: joint\n",
            "Duplicate: 6s\n",
            "Duplicate: amazing\n",
            "Duplicate: foundation\n",
            "Duplicate: gate\n",
            "Duplicate: earlier\n",
            "Duplicate: forces\n",
            "Duplicate: section\n",
            "Duplicate: history\n",
            "Duplicate: none\n",
            "Duplicate: shocked\n",
            "Duplicate: working\n",
            "Duplicate: e\n",
            "Duplicate: 5s\n",
            "Duplicate: c.\n",
            "Duplicate: parliamentary\n",
            "Duplicate: admit\n",
            "Duplicate: line\n",
            "Duplicate: girl\n",
            "Duplicate: rest\n",
            "Duplicate: shame\n",
            "Duplicate: bio\n",
            "Duplicate: woman\n",
            "Duplicate: celebrations\n",
            "Duplicate: during\n",
            "Duplicate: lady\n",
            "Duplicate: general\n",
            "Duplicate: hi\n",
            "Duplicate: six\n",
            "Duplicate: gullyboy\n",
            "Duplicate: ka\n",
            "Duplicate: right\n",
            "Duplicate: highway\n",
            "Duplicate: makeup\n",
            "Duplicate: sunnyleone\n",
            "Duplicate: cool\n",
            "Duplicate: or\n",
            "Duplicate: question\n",
            "Duplicate: grand\n",
            "Duplicate: lakh\n",
            "Duplicate: injured\n",
            "Duplicate: 's\n",
            "Duplicate: spoke\n",
            "Duplicate: then\n",
            "Duplicate: leader\n",
            "Duplicate: about\n",
            "Duplicate: body\n",
            "Duplicate: five\n",
            "Duplicate: beautiful\n",
            "Duplicate: spot\n",
            "Duplicate: due\n",
            "Duplicate: operation\n",
            "Duplicate: hit\n",
            "Duplicate: releasing\n",
            "Duplicate: under\n",
            "Duplicate: staff\n",
            "Duplicate: administration\n",
            "Duplicate: stars\n",
            "Duplicate: iss\n",
            "Duplicate: date\n",
            "Duplicate: naxals\n",
            "Duplicate: agar\n",
            "Duplicate: terrorists\n",
            "Duplicate: fashion\n",
            "Duplicate: opening\n",
            "Duplicate: constitution\n",
            "Duplicate: days\n",
            "Duplicate: any\n",
            "Duplicate: p\n",
            "Duplicate: block\n",
            "Duplicate: biggboss12\n",
            "Duplicate: jo\n",
            "Duplicate: key\n",
            "Duplicate: technology\n",
            "Duplicate: first\n",
            "Duplicate: jab\n",
            "Duplicate: agency\n",
            "Duplicate: ready\n",
            "Duplicate: off\n",
            "Duplicate: selfie\n",
            "Duplicate: bus\n",
            "Duplicate: does\n",
            "Duplicate: we\n",
            "Duplicate: club\n",
            "Duplicate: respect\n",
            "Duplicate: anupampkher\n",
            "Duplicate: sources\n",
            "Duplicate: yoga\n",
            "Duplicate: metro\n",
            "Duplicate: review\n",
            "Duplicate: kajol\n",
            "Duplicate: pure\n",
            "Duplicate: once\n",
            "Duplicate: whosunilgrover\n",
            "Duplicate: guys\n",
            "Duplicate: constituency\n",
            "Duplicate: this\n",
            "Duplicate: river\n",
            "Duplicate: lots\n",
            "Duplicate: department\n",
            "Duplicate: mere\n",
            "Duplicate: uri\n",
            "Duplicate: iv\n",
            "Duplicate: call\n",
            "Duplicate: online\n",
            "Duplicate: pls\n",
            "Duplicate: before\n",
            "Duplicate: old\n",
            "Duplicate: forest\n",
            "Duplicate: on\n",
            "Duplicate: headquarters\n",
            "Duplicate: na\n",
            "Duplicate: information\n",
            "Duplicate: has\n",
            "Duplicate: data\n",
            "Duplicate: constable\n",
            "Duplicate: further\n",
            "Duplicate: thekapilsharmashow\n",
            "Duplicate: be\n",
            "Duplicate: real\n",
            "Duplicate: meri\n",
            "Duplicate: petrol\n",
            "Duplicate: locals\n",
            "Duplicate: summit\n",
            "Duplicate: white\n",
            "Duplicate: nations\n",
            "Duplicate: clash\n",
            "Duplicate: dance\n",
            "Duplicate: love\n",
            "Duplicate: crime\n",
            "Duplicate: extremely\n",
            "Duplicate: free\n",
            "Duplicate: work\n",
            "Duplicate: financial\n",
            "Duplicate: union\n",
            "Duplicate: bharat\n",
            "Duplicate: biggboss\n",
            "Duplicate: outfit\n",
            "Duplicate: company\n",
            "Duplicate: poster\n",
            "Duplicate: salute\n",
            "Duplicate: session\n",
            "Duplicate: trade\n",
            "Duplicate: baahubali2\n",
            "Duplicate: still\n",
            "Duplicate: cricketer\n",
            "Duplicate: aajtak.in\n",
            "Duplicate: united\n",
            "Duplicate: quality\n",
            "Duplicate: dil\n",
            "Duplicate: toh\n",
            "Duplicate: join\n",
            "Duplicate: ban\n",
            "Duplicate: share\n",
            "Duplicate: time\n",
            "Duplicate: car\n",
            "Duplicate: aus\n",
            "Duplicate: private\n",
            "Duplicate: true\n",
            "Duplicate: beauty\n",
            "Duplicate: civil\n",
            "Duplicate: big\n",
            "Duplicate: boy\n",
            "Duplicate: crore\n",
            "Duplicate: area\n",
            "Duplicate: styled\n",
            "Duplicate: stop\n",
            "Duplicate: armed\n",
            "Duplicate: trophy\n",
            "Duplicate: priyankachopra\n",
            "Duplicate: sarkar\n",
            "Duplicate: ghz\n",
            "Duplicate: game\n",
            "Duplicate: sharma\n",
            "Duplicate: insurance\n",
            "Duplicate: training\n",
            "Duplicate: salman\n",
            "Duplicate: kapoor\n",
            "Duplicate: protest\n",
            "Duplicate: motion\n",
            "Duplicate: local\n",
            "Duplicate: prayers\n",
            "Duplicate: mm\n",
            "Duplicate: income\n",
            "Duplicate: tiger\n",
            "Duplicate: zero\n",
            "Duplicate: festival\n",
            "Duplicate: mat\n",
            "Duplicate: details\n",
            "Duplicate: moon\n",
            "Duplicate: rashtrapatibhvn\n",
            "Duplicate: picture\n",
            "Duplicate: l\n",
            "Duplicate: king\n",
            "Duplicate: ab\n",
            "Duplicate: jai\n",
            "Duplicate: few\n",
            "Duplicate: bb13\n",
            "Duplicate: kareenakapoorkhan\n",
            "Duplicate: feeling\n",
            "Duplicate: stadium\n",
            "Duplicate: bridge\n",
            "Duplicate: breaking\n",
            "Duplicate: vivo_india\n",
            "Duplicate: poll\n",
            "Duplicate: hollywood\n",
            "Duplicate: modi\n",
            "Duplicate: crosses\n",
            "Duplicate: dad\n",
            "Duplicate: kalank\n",
            "Duplicate: rajinikanth\n",
            "Duplicate: bhushankumar\n",
            "Duplicate: room\n",
            "Duplicate: day\n",
            "Duplicate: happiness\n",
            "Duplicate: type\n",
            "Duplicate: pictures\n",
            "Duplicate: zenfone\n",
            "Duplicate: seat\n",
            "Duplicate: demonetisation\n",
            "Duplicate: project\n",
            "Duplicate: rights\n",
            "Duplicate: plus\n",
            "Duplicate: democracy\n",
            "Duplicate: shoot\n",
            "Duplicate: rain\n",
            "Duplicate: ranveersingh\n",
            "Duplicate: express\n",
            "Duplicate: friends\n",
            "Duplicate: best\n",
            "Duplicate: rsvpmovies\n",
            "Duplicate: sometimes\n",
            "Duplicate: player\n",
            "Duplicate: at\n",
            "Duplicate: mujhe\n",
            "Duplicate: left\n",
            "Duplicate: code\n",
            "Duplicate: tune\n",
            "Duplicate: cup\n",
            "Duplicate: support\n",
            "Duplicate: me\n",
            "Duplicate: earth\n",
            "Duplicate: crossed\n",
            "Duplicate: look\n",
            "Duplicate: emergency\n",
            "Duplicate: street\n",
            "Duplicate: must\n",
            "Duplicate: enjoy\n",
            "Duplicate: blockbuster\n",
            "Duplicate: race\n",
            "Duplicate: km\n",
            "Duplicate: superb\n",
            "Duplicate: doctors\n",
            "Duplicate: greetings\n",
            "Duplicate: aaryan\n",
            "Duplicate: diesel\n",
            "Duplicate: night\n",
            "Duplicate: sony\n",
            "Duplicate: yesterday\n",
            "Duplicate: store\n",
            "Duplicate: phase\n",
            "Duplicate: independent\n",
            "Duplicate: absolutely\n",
            "Duplicate: exam\n",
            "Duplicate: shot\n",
            "Duplicate: let\n",
            "Duplicate: latest\n",
            "Duplicate: color\n",
            "Duplicate: internet\n",
            "Duplicate: huge\n",
            "Duplicate: paytm\n",
            "Duplicate: teaser\n",
            "Duplicate: active\n",
            "Duplicate: nett\n",
            "Duplicate: ambani\n",
            "Duplicate: glad\n",
            "Duplicate: band\n",
            "Duplicate: mini\n",
            "Duplicate: looks\n",
            "Duplicate: mass\n",
            "Duplicate: going\n",
            "Duplicate: photos\n",
            "Duplicate: money\n",
            "Duplicate: playing\n",
            "Duplicate: seven\n",
            "Duplicate: har\n",
            "Duplicate: member\n",
            "Duplicate: board\n",
            "Duplicate: tata\n",
            "Duplicate: elections\n",
            "Duplicate: made\n",
            "Duplicate: accused\n",
            "Duplicate: end\n",
            "Duplicate: aa\n",
            "Duplicate: blessed\n",
            "Duplicate: fund\n",
            "Duplicate: country\n",
            "Duplicate: too\n",
            "Duplicate: prime\n",
            "Duplicate: television\n",
            "Duplicate: simmba\n",
            "Duplicate: guess\n",
            "Duplicate: democratic\n",
            "Duplicate: political\n",
            "Duplicate: exclusive\n",
            "Duplicate: drive\n",
            "Duplicate: heart\n",
            "Duplicate: digvijaya\n",
            "Duplicate: breaking\n",
            "Duplicate: sharing\n",
            "Duplicate: someone\n",
            "Duplicate: report\n",
            "Duplicate: management\n",
            "Duplicate: protesters\n",
            "Duplicate: according\n",
            "Duplicate: aisa\n",
            "Duplicate: tributes\n",
            "Duplicate: nex\n",
            "Duplicate: fit\n",
            "Duplicate: digital\n",
            "Duplicate: top\n",
            "Duplicate: police\n",
            "Duplicate: personal\n",
            "Duplicate: legislative\n",
            "Duplicate: contact\n",
            "Duplicate: guard\n",
            "Duplicate: fake\n",
            "Duplicate: ashutosh\n",
            "Duplicate: thejohnabraham\n",
            "Duplicate: unit\n",
            "Duplicate: table\n",
            "Duplicate: go\n",
            "Duplicate: iss\n",
            "Duplicate: le\n",
            "Duplicate: soon\n",
            "Duplicate: yuvraj\n",
            "Duplicate: eyes\n",
            "Duplicate: anniversary\n",
            "Duplicate: celebration\n",
            "Duplicate: sky\n",
            "Duplicate: abbas\n",
            "Duplicate: son\n",
            "Duplicate: polling\n",
            "Duplicate: rao\n",
            "Duplicate: incredible\n",
            "Duplicate: nobody\n",
            "Duplicate: na\n",
            "Duplicate: science\n",
            "Duplicate: second\n",
            "Duplicate: oil\n",
            "Duplicate: jawans\n",
            "Duplicate: politics\n",
            "Duplicate: di\n",
            "Duplicate: could\n",
            "Duplicate: maa\n",
            "Duplicate: jobs\n",
            "Duplicate: whatever\n",
            "Duplicate: independence\n",
            "Duplicate: why\n",
            "Duplicate: biggboss13\n",
            "Duplicate: wing\n",
            "Duplicate: system\n",
            "Duplicate: break\n",
            "Duplicate: protection\n",
            "Duplicate: technical\n",
            "Duplicate: core\n",
            "Duplicate: each\n",
            "Duplicate: journey\n",
            "Duplicate: say\n",
            "Duplicate: do\n",
            "Duplicate: mind\n",
            "Duplicate: age\n",
            "Duplicate: tweet\n",
            "Duplicate: mode\n",
            "Duplicate: shooting\n",
            "Duplicate: throwback\n",
            "Duplicate: beta\n",
            "Duplicate: dream\n",
            "Duplicate: attack\n",
            "Duplicate: recruitment\n",
            "Duplicate: maybe\n",
            "Duplicate: kumar\n",
            "Duplicate: pannu\n",
            "Duplicate: saw\n",
            "Duplicate: feel\n",
            "Duplicate: kar\n",
            "Duplicate: task\n",
            "Duplicate: ko\n",
            "Duplicate: desh\n",
            "Duplicate: simmba\n",
            "Duplicate: result\n",
            "Duplicate: wearing\n",
            "Duplicate: alliance\n",
            "Duplicate: theshilpashetty\n",
            "Duplicate: kiss\n",
            "Duplicate: saraalikhan\n",
            "Duplicate: examination\n",
            "Duplicate: spo\n",
            "Duplicate: dark\n",
            "Duplicate: lal\n",
            "Duplicate: urithesurgicalstrike\n",
            "Duplicate: shoes\n",
            "Duplicate: delighted\n",
            "Duplicate: today\n",
            "Duplicate: children\n",
            "Duplicate: heartfelt\n",
            "Duplicate: other\n",
            "Duplicate: everything\n",
            "Duplicate: prakash\n",
            "Duplicate: flight\n",
            "Duplicate: happy\n",
            "Duplicate: air\n",
            "Duplicate: complex\n",
            "Duplicate: super\n",
            "Duplicate: members\n",
            "Duplicate: poor\n",
            "Duplicate: little\n",
            "Duplicate: image\n",
            "Duplicate: baat\n",
            "Duplicate: behind\n",
            "Duplicate: third\n",
            "Duplicate: dept\n",
            "Duplicate: something\n",
            "Duplicate: ms\n",
            "Duplicate: park\n",
            "Duplicate: bullet\n",
            "Duplicate: devotees\n",
            "Duplicate: again\n",
            "Duplicate: memorial\n",
            "Duplicate: blue\n",
            "Duplicate: food\n",
            "Duplicate: morning\n",
            "Duplicate: model\n",
            "Duplicate: freedom\n",
            "Duplicate: strongly\n",
            "Duplicate: several\n",
            "Duplicate: bharat_thefilm\n",
            "Duplicate: hindi\n",
            "Duplicate: zafar\n",
            "Duplicate: commission\n",
            "Duplicate: ranbir\n",
            "Duplicate: filmfare\n",
            "Duplicate: leaving\n",
            "Duplicate: pilot\n",
            "Duplicate: wabetainfo\n",
            "Duplicate: celebrating\n",
            "Duplicate: billion\n",
            "Duplicate: event\n",
            "Duplicate: baba\n",
            "Duplicate: remember\n",
            "Duplicate: town\n",
            "Duplicate: getting\n",
            "Duplicate: ok\n",
            "Duplicate: industry\n",
            "Duplicate: link\n",
            "Duplicate: bb12\n",
            "Duplicate: season\n",
            "Duplicate: metoo\n",
            "Duplicate: rishi\n",
            "Duplicate: toh\n",
            "Duplicate: performance\n",
            "Duplicate: additional\n",
            "Duplicate: release\n",
            "Duplicate: ne\n",
            "Duplicate: speaker\n",
            "Duplicate: y\n",
            "Duplicate: despite\n",
            "Duplicate: location\n",
            "Duplicate: limited\n",
            "Duplicate: maddockfilms\n",
            "Duplicate: congrats\n",
            "Duplicate: alert\n",
            "Duplicate: beach\n",
            "Duplicate: university\n",
            "Duplicate: star\n",
            "Duplicate: farmers\n",
            "Duplicate: making\n",
            "Duplicate: hain\n",
            "Duplicate: jio\n",
            "Duplicate: facts\n",
            "Duplicate: vision\n",
            "Duplicate: presenting\n",
            "Duplicate: oscar\n",
            "Duplicate: village\n",
            "Duplicate: account\n",
            "Duplicate: anti\n",
            "Duplicate: request\n",
            "Duplicate: long\n",
            "Duplicate: range\n",
            "Duplicate: radio\n",
            "Duplicate: mom\n",
            "Duplicate: disha\n",
            "Duplicate: min\n",
            "Duplicate: parliament\n",
            "Duplicate: main\n",
            "Duplicate: till\n",
            "Duplicate: highest\n",
            "Duplicate: yet\n",
            "Duplicate: sreesanth\n",
            "Duplicate: officers\n",
            "Duplicate: driver\n",
            "Duplicate: leaders\n",
            "Duplicate: half\n",
            "Duplicate: anand\n",
            "Duplicate: grateful\n",
            "Duplicate: colors\n",
            "Duplicate: mix\n",
            "Duplicate: give\n",
            "Duplicate: vice\n",
            "Duplicate: koi\n",
            "Duplicate: council\n",
            "Duplicate: front\n",
            "Duplicate: severe\n",
            "Duplicate: budget\n",
            "Duplicate: un\n",
            "Duplicate: need\n",
            "Duplicate: raid\n",
            "Duplicate: master\n",
            "Duplicate: guest\n",
            "Duplicate: actress\n",
            "Duplicate: transport\n",
            "Duplicate: screen\n",
            "Duplicate: way\n",
            "Duplicate: download\n",
            "Duplicate: finale\n",
            "Duplicate: photography\n",
            "Duplicate: nickjonas\n",
            "Duplicate: movies\n",
            "Duplicate: smart\n",
            "Duplicate: exchange\n",
            "Duplicate: bad\n",
            "Duplicate: silver\n",
            "Duplicate: sad\n",
            "Duplicate: sharma\n",
            "Duplicate: coach\n",
            "Duplicate: congress\n",
            "Duplicate: anand\n",
            "Duplicate: base\n",
            "Duplicate: regional\n",
            "Duplicate: run\n",
            "Duplicate: tell\n",
            "Duplicate: avengers\n",
            "Duplicate: im\n",
            "Duplicate: mortal\n",
            "Duplicate: bio\n",
            "Duplicate: praying\n",
            "Duplicate: sab\n",
            "Duplicate: vote\n",
            "Duplicate: fun\n",
            "Duplicate: excellent\n",
            "Duplicate: hot\n",
            "Duplicate: affairs\n",
            "Duplicate: dabangg3\n",
            "Duplicate: voter\n",
            "Duplicate: d.\n",
            "Duplicate: greater\n",
            "Duplicate: mera\n",
            "Duplicate: abhi\n",
            "Duplicate: having\n",
            "Duplicate: se\n",
            "Duplicate: priya\n",
            "Duplicate: mon\n",
            "Duplicate: excited\n",
            "Duplicate: click\n",
            "Duplicate: awesome\n",
            "Duplicate: watched\n",
            "Duplicate: duty\n",
            "Duplicate: sl\n",
            "Duplicate: rural\n",
            "Duplicate: chairman\n",
            "Duplicate: teachers\n",
            "Duplicate: branch\n",
            "Duplicate: vihar\n",
            "Duplicate: record\n",
            "Duplicate: delegation\n",
            "Duplicate: sale\n",
            "Duplicate: riteishd\n",
            "Duplicate: annual\n",
            "Duplicate: ministry\n",
            "Duplicate: universe\n",
            "Duplicate: ex\n",
            "Duplicate: witness\n",
            "Duplicate: center\n",
            "Duplicate: shah\n",
            "Duplicate: papa\n",
            "Duplicate: disaster\n",
            "Duplicate: mein\n",
            "Duplicate: know\n",
            "Duplicate: legend\n",
            "Duplicate: place\n",
            "Duplicate: sanju\n",
            "Duplicate: organisation\n",
            "Duplicate: lunch\n",
            "Duplicate: daddy\n",
            "Duplicate: taking\n",
            "Duplicate: one\n",
            "Duplicate: golden\n",
            "Duplicate: quick\n",
            "Duplicate: association\n",
            "Duplicate: summer\n",
            "Duplicate: early\n",
            "Duplicate: janta\n",
            "Duplicate: missing\n",
            "Duplicate: kiss\n",
            "Duplicate: sport\n",
            "Duplicate: reallyswara\n",
            "Duplicate: person\n",
            "Duplicate: level\n",
            "Duplicate: division\n",
            "Duplicate: victim\n",
            "Duplicate: tv\n",
            "Duplicate: paper\n",
            "Duplicate: welfare\n",
            "Duplicate: clean\n",
            "Duplicate: admission\n",
            "Duplicate: remarks\n",
            "Duplicate: double\n",
            "Duplicate: relief\n",
            "Duplicate: team\n",
            "Duplicate: movement\n",
            "Duplicate: sahab\n",
            "Duplicate: wi-fi\n",
            "Duplicate: intelligence\n",
            "Duplicate: green\n",
            "Duplicate: massive\n",
            "Duplicate: ceremony\n",
            "Duplicate: deepika\n",
            "Duplicate: courtesy\n",
            "Duplicate: mou\n",
            "Duplicate: kuch\n",
            "Duplicate: ball\n",
            "Duplicate: situation\n",
            "Duplicate: eng\n",
            "Duplicate: north\n",
            "Duplicate: register\n",
            "Duplicate: ur\n",
            "Duplicate: policy\n",
            "Duplicate: child\n",
            "Duplicate: secretary\n",
            "Duplicate: trailer\n",
            "Duplicate: number\n",
            "Duplicate: blast\n",
            "Duplicate: community\n",
            "Duplicate: years\n",
            "Duplicate: judge\n",
            "Duplicate: pyaar\n",
            "Duplicate: lawyer\n",
            "Duplicate: br\n",
            "Duplicate: hard\n",
            "Duplicate: ever\n",
            "Duplicate: teacher\n",
            "Duplicate: iphone\n",
            "Duplicate: statement\n",
            "Duplicate: par\n",
            "Duplicate: nahi\n",
            "Duplicate: late\n",
            "Duplicate: indian\n",
            "Duplicate: instead\n",
            "Duplicate: highest\n",
            "Duplicate: dhadak\n",
            "Duplicate: wow\n",
            "Duplicate: salman\n",
            "Duplicate: military\n",
            "Duplicate: dancing\n",
            "Duplicate: camera\n",
            "Duplicate: official\n",
            "Duplicate: ma\n",
            "Duplicate: vishal\n",
            "Duplicate: wife\n",
            "Duplicate: order\n",
            "Duplicate: citizens\n",
            "Duplicate: letter\n",
            "Duplicate: shaadi\n",
            "Duplicate: market\n",
            "Duplicate: young\n",
            "Duplicate: a4\n",
            "Duplicate: pollution\n",
            "Duplicate: god\n",
            "Duplicate: watching\n",
            "Duplicate: common\n",
            "Duplicate: priyanka\n",
            "Duplicate: collection\n",
            "Duplicate: bodies\n",
            "Duplicate: face\n",
            "Duplicate: kedarnath\n",
            "Duplicate: deep\n",
            "Duplicate: hearing\n",
            "Duplicate: listen\n",
            "Duplicate: tigerzindahai\n",
            "Duplicate: veerediwedding\n",
            "Duplicate: student\n",
            "Duplicate: polls\n",
            "Duplicate: around\n",
            "Duplicate: hate\n",
            "Duplicate:"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Building graph...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " gate\n",
            "max_size of vocab was specified as 50000; we now have 50000 words. Stopping reading.\n",
            "creating model...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:129: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:130: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:174: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "INFO:tensorflow:batch_size 20, attn_size: 512, emb_size: 150\n",
            "INFO:tensorflow:Adding attention_decoder timestep 0 of 15\n",
            "INFO:tensorflow:Adding attention_decoder timestep 1 of 15\n",
            "INFO:tensorflow:Adding attention_decoder timestep 2 of 15\n",
            "INFO:tensorflow:Adding attention_decoder timestep 3 of 15\n",
            "INFO:tensorflow:Adding attention_decoder timestep 4 of 15\n",
            "INFO:tensorflow:Adding attention_decoder timestep 5 of 15\n",
            "INFO:tensorflow:Adding attention_decoder timestep 6 of 15\n",
            "INFO:tensorflow:Adding attention_decoder timestep 7 of 15\n",
            "INFO:tensorflow:Adding attention_decoder timestep 8 of 15\n",
            "INFO:tensorflow:Adding attention_decoder timestep 9 of 15\n",
            "INFO:tensorflow:Adding attention_decoder timestep 10 of 15\n",
            "INFO:tensorflow:Adding attention_decoder timestep 11 of 15\n",
            "INFO:tensorflow:Adding attention_decoder timestep 12 of 15\n",
            "INFO:tensorflow:Adding attention_decoder timestep 13 of 15\n",
            "INFO:tensorflow:Adding attention_decoder timestep 14 of 15\n",
            "INFO:tensorflow:Time to build graph: 16 seconds\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading my Model ..\n",
            "Loading Done el7 !!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:138: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "[========================================] 269174/269174 (100%)      0 to go\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Word embeddings: 269178\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-92-ff2353f5e914>:219: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.MonitoredTrainingSession\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word Embedding Reading done.\n",
            "getWordEmbedding.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10519: 0.8055205345153809\n",
            "INFO:tensorflow:pgen_loss: 4.089644432067871\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10520: 0.3503100872039795\n",
            "INFO:tensorflow:pgen_loss: 2.896897792816162\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10521: 0.6729533672332764\n",
            "INFO:tensorflow:pgen_loss: 3.9876341819763184\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10522: 0.870661735534668\n",
            "INFO:tensorflow:pgen_loss: 3.8990015983581543\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10523: 0.6746258735656738\n",
            "INFO:tensorflow:pgen_loss: 3.8349671363830566\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10524: 0.5574448108673096\n",
            "INFO:tensorflow:pgen_loss: 4.125080585479736\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10525: 0.8563101291656494\n",
            "INFO:tensorflow:pgen_loss: 3.9490363597869873\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10526: 0.8456833362579346\n",
            "INFO:tensorflow:pgen_loss: 3.5878357887268066\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10527: 1.0045907497406006\n",
            "INFO:tensorflow:pgen_loss: 4.174538612365723\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10528: 0.938896894454956\n",
            "INFO:tensorflow:pgen_loss: 3.9121055603027344\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10529: 0.9103929996490479\n",
            "INFO:tensorflow:pgen_loss: 3.789231777191162\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10530: 0.9285798072814941\n",
            "INFO:tensorflow:pgen_loss: 3.4394707679748535\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10531: 0.742957592010498\n",
            "INFO:tensorflow:pgen_loss: 3.6684768199920654\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10532: 1.0047154426574707\n",
            "INFO:tensorflow:pgen_loss: 4.372260093688965\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10533: 0.7197754383087158\n",
            "INFO:tensorflow:pgen_loss: 4.266485691070557\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10534: 0.9997923374176025\n",
            "INFO:tensorflow:pgen_loss: 4.352200984954834\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10535: 0.9661815166473389\n",
            "INFO:tensorflow:pgen_loss: 4.081516742706299\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10536: 1.0014262199401855\n",
            "INFO:tensorflow:pgen_loss: 3.817910671234131\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10537: 0.40836024284362793\n",
            "INFO:tensorflow:pgen_loss: 3.6308541297912598\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10538: 0.3366658687591553\n",
            "INFO:tensorflow:pgen_loss: 3.63459849357605\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10539: 0.9881720542907715\n",
            "INFO:tensorflow:pgen_loss: 3.516397476196289\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10540: 0.7438523769378662\n",
            "INFO:tensorflow:pgen_loss: 3.3583006858825684\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10541: 0.2939572334289551\n",
            "INFO:tensorflow:pgen_loss: 2.968106269836426\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10542: 0.4581725597381592\n",
            "INFO:tensorflow:pgen_loss: 3.539768934249878\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10543: 0.44492101669311523\n",
            "INFO:tensorflow:pgen_loss: 3.0434489250183105\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10544: 1.0006089210510254\n",
            "INFO:tensorflow:pgen_loss: 3.9423828125\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10545: 0.6148397922515869\n",
            "INFO:tensorflow:pgen_loss: 4.111156940460205\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10546: 0.4966166019439697\n",
            "INFO:tensorflow:pgen_loss: 3.0754780769348145\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10547: 0.5424995422363281\n",
            "INFO:tensorflow:pgen_loss: 2.6096432209014893\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10548: 0.3972930908203125\n",
            "INFO:tensorflow:pgen_loss: 4.460345268249512\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10549: 0.5689184665679932\n",
            "INFO:tensorflow:pgen_loss: 4.07253885269165\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10550: 0.46838831901550293\n",
            "INFO:tensorflow:pgen_loss: 2.298628330230713\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10551: 0.9842333793640137\n",
            "INFO:tensorflow:pgen_loss: 4.232113361358643\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10552: 1.0019786357879639\n",
            "INFO:tensorflow:pgen_loss: 4.182826042175293\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10553: 0.9884519577026367\n",
            "INFO:tensorflow:pgen_loss: 4.033237934112549\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10554: 0.6249887943267822\n",
            "INFO:tensorflow:pgen_loss: 3.261301040649414\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10555: 0.48417186737060547\n",
            "INFO:tensorflow:pgen_loss: 3.5700314044952393\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10556: 0.9806950092315674\n",
            "INFO:tensorflow:pgen_loss: 4.057727813720703\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10557: 0.3700072765350342\n",
            "INFO:tensorflow:pgen_loss: 3.0003206729888916\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10558: 0.4664769172668457\n",
            "INFO:tensorflow:pgen_loss: 2.566591739654541\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10559: 0.972325325012207\n",
            "INFO:tensorflow:pgen_loss: 4.216940402984619\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10560: 0.9364538192749023\n",
            "INFO:tensorflow:pgen_loss: 3.558137893676758\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10561: 0.7101426124572754\n",
            "INFO:tensorflow:pgen_loss: 3.8160057067871094\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10562: 0.9721827507019043\n",
            "INFO:tensorflow:pgen_loss: 3.9840400218963623\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10563: 0.9172122478485107\n",
            "INFO:tensorflow:pgen_loss: 4.001260280609131\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10564: 0.5298619270324707\n",
            "INFO:tensorflow:pgen_loss: 3.6793627738952637\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10565: 0.45008134841918945\n",
            "INFO:tensorflow:pgen_loss: 2.488257646560669\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10566: 0.9968042373657227\n",
            "INFO:tensorflow:pgen_loss: 3.7409701347351074\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10567: 0.7888562679290771\n",
            "INFO:tensorflow:pgen_loss: 3.578979015350342\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10568: 0.7830946445465088\n",
            "INFO:tensorflow:pgen_loss: 3.6196188926696777\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10569: 0.3686671257019043\n",
            "INFO:tensorflow:pgen_loss: 4.079117298126221\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10570: 0.8819754123687744\n",
            "INFO:tensorflow:pgen_loss: 3.3374416828155518\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10571: 0.9458625316619873\n",
            "INFO:tensorflow:pgen_loss: 4.014059066772461\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10572: 0.8394160270690918\n",
            "INFO:tensorflow:pgen_loss: 4.206607818603516\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10573: 0.863905668258667\n",
            "INFO:tensorflow:pgen_loss: 4.115096092224121\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10574: 0.7927181720733643\n",
            "INFO:tensorflow:pgen_loss: 4.002915382385254\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10575: 0.8190348148345947\n",
            "INFO:tensorflow:pgen_loss: 3.955796003341675\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10576: 0.5494034290313721\n",
            "INFO:tensorflow:pgen_loss: 3.908621311187744\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:Saving checkpoint to path drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step 10577: 1.1773641109466553\n",
            "INFO:tensorflow:pgen_loss: 4.019297122955322\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10578: 1.079484224319458\n",
            "INFO:tensorflow:pgen_loss: 2.708495616912842\t\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-10576.data-00000-of-00001\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:186200\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-10576.index\n",
            "INFO:tensorflow:186200\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-10576.meta\n",
            "INFO:tensorflow:190500\n",
            "INFO:tensorflow:seconds for training step 10579: 0.9704787731170654\n",
            "INFO:tensorflow:pgen_loss: 3.672516345977783\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10580: 0.7271134853363037\n",
            "INFO:tensorflow:pgen_loss: 3.556370973587036\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10581: 0.5194079875946045\n",
            "INFO:tensorflow:pgen_loss: 3.9494881629943848\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10582: 0.708289384841919\n",
            "INFO:tensorflow:pgen_loss: 2.5724587440490723\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10583: 0.9696271419525146\n",
            "INFO:tensorflow:pgen_loss: 3.613903522491455\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10584: 0.2821784019470215\n",
            "INFO:tensorflow:pgen_loss: 3.117830514907837\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10585: 0.6343765258789062\n",
            "INFO:tensorflow:pgen_loss: 3.6659598350524902\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10586: 0.5887041091918945\n",
            "INFO:tensorflow:pgen_loss: 3.7513248920440674\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10587: 0.38992953300476074\n",
            "INFO:tensorflow:pgen_loss: 3.3846046924591064\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10588: 0.9805803298950195\n",
            "INFO:tensorflow:pgen_loss: 3.4102420806884766\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10589: 0.9288694858551025\n",
            "INFO:tensorflow:pgen_loss: 3.6266167163848877\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10590: 1.1428191661834717\n",
            "INFO:tensorflow:pgen_loss: 4.154788017272949\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10591: 1.122159481048584\n",
            "INFO:tensorflow:pgen_loss: 3.242527484893799\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10592: 0.565199613571167\n",
            "INFO:tensorflow:pgen_loss: 3.522526502609253\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10593: 0.8070573806762695\n",
            "INFO:tensorflow:pgen_loss: 3.1677541732788086\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10594: 1.0579936504364014\n",
            "INFO:tensorflow:pgen_loss: 3.181025266647339\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10595: 0.9767026901245117\n",
            "INFO:tensorflow:pgen_loss: 3.7973170280456543\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10596: 0.9326636791229248\n",
            "INFO:tensorflow:pgen_loss: 4.4026384353637695\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10597: 0.6221635341644287\n",
            "INFO:tensorflow:pgen_loss: 3.7683138847351074\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10598: 1.6151883602142334\n",
            "INFO:tensorflow:pgen_loss: 3.9433047771453857\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10599: 0.6531481742858887\n",
            "INFO:tensorflow:pgen_loss: 3.1301121711730957\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10600: 0.9757540225982666\n",
            "INFO:tensorflow:pgen_loss: 3.632122755050659\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10601: 0.6479759216308594\n",
            "INFO:tensorflow:pgen_loss: 4.7930707931518555\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10602: 1.4577062129974365\n",
            "INFO:tensorflow:pgen_loss: 3.893461227416992\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10603: 0.7210040092468262\n",
            "INFO:tensorflow:pgen_loss: 3.952608823776245\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10604: 0.8373537063598633\n",
            "INFO:tensorflow:pgen_loss: 2.8163981437683105\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10605: 0.5219833850860596\n",
            "INFO:tensorflow:pgen_loss: 3.792231798171997\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10606: 0.9397871494293213\n",
            "INFO:tensorflow:pgen_loss: 4.004416465759277\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10607: 0.7812776565551758\n",
            "INFO:tensorflow:pgen_loss: 4.38750696182251\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10608: 0.7637441158294678\n",
            "INFO:tensorflow:pgen_loss: 3.3577446937561035\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10609: 0.9869396686553955\n",
            "INFO:tensorflow:pgen_loss: 3.5574302673339844\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10610: 0.9773130416870117\n",
            "INFO:tensorflow:pgen_loss: 3.857945203781128\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10611: 0.9557011127471924\n",
            "INFO:tensorflow:pgen_loss: 3.813488483428955\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10612: 0.4457056522369385\n",
            "INFO:tensorflow:pgen_loss: 4.292668342590332\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10613: 0.5905828475952148\n",
            "INFO:tensorflow:pgen_loss: 3.7487754821777344\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10614: 0.5222878456115723\n",
            "INFO:tensorflow:pgen_loss: 3.220515489578247\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10615: 1.017035722732544\n",
            "INFO:tensorflow:pgen_loss: 4.117478847503662\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10616: 0.7748894691467285\n",
            "INFO:tensorflow:pgen_loss: 3.471402645111084\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10617: 0.7003757953643799\n",
            "INFO:tensorflow:pgen_loss: 3.824742078781128\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10618: 0.9970905780792236\n",
            "INFO:tensorflow:pgen_loss: 3.9224555492401123\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10619: 0.8776555061340332\n",
            "INFO:tensorflow:pgen_loss: 4.766840934753418\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10620: 0.8763444423675537\n",
            "INFO:tensorflow:pgen_loss: 3.992745876312256\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10621: 0.8693585395812988\n",
            "INFO:tensorflow:pgen_loss: 3.429081678390503\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10622: 0.9620850086212158\n",
            "INFO:tensorflow:pgen_loss: 4.079152584075928\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10623: 0.844782829284668\n",
            "INFO:tensorflow:pgen_loss: 3.4009690284729004\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10624: 0.6200251579284668\n",
            "INFO:tensorflow:pgen_loss: 3.2996933460235596\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10625: 0.43616175651550293\n",
            "INFO:tensorflow:pgen_loss: 3.0426526069641113\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10626: 0.6945176124572754\n",
            "INFO:tensorflow:pgen_loss: 3.206808567047119\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10627: 0.7766058444976807\n",
            "INFO:tensorflow:pgen_loss: 3.9406654834747314\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10628: 0.7483253479003906\n",
            "INFO:tensorflow:pgen_loss: 3.777106523513794\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10629: 0.7963314056396484\n",
            "INFO:tensorflow:pgen_loss: 4.619894981384277\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10630: 0.6495425701141357\n",
            "INFO:tensorflow:pgen_loss: 4.166721343994141\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10631: 0.7486512660980225\n",
            "INFO:tensorflow:pgen_loss: 3.9179351329803467\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10632: 0.5797319412231445\n",
            "INFO:tensorflow:pgen_loss: 2.9158401489257812\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10633: 0.7038202285766602\n",
            "INFO:tensorflow:pgen_loss: 3.017392873764038\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10634: 0.5637943744659424\n",
            "INFO:tensorflow:pgen_loss: 3.2862045764923096\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10635: 0.9563653469085693\n",
            "INFO:tensorflow:pgen_loss: 4.220686912536621\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10636: 0.9718813896179199\n",
            "INFO:tensorflow:pgen_loss: 3.6324806213378906\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10637: 0.9695234298706055\n",
            "INFO:tensorflow:pgen_loss: 4.000069618225098\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10638: 1.019322395324707\n",
            "INFO:tensorflow:pgen_loss: 3.8828225135803223\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10639: 1.0082266330718994\n",
            "INFO:tensorflow:pgen_loss: 3.5940794944763184\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10640: 0.9444468021392822\n",
            "INFO:tensorflow:pgen_loss: 3.166553020477295\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10641: 0.9727363586425781\n",
            "INFO:tensorflow:pgen_loss: 3.6007163524627686\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10642: 0.9477255344390869\n",
            "INFO:tensorflow:pgen_loss: 3.737941265106201\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10643: 0.9916367530822754\n",
            "INFO:tensorflow:pgen_loss: 3.9931747913360596\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10644: 0.5773453712463379\n",
            "INFO:tensorflow:pgen_loss: 3.0682945251464844\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10645: 0.9673459529876709\n",
            "INFO:tensorflow:pgen_loss: 3.4339146614074707\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10646: 0.6780188083648682\n",
            "INFO:tensorflow:pgen_loss: 4.531278133392334\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10647: 0.6601433753967285\n",
            "INFO:tensorflow:pgen_loss: 3.3602612018585205\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:Saving checkpoint to path drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step 10648: 1.2116000652313232\n",
            "INFO:tensorflow:pgen_loss: 3.5388076305389404\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-10647.data-00000-of-00001\n",
            "INFO:tensorflow:186200\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-10647.index\n",
            "INFO:tensorflow:186200\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-10647.meta\n",
            "INFO:tensorflow:190500\n",
            "INFO:tensorflow:seconds for training step 10649: 1.0758800506591797\n",
            "INFO:tensorflow:pgen_loss: 3.6747639179229736\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10650: 0.4994041919708252\n",
            "INFO:tensorflow:pgen_loss: 3.8956027030944824\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10651: 0.9790668487548828\n",
            "INFO:tensorflow:pgen_loss: 3.295419216156006\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10652: 0.8389134407043457\n",
            "INFO:tensorflow:pgen_loss: 3.2813708782196045\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10653: 0.7536020278930664\n",
            "INFO:tensorflow:pgen_loss: 4.485333442687988\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10654: 0.8958015441894531\n",
            "INFO:tensorflow:pgen_loss: 3.7026774883270264\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10655: 0.994011402130127\n",
            "INFO:tensorflow:pgen_loss: 4.051690578460693\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10656: 0.6871030330657959\n",
            "INFO:tensorflow:pgen_loss: 3.2259304523468018\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10657: 0.5695939064025879\n",
            "INFO:tensorflow:pgen_loss: 3.4714877605438232\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10658: 0.8068814277648926\n",
            "INFO:tensorflow:pgen_loss: 3.396981716156006\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10659: 1.0674500465393066\n",
            "INFO:tensorflow:pgen_loss: 3.2599387168884277\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10660: 1.1085219383239746\n",
            "INFO:tensorflow:pgen_loss: 3.987766742706299\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10661: 1.1068191528320312\n",
            "INFO:tensorflow:pgen_loss: 4.242108345031738\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10662: 0.48787593841552734\n",
            "INFO:tensorflow:pgen_loss: 2.8898262977600098\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10663: 0.5301249027252197\n",
            "INFO:tensorflow:pgen_loss: 3.6742866039276123\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10664: 0.935497522354126\n",
            "INFO:tensorflow:pgen_loss: 3.3575637340545654\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10665: 0.57737135887146\n",
            "INFO:tensorflow:pgen_loss: 3.4155850410461426\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10666: 0.6257259845733643\n",
            "INFO:tensorflow:pgen_loss: 4.0985612869262695\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10667: 0.9367995262145996\n",
            "INFO:tensorflow:pgen_loss: 4.025728702545166\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10668: 0.6121103763580322\n",
            "INFO:tensorflow:pgen_loss: 3.516253709793091\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10669: 0.9310903549194336\n",
            "INFO:tensorflow:pgen_loss: 3.582531452178955\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10670: 0.42427515983581543\n",
            "INFO:tensorflow:pgen_loss: 3.071261405944824\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10671: 0.46607327461242676\n",
            "INFO:tensorflow:pgen_loss: 3.297806978225708\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10672: 0.5594828128814697\n",
            "INFO:tensorflow:pgen_loss: 3.648982286453247\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10673: 0.7762267589569092\n",
            "INFO:tensorflow:pgen_loss: 3.6913914680480957\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10674: 0.5130774974822998\n",
            "INFO:tensorflow:pgen_loss: 3.2357184886932373\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10675: 0.5591318607330322\n",
            "INFO:tensorflow:pgen_loss: 3.4532809257507324\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10676: 1.043959140777588\n",
            "INFO:tensorflow:pgen_loss: 3.9111244678497314\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10677: 0.550689697265625\n",
            "INFO:tensorflow:pgen_loss: 3.3819847106933594\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10678: 0.5855176448822021\n",
            "INFO:tensorflow:pgen_loss: 3.1661810874938965\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10679: 0.3629765510559082\n",
            "INFO:tensorflow:pgen_loss: 3.1524617671966553\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10680: 0.6128621101379395\n",
            "INFO:tensorflow:pgen_loss: 3.07580304145813\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10681: 0.4960050582885742\n",
            "INFO:tensorflow:pgen_loss: 3.706014633178711\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10682: 0.9959256649017334\n",
            "INFO:tensorflow:pgen_loss: 3.7563419342041016\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10683: 0.9629428386688232\n",
            "INFO:tensorflow:pgen_loss: 3.02067232131958\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10684: 0.9806070327758789\n",
            "INFO:tensorflow:pgen_loss: 3.975144147872925\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10685: 0.9774644374847412\n",
            "INFO:tensorflow:pgen_loss: 3.4874846935272217\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10686: 0.9541091918945312\n",
            "INFO:tensorflow:pgen_loss: 3.5455734729766846\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10687: 1.004812240600586\n",
            "INFO:tensorflow:pgen_loss: 3.552494764328003\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10688: 0.6265804767608643\n",
            "INFO:tensorflow:pgen_loss: 3.0054218769073486\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10689: 0.5937159061431885\n",
            "INFO:tensorflow:pgen_loss: 3.5058891773223877\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10690: 0.6565077304840088\n",
            "INFO:tensorflow:pgen_loss: 3.6123058795928955\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10691: 0.7445478439331055\n",
            "INFO:tensorflow:pgen_loss: 3.8683180809020996\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10692: 0.9811761379241943\n",
            "INFO:tensorflow:pgen_loss: 3.473532199859619\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10693: 0.7705647945404053\n",
            "INFO:tensorflow:pgen_loss: 4.250632286071777\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10694: 0.7070448398590088\n",
            "INFO:tensorflow:pgen_loss: 3.6164848804473877\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10695: 0.5818729400634766\n",
            "INFO:tensorflow:pgen_loss: 4.194681644439697\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10696: 0.9730393886566162\n",
            "INFO:tensorflow:pgen_loss: 3.710233211517334\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10697: 0.6218569278717041\n",
            "INFO:tensorflow:pgen_loss: 3.2949326038360596\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10698: 0.7421298027038574\n",
            "INFO:tensorflow:pgen_loss: 3.6729931831359863\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10699: 0.5915470123291016\n",
            "INFO:tensorflow:pgen_loss: 3.671851396560669\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10700: 0.9080109596252441\n",
            "INFO:tensorflow:pgen_loss: 3.6078953742980957\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10701: 0.6952457427978516\n",
            "INFO:tensorflow:pgen_loss: 2.9652903079986572\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10702: 0.970081090927124\n",
            "INFO:tensorflow:pgen_loss: 4.312788486480713\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10703: 0.5910699367523193\n",
            "INFO:tensorflow:pgen_loss: 3.698535919189453\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10704: 0.5945188999176025\n",
            "INFO:tensorflow:pgen_loss: 3.7797820568084717\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10705: 0.6904170513153076\n",
            "INFO:tensorflow:pgen_loss: 4.093986511230469\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10706: 0.46057558059692383\n",
            "INFO:tensorflow:pgen_loss: 4.183435440063477\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10707: 0.9840898513793945\n",
            "INFO:tensorflow:pgen_loss: 4.448802471160889\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10708: 0.38460803031921387\n",
            "INFO:tensorflow:pgen_loss: 3.5894036293029785\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10709: 0.5554475784301758\n",
            "INFO:tensorflow:pgen_loss: 3.290192127227783\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10710: 0.9601716995239258\n",
            "INFO:tensorflow:pgen_loss: 4.098167419433594\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10711: 0.9831478595733643\n",
            "INFO:tensorflow:pgen_loss: 4.025754928588867\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10712: 0.9691622257232666\n",
            "INFO:tensorflow:pgen_loss: 3.889084577560425\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10713: 0.3603241443634033\n",
            "INFO:tensorflow:pgen_loss: 3.691462278366089\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10714: 0.5163857936859131\n",
            "INFO:tensorflow:pgen_loss: 3.5333075523376465\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10715: 1.0089256763458252\n",
            "INFO:tensorflow:pgen_loss: 4.411437511444092\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10716: 0.8612337112426758\n",
            "INFO:tensorflow:pgen_loss: 3.583948850631714\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10717: 0.5009636878967285\n",
            "INFO:tensorflow:pgen_loss: 3.220097303390503\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10718: 0.9775590896606445\n",
            "INFO:tensorflow:pgen_loss: 3.4146804809570312\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10719: 0.7026104927062988\n",
            "INFO:tensorflow:pgen_loss: 4.018202781677246\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10720: 0.46217989921569824\n",
            "INFO:tensorflow:pgen_loss: 3.660243511199951\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10721: 0.8017599582672119\n",
            "INFO:tensorflow:pgen_loss: 4.133959770202637\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10722: 0.9900109767913818\n",
            "INFO:tensorflow:pgen_loss: 4.223471164703369\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10723: 0.8053514957427979\n",
            "INFO:tensorflow:pgen_loss: 3.9112770557403564\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10724: 0.23764753341674805\n",
            "INFO:tensorflow:pgen_loss: 4.045561790466309\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:Saving checkpoint to path drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step 10725: 0.7951571941375732\n",
            "INFO:tensorflow:pgen_loss: 4.533278942108154\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10726: 0.8993151187896729\n",
            "INFO:tensorflow:pgen_loss: 3.7322425842285156\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-10724.data-00000-of-00001\n",
            "INFO:tensorflow:186200\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-10724.index\n",
            "INFO:tensorflow:186200\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-10724.meta\n",
            "INFO:tensorflow:190500\n",
            "INFO:tensorflow:seconds for training step 10727: 1.0781774520874023\n",
            "INFO:tensorflow:pgen_loss: 4.125724792480469\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10728: 0.9525501728057861\n",
            "INFO:tensorflow:pgen_loss: 3.970407009124756\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10729: 0.6440050601959229\n",
            "INFO:tensorflow:pgen_loss: 3.789127826690674\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10730: 0.48624110221862793\n",
            "INFO:tensorflow:pgen_loss: 3.48022723197937\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10731: 0.9818267822265625\n",
            "INFO:tensorflow:pgen_loss: 4.335352897644043\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10732: 0.5637750625610352\n",
            "INFO:tensorflow:pgen_loss: 3.4845097064971924\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10733: 0.3412337303161621\n",
            "INFO:tensorflow:pgen_loss: 3.0172839164733887\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10734: 0.9885401725769043\n",
            "INFO:tensorflow:pgen_loss: 4.163243293762207\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10735: 0.955315351486206\n",
            "INFO:tensorflow:pgen_loss: 3.8828208446502686\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10736: 0.9108083248138428\n",
            "INFO:tensorflow:pgen_loss: 3.8805480003356934\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10737: 1.1252007484436035\n",
            "INFO:tensorflow:pgen_loss: 3.691052198410034\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10738: 0.6079061031341553\n",
            "INFO:tensorflow:pgen_loss: 3.060227394104004\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10739: 0.687885046005249\n",
            "INFO:tensorflow:pgen_loss: 3.5871787071228027\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10740: 1.120558500289917\n",
            "INFO:tensorflow:pgen_loss: 3.7228305339813232\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10741: 0.9671189785003662\n",
            "INFO:tensorflow:pgen_loss: 3.6660594940185547\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10742: 0.4143223762512207\n",
            "INFO:tensorflow:pgen_loss: 3.531214475631714\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10743: 0.26131176948547363\n",
            "INFO:tensorflow:pgen_loss: 2.7041633129119873\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10744: 0.9873600006103516\n",
            "INFO:tensorflow:pgen_loss: 3.5006794929504395\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10745: 0.975701093673706\n",
            "INFO:tensorflow:pgen_loss: 4.133993625640869\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10746: 0.6461923122406006\n",
            "INFO:tensorflow:pgen_loss: 3.705949068069458\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10747: 0.39884305000305176\n",
            "INFO:tensorflow:pgen_loss: 2.764524459838867\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10748: 0.9904720783233643\n",
            "INFO:tensorflow:pgen_loss: 4.39559268951416\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10749: 0.6387162208557129\n",
            "INFO:tensorflow:pgen_loss: 3.8525681495666504\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10750: 0.7779593467712402\n",
            "INFO:tensorflow:pgen_loss: 3.787785291671753\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10751: 0.9961018562316895\n",
            "INFO:tensorflow:pgen_loss: 3.580854892730713\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10752: 0.6493659019470215\n",
            "INFO:tensorflow:pgen_loss: 4.734557151794434\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10753: 1.0211842060089111\n",
            "INFO:tensorflow:pgen_loss: 3.9788482189178467\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10754: 0.8215615749359131\n",
            "INFO:tensorflow:pgen_loss: 3.5836341381073\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10755: 0.7338535785675049\n",
            "INFO:tensorflow:pgen_loss: 3.209629774093628\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10756: 0.6716854572296143\n",
            "INFO:tensorflow:pgen_loss: 3.383517026901245\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10757: 0.49764037132263184\n",
            "INFO:tensorflow:pgen_loss: 3.4928619861602783\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10758: 0.42327046394348145\n",
            "INFO:tensorflow:pgen_loss: 3.1422247886657715\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10759: 0.8351013660430908\n",
            "INFO:tensorflow:pgen_loss: 3.7634968757629395\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10760: 0.9758198261260986\n",
            "INFO:tensorflow:pgen_loss: 4.509839057922363\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10761: 0.6220932006835938\n",
            "INFO:tensorflow:pgen_loss: 3.6698355674743652\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10762: 0.9924216270446777\n",
            "INFO:tensorflow:pgen_loss: 3.9523704051971436\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10763: 0.7730855941772461\n",
            "INFO:tensorflow:pgen_loss: 4.704502582550049\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10764: 0.7482900619506836\n",
            "INFO:tensorflow:pgen_loss: 3.5425000190734863\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10765: 0.9325108528137207\n",
            "INFO:tensorflow:pgen_loss: 4.127213478088379\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10766: 0.4254295825958252\n",
            "INFO:tensorflow:pgen_loss: 2.754398822784424\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10767: 0.5715398788452148\n",
            "INFO:tensorflow:pgen_loss: 3.991269588470459\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10768: 0.7974250316619873\n",
            "INFO:tensorflow:pgen_loss: 4.171177387237549\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10769: 0.9944252967834473\n",
            "INFO:tensorflow:pgen_loss: 4.503963470458984\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10770: 0.7183845043182373\n",
            "INFO:tensorflow:pgen_loss: 3.856555461883545\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10771: 0.9619982242584229\n",
            "INFO:tensorflow:pgen_loss: 3.989668607711792\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10772: 0.948638916015625\n",
            "INFO:tensorflow:pgen_loss: 4.168032169342041\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10773: 0.9808444976806641\n",
            "INFO:tensorflow:pgen_loss: 3.9239895343780518\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10774: 0.7930777072906494\n",
            "INFO:tensorflow:pgen_loss: 4.570651054382324\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10775: 0.5215208530426025\n",
            "INFO:tensorflow:pgen_loss: 3.1781222820281982\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10776: 0.9667911529541016\n",
            "INFO:tensorflow:pgen_loss: 3.8678863048553467\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10777: 0.7767348289489746\n",
            "INFO:tensorflow:pgen_loss: 3.5104873180389404\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10778: 0.9769423007965088\n",
            "INFO:tensorflow:pgen_loss: 4.1717529296875\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10779: 0.9721903800964355\n",
            "INFO:tensorflow:pgen_loss: 3.5996994972229004\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10780: 0.6488137245178223\n",
            "INFO:tensorflow:pgen_loss: 3.806307315826416\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10781: 0.4922187328338623\n",
            "INFO:tensorflow:pgen_loss: 3.4153695106506348\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10782: 0.9403722286224365\n",
            "INFO:tensorflow:pgen_loss: 3.439962387084961\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10783: 0.7705032825469971\n",
            "INFO:tensorflow:pgen_loss: 3.9098243713378906\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10784: 0.8607504367828369\n",
            "INFO:tensorflow:pgen_loss: 2.984158992767334\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10785: 0.9789881706237793\n",
            "INFO:tensorflow:pgen_loss: 4.2820868492126465\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10786: 0.9557347297668457\n",
            "INFO:tensorflow:pgen_loss: 3.806725263595581\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10787: 0.6096904277801514\n",
            "INFO:tensorflow:pgen_loss: 3.9550251960754395\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10788: 0.9599006175994873\n",
            "INFO:tensorflow:pgen_loss: 3.5637238025665283\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10789: 0.9389100074768066\n",
            "INFO:tensorflow:pgen_loss: 3.6364612579345703\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10790: 0.8854279518127441\n",
            "INFO:tensorflow:pgen_loss: 4.320834159851074\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10791: 0.9628119468688965\n",
            "INFO:tensorflow:pgen_loss: 3.6688430309295654\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10792: 0.9938006401062012\n",
            "INFO:tensorflow:pgen_loss: 3.9063668251037598\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10793: 0.9984850883483887\n",
            "INFO:tensorflow:pgen_loss: 4.063704013824463\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10794: 0.808168888092041\n",
            "INFO:tensorflow:pgen_loss: 3.8816027641296387\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10795: 0.9985489845275879\n",
            "INFO:tensorflow:pgen_loss: 4.003884792327881\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10796: 0.6098616123199463\n",
            "INFO:tensorflow:pgen_loss: 3.9898884296417236\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:Saving checkpoint to path drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step 10797: 0.5197992324829102\n",
            "INFO:tensorflow:pgen_loss: 4.275567531585693\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10798: 1.428832769393921\n",
            "INFO:tensorflow:pgen_loss: 3.860414981842041\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-10796.data-00000-of-00001\n",
            "INFO:tensorflow:186200\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-10796.index\n",
            "INFO:tensorflow:186200\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-10796.meta\n",
            "INFO:tensorflow:190500\n",
            "INFO:tensorflow:seconds for training step 10799: 1.2601547241210938\n",
            "INFO:tensorflow:pgen_loss: 3.0771117210388184\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10800: 0.7453789710998535\n",
            "INFO:tensorflow:pgen_loss: 3.5098299980163574\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10801: 1.7518310546875\n",
            "INFO:tensorflow:pgen_loss: 3.9528565406799316\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10802: 0.4615335464477539\n",
            "INFO:tensorflow:pgen_loss: 2.1542513370513916\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10803: 0.5920851230621338\n",
            "INFO:tensorflow:pgen_loss: 4.47340202331543\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10804: 0.7068831920623779\n",
            "INFO:tensorflow:pgen_loss: 4.033621788024902\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10805: 0.9747796058654785\n",
            "INFO:tensorflow:pgen_loss: 3.761378765106201\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10806: 0.821277379989624\n",
            "INFO:tensorflow:pgen_loss: 3.3283753395080566\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10807: 0.9987623691558838\n",
            "INFO:tensorflow:pgen_loss: 3.9656174182891846\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10808: 0.9178650379180908\n",
            "INFO:tensorflow:pgen_loss: 3.7788195610046387\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10809: 1.033916711807251\n",
            "INFO:tensorflow:pgen_loss: 3.4205222129821777\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10810: 0.9444892406463623\n",
            "INFO:tensorflow:pgen_loss: 4.181575298309326\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10811: 0.859560489654541\n",
            "INFO:tensorflow:pgen_loss: 4.778295040130615\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10812: 1.0603101253509521\n",
            "INFO:tensorflow:pgen_loss: 3.728778123855591\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10813: 0.8673148155212402\n",
            "INFO:tensorflow:pgen_loss: 3.73590087890625\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10814: 0.7869982719421387\n",
            "INFO:tensorflow:pgen_loss: 3.7993247509002686\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10815: 0.9861786365509033\n",
            "INFO:tensorflow:pgen_loss: 3.621711254119873\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10816: 0.9716818332672119\n",
            "INFO:tensorflow:pgen_loss: 3.939789295196533\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10817: 0.5753576755523682\n",
            "INFO:tensorflow:pgen_loss: 4.021540641784668\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10818: 0.5588932037353516\n",
            "INFO:tensorflow:pgen_loss: 2.871643543243408\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10819: 0.6222634315490723\n",
            "INFO:tensorflow:pgen_loss: 3.9851653575897217\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10820: 0.963637113571167\n",
            "INFO:tensorflow:pgen_loss: 3.909621477127075\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10821: 0.6851918697357178\n",
            "INFO:tensorflow:pgen_loss: 3.485699415206909\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10822: 0.5662491321563721\n",
            "INFO:tensorflow:pgen_loss: 3.105095624923706\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10823: 0.7499446868896484\n",
            "INFO:tensorflow:pgen_loss: 4.202703475952148\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10824: 0.3758258819580078\n",
            "INFO:tensorflow:pgen_loss: 3.081406831741333\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10825: 0.39758777618408203\n",
            "INFO:tensorflow:pgen_loss: 2.5791015625\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10826: 0.5605900287628174\n",
            "INFO:tensorflow:pgen_loss: 2.9233546257019043\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10827: 1.0035641193389893\n",
            "INFO:tensorflow:pgen_loss: 3.626035690307617\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10828: 0.9759554862976074\n",
            "INFO:tensorflow:pgen_loss: 3.6977686882019043\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10829: 0.9903512001037598\n",
            "INFO:tensorflow:pgen_loss: 3.172914743423462\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10830: 0.49298715591430664\n",
            "INFO:tensorflow:pgen_loss: 3.1674561500549316\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10831: 0.652606725692749\n",
            "INFO:tensorflow:pgen_loss: 4.1081366539001465\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10832: 0.9689517021179199\n",
            "INFO:tensorflow:pgen_loss: 3.918793201446533\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10833: 0.6930491924285889\n",
            "INFO:tensorflow:pgen_loss: 3.486546754837036\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10834: 0.8614628314971924\n",
            "INFO:tensorflow:pgen_loss: 3.187655210494995\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10835: 0.8403759002685547\n",
            "INFO:tensorflow:pgen_loss: 4.211112022399902\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10836: 0.5552370548248291\n",
            "INFO:tensorflow:pgen_loss: 3.0473575592041016\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10837: 0.4417388439178467\n",
            "INFO:tensorflow:pgen_loss: 3.3805267810821533\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10838: 0.43448495864868164\n",
            "INFO:tensorflow:pgen_loss: 3.2806396484375\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10839: 0.46398091316223145\n",
            "INFO:tensorflow:pgen_loss: 3.594147205352783\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10840: 0.600900411605835\n",
            "INFO:tensorflow:pgen_loss: 3.619231700897217\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10841: 0.46587657928466797\n",
            "INFO:tensorflow:pgen_loss: 2.9717063903808594\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10842: 0.3567349910736084\n",
            "INFO:tensorflow:pgen_loss: 2.4810101985931396\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10843: 0.7367064952850342\n",
            "INFO:tensorflow:pgen_loss: 3.6436927318573\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10844: 0.5938138961791992\n",
            "INFO:tensorflow:pgen_loss: 3.3641045093536377\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10845: 1.0082008838653564\n",
            "INFO:tensorflow:pgen_loss: 3.573500394821167\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10846: 0.8214054107666016\n",
            "INFO:tensorflow:pgen_loss: 3.5765023231506348\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10847: 0.7512426376342773\n",
            "INFO:tensorflow:pgen_loss: 3.193150758743286\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10848: 0.7514843940734863\n",
            "INFO:tensorflow:pgen_loss: 3.8743362426757812\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10849: 0.43671536445617676\n",
            "INFO:tensorflow:pgen_loss: 3.4718680381774902\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10850: 0.6463046073913574\n",
            "INFO:tensorflow:pgen_loss: 3.1774771213531494\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10851: 0.3768794536590576\n",
            "INFO:tensorflow:pgen_loss: 3.4665093421936035\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10852: 0.8314008712768555\n",
            "INFO:tensorflow:pgen_loss: 4.298177242279053\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10853: 0.5272073745727539\n",
            "INFO:tensorflow:pgen_loss: 3.942460536956787\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10854: 0.9814772605895996\n",
            "INFO:tensorflow:pgen_loss: 4.331944465637207\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10855: 0.5340671539306641\n",
            "INFO:tensorflow:pgen_loss: 2.886239528656006\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10856: 0.7837681770324707\n",
            "INFO:tensorflow:pgen_loss: 3.7791900634765625\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10857: 0.9422016143798828\n",
            "INFO:tensorflow:pgen_loss: 3.469240665435791\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10858: 0.39339327812194824\n",
            "INFO:tensorflow:pgen_loss: 3.4281280040740967\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10859: 0.8949508666992188\n",
            "INFO:tensorflow:pgen_loss: 3.98488187789917\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10860: 0.9459068775177002\n",
            "INFO:tensorflow:pgen_loss: 3.2567055225372314\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10861: 0.6397378444671631\n",
            "INFO:tensorflow:pgen_loss: 3.507614850997925\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10862: 0.7124524116516113\n",
            "INFO:tensorflow:pgen_loss: 4.161998271942139\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10863: 0.9280364513397217\n",
            "INFO:tensorflow:pgen_loss: 3.8329358100891113\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10864: 0.8928155899047852\n",
            "INFO:tensorflow:pgen_loss: 3.37894868850708\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10865: 0.5427858829498291\n",
            "INFO:tensorflow:pgen_loss: 3.3454184532165527\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10866: 0.6863803863525391\n",
            "INFO:tensorflow:pgen_loss: 3.646775007247925\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10867: 0.6466114521026611\n",
            "INFO:tensorflow:pgen_loss: 3.601506471633911\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10868: 0.6653282642364502\n",
            "INFO:tensorflow:pgen_loss: 4.03076696395874\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10869: 0.6159954071044922\n",
            "INFO:tensorflow:pgen_loss: 3.7159202098846436\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10870: 0.9055435657501221\n",
            "INFO:tensorflow:pgen_loss: 3.87261962890625\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10871: 1.0017197132110596\n",
            "INFO:tensorflow:pgen_loss: 3.8477859497070312\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10872: 0.9480843544006348\n",
            "INFO:tensorflow:pgen_loss: 4.208215236663818\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:Saving checkpoint to path drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step 10873: 1.658618688583374\n",
            "INFO:tensorflow:pgen_loss: 3.5230910778045654\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-10872.data-00000-of-00001\n",
            "INFO:tensorflow:186200\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-10872.index\n",
            "INFO:tensorflow:186200\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-10872.meta\n",
            "INFO:tensorflow:190500\n",
            "INFO:tensorflow:seconds for training step 10874: 1.2062597274780273\n",
            "INFO:tensorflow:pgen_loss: 3.3088061809539795\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10875: 0.6518800258636475\n",
            "INFO:tensorflow:pgen_loss: 3.306312084197998\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10876: 0.6352136135101318\n",
            "INFO:tensorflow:pgen_loss: 4.083234786987305\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10877: 0.8321318626403809\n",
            "INFO:tensorflow:pgen_loss: 3.8866398334503174\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10878: 0.6432600021362305\n",
            "INFO:tensorflow:pgen_loss: 3.941815137863159\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10879: 0.41961097717285156\n",
            "INFO:tensorflow:pgen_loss: 3.0742969512939453\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10880: 0.3400082588195801\n",
            "INFO:tensorflow:pgen_loss: 2.354236602783203\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10881: 0.4917140007019043\n",
            "INFO:tensorflow:pgen_loss: 3.732546329498291\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10882: 0.9717831611633301\n",
            "INFO:tensorflow:pgen_loss: 3.494365692138672\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10883: 0.9284088611602783\n",
            "INFO:tensorflow:pgen_loss: 3.421525478363037\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10884: 0.5016336441040039\n",
            "INFO:tensorflow:pgen_loss: 3.4390106201171875\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10885: 0.5686080455780029\n",
            "INFO:tensorflow:pgen_loss: 3.5280964374542236\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10886: 0.5523815155029297\n",
            "INFO:tensorflow:pgen_loss: 2.832397937774658\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10887: 0.9988558292388916\n",
            "INFO:tensorflow:pgen_loss: 3.760836362838745\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10888: 1.0668058395385742\n",
            "INFO:tensorflow:pgen_loss: 3.3372206687927246\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10889: 1.0057950019836426\n",
            "INFO:tensorflow:pgen_loss: 3.721276044845581\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10890: 0.726438045501709\n",
            "INFO:tensorflow:pgen_loss: 4.291018962860107\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10891: 0.8947772979736328\n",
            "INFO:tensorflow:pgen_loss: 3.539996385574341\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10892: 0.9143095016479492\n",
            "INFO:tensorflow:pgen_loss: 4.247969150543213\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10893: 0.6058228015899658\n",
            "INFO:tensorflow:pgen_loss: 3.279871702194214\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10894: 0.6847689151763916\n",
            "INFO:tensorflow:pgen_loss: 3.8182532787323\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10895: 0.768507719039917\n",
            "INFO:tensorflow:pgen_loss: 3.7530555725097656\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10896: 0.6758346557617188\n",
            "INFO:tensorflow:pgen_loss: 3.444187879562378\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10897: 0.9890758991241455\n",
            "INFO:tensorflow:pgen_loss: 3.6993374824523926\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10898: 0.9884762763977051\n",
            "INFO:tensorflow:pgen_loss: 3.3141326904296875\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10899: 0.8009963035583496\n",
            "INFO:tensorflow:pgen_loss: 3.7636756896972656\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10900: 0.6646802425384521\n",
            "INFO:tensorflow:pgen_loss: 3.901580810546875\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10901: 0.7794773578643799\n",
            "INFO:tensorflow:pgen_loss: 3.416365146636963\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10902: 0.6602849960327148\n",
            "INFO:tensorflow:pgen_loss: 3.463106870651245\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10903: 0.7162084579467773\n",
            "INFO:tensorflow:pgen_loss: 3.7275993824005127\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10904: 0.40802931785583496\n",
            "INFO:tensorflow:pgen_loss: 3.417008876800537\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10905: 0.7502615451812744\n",
            "INFO:tensorflow:pgen_loss: 3.6085190773010254\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10906: 0.48938703536987305\n",
            "INFO:tensorflow:pgen_loss: 3.3595130443573\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10907: 1.0000841617584229\n",
            "INFO:tensorflow:pgen_loss: 4.191953182220459\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10908: 1.01788330078125\n",
            "INFO:tensorflow:pgen_loss: 3.6716091632843018\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10909: 0.5572617053985596\n",
            "INFO:tensorflow:pgen_loss: 4.188164710998535\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10910: 0.5784308910369873\n",
            "INFO:tensorflow:pgen_loss: 3.4157726764678955\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10911: 0.5224106311798096\n",
            "INFO:tensorflow:pgen_loss: 3.6215240955352783\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10912: 0.7811446189880371\n",
            "INFO:tensorflow:pgen_loss: 3.6605567932128906\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10913: 0.5650041103363037\n",
            "INFO:tensorflow:pgen_loss: 3.7598090171813965\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10914: 0.9531927108764648\n",
            "INFO:tensorflow:pgen_loss: 3.986845016479492\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10915: 0.6410496234893799\n",
            "INFO:tensorflow:pgen_loss: 4.243784427642822\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10916: 0.6904003620147705\n",
            "INFO:tensorflow:pgen_loss: 3.9746341705322266\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10917: 0.44567322731018066\n",
            "INFO:tensorflow:pgen_loss: 3.7115368843078613\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10918: 0.375469446182251\n",
            "INFO:tensorflow:pgen_loss: 3.2807579040527344\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10919: 0.9964373111724854\n",
            "INFO:tensorflow:pgen_loss: 4.451689720153809\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10920: 0.9952573776245117\n",
            "INFO:tensorflow:pgen_loss: 4.452167510986328\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10921: 0.3931889533996582\n",
            "INFO:tensorflow:pgen_loss: 2.8171234130859375\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10922: 0.6005113124847412\n",
            "INFO:tensorflow:pgen_loss: 3.2951126098632812\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10923: 0.8092026710510254\n",
            "INFO:tensorflow:pgen_loss: 3.856431245803833\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10924: 0.9934651851654053\n",
            "INFO:tensorflow:pgen_loss: 4.431308746337891\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10925: 0.935779333114624\n",
            "INFO:tensorflow:pgen_loss: 3.599774122238159\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10926: 0.8856661319732666\n",
            "INFO:tensorflow:pgen_loss: 3.8321120738983154\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10927: 0.764258623123169\n",
            "INFO:tensorflow:pgen_loss: 3.732156276702881\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10928: 0.4133586883544922\n",
            "INFO:tensorflow:pgen_loss: 2.996718645095825\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10929: 0.6357817649841309\n",
            "INFO:tensorflow:pgen_loss: 3.475660800933838\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10930: 0.6396059989929199\n",
            "INFO:tensorflow:pgen_loss: 2.817899465560913\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10931: 0.5925493240356445\n",
            "INFO:tensorflow:pgen_loss: 3.2039437294006348\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10932: 0.9659507274627686\n",
            "INFO:tensorflow:pgen_loss: 3.9676365852355957\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10933: 0.6469252109527588\n",
            "INFO:tensorflow:pgen_loss: 3.649249315261841\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10934: 0.9863913059234619\n",
            "INFO:tensorflow:pgen_loss: 4.07306432723999\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10935: 0.9868192672729492\n",
            "INFO:tensorflow:pgen_loss: 4.433337211608887\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10936: 0.6164035797119141\n",
            "INFO:tensorflow:pgen_loss: 3.456355571746826\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10937: 0.9544892311096191\n",
            "INFO:tensorflow:pgen_loss: 3.5869498252868652\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10938: 0.586554765701294\n",
            "INFO:tensorflow:pgen_loss: 3.5979061126708984\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10939: 0.9950013160705566\n",
            "INFO:tensorflow:pgen_loss: 3.888805389404297\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10940: 0.3917088508605957\n",
            "INFO:tensorflow:pgen_loss: 3.0854053497314453\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10941: 0.9550971984863281\n",
            "INFO:tensorflow:pgen_loss: 3.83729887008667\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10942: 1.0032923221588135\n",
            "INFO:tensorflow:pgen_loss: 4.09537410736084\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10943: 0.8195507526397705\n",
            "INFO:tensorflow:pgen_loss: 3.3543593883514404\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10944: 0.8295447826385498\n",
            "INFO:tensorflow:pgen_loss: 3.7940144538879395\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10945: 0.3787689208984375\n",
            "INFO:tensorflow:pgen_loss: 2.8493287563323975\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10946: 0.9891290664672852\n",
            "INFO:tensorflow:pgen_loss: 4.2108564376831055\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10947: 0.7136828899383545\n",
            "INFO:tensorflow:pgen_loss: 4.227706432342529\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10948: 0.3477461338043213\n",
            "INFO:tensorflow:pgen_loss: 2.701547145843506\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10949: 0.9841170310974121\n",
            "INFO:tensorflow:pgen_loss: 4.009669780731201\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:Saving checkpoint to path drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step 10950: 0.9694385528564453\n",
            "INFO:tensorflow:pgen_loss: 3.7485854625701904\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10951: 1.4967765808105469\n",
            "INFO:tensorflow:pgen_loss: 3.757315158843994\t\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-10949.data-00000-of-00001\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:186200\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-10949.index\n",
            "INFO:tensorflow:186200\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-10949.meta\n",
            "INFO:tensorflow:190500\n",
            "INFO:tensorflow:seconds for training step 10952: 0.9581935405731201\n",
            "INFO:tensorflow:pgen_loss: 3.6979591846466064\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10953: 0.8400180339813232\n",
            "INFO:tensorflow:pgen_loss: 4.09273624420166\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10954: 1.0080230236053467\n",
            "INFO:tensorflow:pgen_loss: 3.971309185028076\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10955: 0.6835250854492188\n",
            "INFO:tensorflow:pgen_loss: 3.2901034355163574\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10956: 0.8480970859527588\n",
            "INFO:tensorflow:pgen_loss: 3.664414882659912\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10957: 0.6763448715209961\n",
            "INFO:tensorflow:pgen_loss: 2.903564453125\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10958: 0.4738645553588867\n",
            "INFO:tensorflow:pgen_loss: 4.166721820831299\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10959: 0.8651583194732666\n",
            "INFO:tensorflow:pgen_loss: 4.204998016357422\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10960: 0.48903679847717285\n",
            "INFO:tensorflow:pgen_loss: 2.7712225914001465\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10961: 0.919635534286499\n",
            "INFO:tensorflow:pgen_loss: 4.112886905670166\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10962: 1.1403234004974365\n",
            "INFO:tensorflow:pgen_loss: 3.834017276763916\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10963: 0.5322988033294678\n",
            "INFO:tensorflow:pgen_loss: 3.237302303314209\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10964: 0.7506265640258789\n",
            "INFO:tensorflow:pgen_loss: 2.869842052459717\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10965: 0.5052309036254883\n",
            "INFO:tensorflow:pgen_loss: 3.798232316970825\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10966: 0.7609138488769531\n",
            "INFO:tensorflow:pgen_loss: 3.450709819793701\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10967: 1.084794521331787\n",
            "INFO:tensorflow:pgen_loss: 4.533886909484863\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10968: 0.9633042812347412\n",
            "INFO:tensorflow:pgen_loss: 4.58950138092041\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10969: 0.6306912899017334\n",
            "INFO:tensorflow:pgen_loss: 4.063256740570068\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10970: 0.5220813751220703\n",
            "INFO:tensorflow:pgen_loss: 3.323472499847412\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10971: 0.9577431678771973\n",
            "INFO:tensorflow:pgen_loss: 3.902632236480713\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10972: 0.773747444152832\n",
            "INFO:tensorflow:pgen_loss: 3.8603522777557373\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10973: 0.9924578666687012\n",
            "INFO:tensorflow:pgen_loss: 3.8527228832244873\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10974: 0.9813268184661865\n",
            "INFO:tensorflow:pgen_loss: 4.1195526123046875\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10975: 1.008735179901123\n",
            "INFO:tensorflow:pgen_loss: 4.093928337097168\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10976: 0.6001665592193604\n",
            "INFO:tensorflow:pgen_loss: 4.251589775085449\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10977: 0.8060038089752197\n",
            "INFO:tensorflow:pgen_loss: 3.7209599018096924\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10978: 0.9951772689819336\n",
            "INFO:tensorflow:pgen_loss: 3.103938341140747\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10979: 0.657050609588623\n",
            "INFO:tensorflow:pgen_loss: 3.611173629760742\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10980: 0.565380334854126\n",
            "INFO:tensorflow:pgen_loss: 3.995217800140381\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10981: 0.5190155506134033\n",
            "INFO:tensorflow:pgen_loss: 3.7252724170684814\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10982: 0.8757171630859375\n",
            "INFO:tensorflow:pgen_loss: 4.0267815589904785\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10983: 0.9954512119293213\n",
            "INFO:tensorflow:pgen_loss: 3.645747423171997\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10984: 0.8173458576202393\n",
            "INFO:tensorflow:pgen_loss: 3.483015775680542\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10985: 0.7252106666564941\n",
            "INFO:tensorflow:pgen_loss: 3.915879487991333\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10986: 0.833547830581665\n",
            "INFO:tensorflow:pgen_loss: 3.8918464183807373\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10987: 0.30489087104797363\n",
            "INFO:tensorflow:pgen_loss: 2.6047134399414062\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10988: 0.9872865676879883\n",
            "INFO:tensorflow:pgen_loss: 4.081518173217773\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10989: 0.5031182765960693\n",
            "INFO:tensorflow:pgen_loss: 3.706275224685669\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10990: 1.0132346153259277\n",
            "INFO:tensorflow:pgen_loss: 3.622462511062622\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10991: 0.6540384292602539\n",
            "INFO:tensorflow:pgen_loss: 4.1373186111450195\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10992: 0.955653190612793\n",
            "INFO:tensorflow:pgen_loss: 3.1855857372283936\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10993: 0.426105260848999\n",
            "INFO:tensorflow:pgen_loss: 3.5719451904296875\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10994: 0.9538712501525879\n",
            "INFO:tensorflow:pgen_loss: 4.371633529663086\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10995: 0.5841081142425537\n",
            "INFO:tensorflow:pgen_loss: 2.70428729057312\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10996: 0.524836540222168\n",
            "INFO:tensorflow:pgen_loss: 2.736001491546631\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10997: 0.9157702922821045\n",
            "INFO:tensorflow:pgen_loss: 3.4064643383026123\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10998: 0.8480668067932129\n",
            "INFO:tensorflow:pgen_loss: 3.232083559036255\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 10999: 1.069040060043335\n",
            "INFO:tensorflow:pgen_loss: 3.97755765914917\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11000: 0.7602279186248779\n",
            "INFO:tensorflow:pgen_loss: 3.3482069969177246\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11001: 1.6256141662597656\n",
            "INFO:tensorflow:pgen_loss: 3.875286817550659\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11002: 0.5439174175262451\n",
            "INFO:tensorflow:pgen_loss: 4.110262393951416\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11003: 0.7657368183135986\n",
            "INFO:tensorflow:pgen_loss: 3.9112353324890137\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11004: 0.9608132839202881\n",
            "INFO:tensorflow:pgen_loss: 3.3762078285217285\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11005: 0.3208189010620117\n",
            "INFO:tensorflow:pgen_loss: 2.9400415420532227\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11006: 0.6242082118988037\n",
            "INFO:tensorflow:pgen_loss: 3.5614395141601562\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11007: 0.7597508430480957\n",
            "INFO:tensorflow:pgen_loss: 3.829425811767578\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11008: 0.5723598003387451\n",
            "INFO:tensorflow:pgen_loss: 3.4990668296813965\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11009: 1.003169059753418\n",
            "INFO:tensorflow:pgen_loss: 4.1004109382629395\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11010: 0.793438196182251\n",
            "INFO:tensorflow:pgen_loss: 3.6809871196746826\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11011: 0.9447660446166992\n",
            "INFO:tensorflow:pgen_loss: 3.8494293689727783\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11012: 0.9939990043640137\n",
            "INFO:tensorflow:pgen_loss: 4.178771018981934\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11013: 0.9715678691864014\n",
            "INFO:tensorflow:pgen_loss: 4.108529090881348\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11014: 0.31020545959472656\n",
            "INFO:tensorflow:pgen_loss: 2.8088927268981934\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11015: 0.5714805126190186\n",
            "INFO:tensorflow:pgen_loss: 3.539562225341797\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11016: 0.44529294967651367\n",
            "INFO:tensorflow:pgen_loss: 3.134739398956299\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11017: 0.8187539577484131\n",
            "INFO:tensorflow:pgen_loss: 3.6031107902526855\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11018: 0.7604103088378906\n",
            "INFO:tensorflow:pgen_loss: 2.8318400382995605\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11019: 0.9930386543273926\n",
            "INFO:tensorflow:pgen_loss: 3.5146186351776123\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11020: 0.780132532119751\n",
            "INFO:tensorflow:pgen_loss: 3.631514310836792\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11021: 0.8203394412994385\n",
            "INFO:tensorflow:pgen_loss: 3.776926040649414\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11022: 1.0482392311096191\n",
            "INFO:tensorflow:pgen_loss: 4.164463996887207\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:Saving checkpoint to path drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step 11023: 0.7875494956970215\n",
            "INFO:tensorflow:pgen_loss: 3.3599517345428467\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11024: 1.5091500282287598\n",
            "INFO:tensorflow:pgen_loss: 4.057936191558838\t\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-11022.data-00000-of-00001\n",
            "INFO:tensorflow:186200\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-11022.index\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:186200\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-11022.meta\n",
            "INFO:tensorflow:190500\n",
            "INFO:tensorflow:seconds for training step 11025: 0.7413098812103271\n",
            "INFO:tensorflow:pgen_loss: 3.709794521331787\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11026: 0.8487019538879395\n",
            "INFO:tensorflow:pgen_loss: 3.7686543464660645\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11027: 0.9597530364990234\n",
            "INFO:tensorflow:pgen_loss: 3.659299850463867\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11028: 0.9560575485229492\n",
            "INFO:tensorflow:pgen_loss: 4.0997314453125\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11029: 0.8799624443054199\n",
            "INFO:tensorflow:pgen_loss: 4.270592212677002\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11030: 0.9673144817352295\n",
            "INFO:tensorflow:pgen_loss: 3.699432849884033\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11031: 0.9879360198974609\n",
            "INFO:tensorflow:pgen_loss: 3.4210689067840576\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11032: 0.715609073638916\n",
            "INFO:tensorflow:pgen_loss: 3.858335018157959\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11033: 0.6133480072021484\n",
            "INFO:tensorflow:pgen_loss: 3.0557703971862793\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11034: 1.0472493171691895\n",
            "INFO:tensorflow:pgen_loss: 4.006760597229004\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11035: 0.3992915153503418\n",
            "INFO:tensorflow:pgen_loss: 3.7427589893341064\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11036: 0.8551812171936035\n",
            "INFO:tensorflow:pgen_loss: 3.334054946899414\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11037: 0.6139557361602783\n",
            "INFO:tensorflow:pgen_loss: 3.6495227813720703\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11038: 0.7127399444580078\n",
            "INFO:tensorflow:pgen_loss: 3.855175018310547\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11039: 0.9496109485626221\n",
            "INFO:tensorflow:pgen_loss: 3.6951727867126465\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11040: 0.6929285526275635\n",
            "INFO:tensorflow:pgen_loss: 2.900977611541748\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11041: 0.64162278175354\n",
            "INFO:tensorflow:pgen_loss: 4.5260491371154785\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11042: 0.3475193977355957\n",
            "INFO:tensorflow:pgen_loss: 2.935896635055542\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11043: 0.9946885108947754\n",
            "INFO:tensorflow:pgen_loss: 3.7179698944091797\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11044: 0.5896074771881104\n",
            "INFO:tensorflow:pgen_loss: 3.3267085552215576\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11045: 0.9204800128936768\n",
            "INFO:tensorflow:pgen_loss: 4.105327606201172\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11046: 0.9823808670043945\n",
            "INFO:tensorflow:pgen_loss: 3.5657458305358887\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11047: 0.44803547859191895\n",
            "INFO:tensorflow:pgen_loss: 3.635016679763794\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11048: 0.5557844638824463\n",
            "INFO:tensorflow:pgen_loss: 4.511291027069092\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11049: 0.906609296798706\n",
            "INFO:tensorflow:pgen_loss: 3.726357936859131\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11050: 0.6045706272125244\n",
            "INFO:tensorflow:pgen_loss: 3.2270584106445312\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11051: 0.9737613201141357\n",
            "INFO:tensorflow:pgen_loss: 3.9774422645568848\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11052: 0.584144115447998\n",
            "INFO:tensorflow:pgen_loss: 4.687650203704834\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11053: 0.5823583602905273\n",
            "INFO:tensorflow:pgen_loss: 4.016462326049805\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11054: 0.9904189109802246\n",
            "INFO:tensorflow:pgen_loss: 4.031524181365967\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11055: 0.98067307472229\n",
            "INFO:tensorflow:pgen_loss: 3.900491714477539\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11056: 0.979792594909668\n",
            "INFO:tensorflow:pgen_loss: 3.330780029296875\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11057: 0.9479930400848389\n",
            "INFO:tensorflow:pgen_loss: 3.4640281200408936\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11058: 1.0469279289245605\n",
            "INFO:tensorflow:pgen_loss: 3.146555185317993\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11059: 0.9756102561950684\n",
            "INFO:tensorflow:pgen_loss: 4.45228910446167\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11060: 0.9677233695983887\n",
            "INFO:tensorflow:pgen_loss: 3.1295101642608643\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11061: 0.8263912200927734\n",
            "INFO:tensorflow:pgen_loss: 3.5212531089782715\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11062: 0.47792887687683105\n",
            "INFO:tensorflow:pgen_loss: 2.6063578128814697\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11063: 0.9951109886169434\n",
            "INFO:tensorflow:pgen_loss: 3.4782474040985107\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11064: 0.563248872756958\n",
            "INFO:tensorflow:pgen_loss: 3.715710163116455\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11065: 0.46191859245300293\n",
            "INFO:tensorflow:pgen_loss: 2.644456148147583\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11066: 0.8214969635009766\n",
            "INFO:tensorflow:pgen_loss: 3.7949154376983643\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11067: 0.8141074180603027\n",
            "INFO:tensorflow:pgen_loss: 4.239274501800537\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11068: 0.45298290252685547\n",
            "INFO:tensorflow:pgen_loss: 3.446864366531372\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11069: 0.8057296276092529\n",
            "INFO:tensorflow:pgen_loss: 4.404837131500244\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11070: 0.3878946304321289\n",
            "INFO:tensorflow:pgen_loss: 3.455435276031494\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11071: 0.7549057006835938\n",
            "INFO:tensorflow:pgen_loss: 4.126236915588379\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11072: 0.669029951095581\n",
            "INFO:tensorflow:pgen_loss: 3.868661403656006\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11073: 0.556593656539917\n",
            "INFO:tensorflow:pgen_loss: 3.337057590484619\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11074: 0.9536869525909424\n",
            "INFO:tensorflow:pgen_loss: 3.7407124042510986\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11075: 0.9670937061309814\n",
            "INFO:tensorflow:pgen_loss: 3.8212103843688965\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11076: 0.9737799167633057\n",
            "INFO:tensorflow:pgen_loss: 2.7543070316314697\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11077: 0.5896635055541992\n",
            "INFO:tensorflow:pgen_loss: 2.8157238960266113\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11078: 0.8852300643920898\n",
            "INFO:tensorflow:pgen_loss: 3.8162293434143066\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11079: 0.6014854907989502\n",
            "INFO:tensorflow:pgen_loss: 3.5363450050354004\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11080: 0.829979658126831\n",
            "INFO:tensorflow:pgen_loss: 3.856823682785034\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11081: 0.6344168186187744\n",
            "INFO:tensorflow:pgen_loss: 3.823693037033081\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11082: 0.6109192371368408\n",
            "INFO:tensorflow:pgen_loss: 4.217038631439209\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11083: 1.000096321105957\n",
            "INFO:tensorflow:pgen_loss: 3.5415186882019043\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11084: 0.3127562999725342\n",
            "INFO:tensorflow:pgen_loss: 2.786128520965576\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11085: 0.9997718334197998\n",
            "INFO:tensorflow:pgen_loss: 3.471789598464966\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11086: 0.7139260768890381\n",
            "INFO:tensorflow:pgen_loss: 3.6129822731018066\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11087: 0.4269108772277832\n",
            "INFO:tensorflow:pgen_loss: 3.3511714935302734\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11088: 0.8889997005462646\n",
            "INFO:tensorflow:pgen_loss: 4.017394542694092\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11089: 0.5207014083862305\n",
            "INFO:tensorflow:pgen_loss: 4.005383491516113\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11090: 0.9983186721801758\n",
            "INFO:tensorflow:pgen_loss: 3.6699821949005127\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11091: 0.484952449798584\n",
            "INFO:tensorflow:pgen_loss: 3.7314467430114746\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11092: 0.7533793449401855\n",
            "INFO:tensorflow:pgen_loss: 3.863767623901367\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11093: 0.7106220722198486\n",
            "INFO:tensorflow:pgen_loss: 3.2945282459259033\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11094: 0.44698643684387207\n",
            "INFO:tensorflow:pgen_loss: 3.5155110359191895\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11095: 0.7287330627441406\n",
            "INFO:tensorflow:pgen_loss: 3.180097818374634\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11096: 0.5207159519195557\n",
            "INFO:tensorflow:pgen_loss: 4.276928901672363\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11097: 0.4701995849609375\n",
            "INFO:tensorflow:pgen_loss: 3.410503387451172\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11098: 1.0113201141357422\n",
            "INFO:tensorflow:pgen_loss: 3.908876895904541\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:Saving checkpoint to path drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step 11099: 1.4591233730316162\n",
            "INFO:tensorflow:pgen_loss: 3.7076473236083984\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-11098.data-00000-of-00001\n",
            "INFO:tensorflow:186200\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-11098.index\n",
            "INFO:tensorflow:186200\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-11098.meta\n",
            "INFO:tensorflow:190500\n",
            "INFO:tensorflow:seconds for training step 11100: 0.7099945545196533\n",
            "INFO:tensorflow:pgen_loss: 3.6500306129455566\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11101: 0.8842754364013672\n",
            "INFO:tensorflow:pgen_loss: 3.3085789680480957\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11102: 0.9977366924285889\n",
            "INFO:tensorflow:pgen_loss: 3.856776714324951\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11103: 0.6940968036651611\n",
            "INFO:tensorflow:pgen_loss: 4.252795219421387\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11104: 0.8043999671936035\n",
            "INFO:tensorflow:pgen_loss: 3.803668260574341\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11105: 0.9698596000671387\n",
            "INFO:tensorflow:pgen_loss: 4.281487941741943\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11106: 0.6949830055236816\n",
            "INFO:tensorflow:pgen_loss: 3.721841335296631\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11107: 0.6907005310058594\n",
            "INFO:tensorflow:pgen_loss: 3.624030590057373\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11108: 0.7200818061828613\n",
            "INFO:tensorflow:pgen_loss: 3.4415855407714844\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11109: 0.9692728519439697\n",
            "INFO:tensorflow:pgen_loss: 3.529639482498169\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11110: 0.748960018157959\n",
            "INFO:tensorflow:pgen_loss: 3.9019877910614014\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11111: 1.0006697177886963\n",
            "INFO:tensorflow:pgen_loss: 3.7201004028320312\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11112: 0.6244018077850342\n",
            "INFO:tensorflow:pgen_loss: 3.358611583709717\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11113: 0.8801207542419434\n",
            "INFO:tensorflow:pgen_loss: 3.503291368484497\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11114: 0.9646785259246826\n",
            "INFO:tensorflow:pgen_loss: 3.6674485206604004\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11115: 0.9642322063446045\n",
            "INFO:tensorflow:pgen_loss: 4.01121187210083\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11116: 1.0019676685333252\n",
            "INFO:tensorflow:pgen_loss: 3.5918993949890137\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11117: 1.004197120666504\n",
            "INFO:tensorflow:pgen_loss: 3.9000320434570312\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11118: 0.8353397846221924\n",
            "INFO:tensorflow:pgen_loss: 5.023499488830566\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11119: 0.40037059783935547\n",
            "INFO:tensorflow:pgen_loss: 3.078015089035034\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11120: 0.9830212593078613\n",
            "INFO:tensorflow:pgen_loss: 3.973278045654297\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11121: 0.44725894927978516\n",
            "INFO:tensorflow:pgen_loss: 3.644486665725708\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11122: 0.8051743507385254\n",
            "INFO:tensorflow:pgen_loss: 3.498886823654175\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11123: 0.4298076629638672\n",
            "INFO:tensorflow:pgen_loss: 3.1354057788848877\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11124: 0.6010251045227051\n",
            "INFO:tensorflow:pgen_loss: 3.472862958908081\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11125: 0.7966434955596924\n",
            "INFO:tensorflow:pgen_loss: 4.376943111419678\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11126: 0.9796099662780762\n",
            "INFO:tensorflow:pgen_loss: 3.5920956134796143\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11127: 0.6814429759979248\n",
            "INFO:tensorflow:pgen_loss: 2.9689958095550537\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11128: 0.31264710426330566\n",
            "INFO:tensorflow:pgen_loss: 3.025214672088623\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11129: 0.976578950881958\n",
            "INFO:tensorflow:pgen_loss: 4.772212028503418\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11130: 0.6032872200012207\n",
            "INFO:tensorflow:pgen_loss: 4.335528373718262\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11131: 0.7688019275665283\n",
            "INFO:tensorflow:pgen_loss: 4.1643218994140625\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11132: 1.0113770961761475\n",
            "INFO:tensorflow:pgen_loss: 4.249446868896484\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11133: 0.6514809131622314\n",
            "INFO:tensorflow:pgen_loss: 3.394562244415283\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11134: 0.4965970516204834\n",
            "INFO:tensorflow:pgen_loss: 3.6081366539001465\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11135: 1.055058479309082\n",
            "INFO:tensorflow:pgen_loss: 3.889310836791992\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11136: 0.5985429286956787\n",
            "INFO:tensorflow:pgen_loss: 3.06512713432312\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11137: 0.38542771339416504\n",
            "INFO:tensorflow:pgen_loss: 3.0272529125213623\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11138: 0.4633762836456299\n",
            "INFO:tensorflow:pgen_loss: 3.3219847679138184\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11139: 0.6965477466583252\n",
            "INFO:tensorflow:pgen_loss: 3.472848415374756\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11140: 0.9987452030181885\n",
            "INFO:tensorflow:pgen_loss: 3.530625104904175\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11141: 0.9396486282348633\n",
            "INFO:tensorflow:pgen_loss: 4.0200605392456055\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11142: 0.9938905239105225\n",
            "INFO:tensorflow:pgen_loss: 4.195700168609619\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11143: 0.4650743007659912\n",
            "INFO:tensorflow:pgen_loss: 3.36834716796875\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11144: 0.9559028148651123\n",
            "INFO:tensorflow:pgen_loss: 3.3039710521698\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11145: 0.7507789134979248\n",
            "INFO:tensorflow:pgen_loss: 3.4588470458984375\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11146: 0.9022667407989502\n",
            "INFO:tensorflow:pgen_loss: 4.0435099601745605\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11147: 0.5622828006744385\n",
            "INFO:tensorflow:pgen_loss: 4.325315475463867\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11148: 0.43036508560180664\n",
            "INFO:tensorflow:pgen_loss: 3.448373317718506\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11149: 0.5698463916778564\n",
            "INFO:tensorflow:pgen_loss: 3.2021210193634033\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11150: 0.5326299667358398\n",
            "INFO:tensorflow:pgen_loss: 3.8935940265655518\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11151: 0.8023250102996826\n",
            "INFO:tensorflow:pgen_loss: 4.007425785064697\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11152: 0.9916961193084717\n",
            "INFO:tensorflow:pgen_loss: 3.907717227935791\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11153: 0.9692869186401367\n",
            "INFO:tensorflow:pgen_loss: 4.394125938415527\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11154: 0.82651686668396\n",
            "INFO:tensorflow:pgen_loss: 3.9700140953063965\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11155: 0.49466896057128906\n",
            "INFO:tensorflow:pgen_loss: 2.9263510704040527\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11156: 0.7219846248626709\n",
            "INFO:tensorflow:pgen_loss: 3.7790703773498535\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11157: 0.3798637390136719\n",
            "INFO:tensorflow:pgen_loss: 3.486647129058838\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11158: 0.7375748157501221\n",
            "INFO:tensorflow:pgen_loss: 3.766568660736084\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11159: 0.5343360900878906\n",
            "INFO:tensorflow:pgen_loss: 2.846132755279541\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11160: 0.7932794094085693\n",
            "INFO:tensorflow:pgen_loss: 3.7558929920196533\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11161: 0.7827413082122803\n",
            "INFO:tensorflow:pgen_loss: 4.111933708190918\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11162: 0.5444509983062744\n",
            "INFO:tensorflow:pgen_loss: 3.598491668701172\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11163: 1.092132329940796\n",
            "INFO:tensorflow:pgen_loss: 4.211603164672852\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11164: 0.9952437877655029\n",
            "INFO:tensorflow:pgen_loss: 4.311511039733887\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11165: 0.7647652626037598\n",
            "INFO:tensorflow:pgen_loss: 4.0198845863342285\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11166: 0.9832196235656738\n",
            "INFO:tensorflow:pgen_loss: 3.6450886726379395\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11167: 0.6027169227600098\n",
            "INFO:tensorflow:pgen_loss: 3.7452354431152344\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11168: 0.39371800422668457\n",
            "INFO:tensorflow:pgen_loss: 3.2804627418518066\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11169: 1.0009844303131104\n",
            "INFO:tensorflow:pgen_loss: 3.9059948921203613\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11170: 0.5078816413879395\n",
            "INFO:tensorflow:pgen_loss: 4.390285968780518\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11171: 0.8685996532440186\n",
            "INFO:tensorflow:pgen_loss: 4.232182502746582\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11172: 0.7494471073150635\n",
            "INFO:tensorflow:pgen_loss: 3.5157055854797363\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11173: 0.6721625328063965\n",
            "INFO:tensorflow:pgen_loss: 3.6215286254882812\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11174: 0.43906068801879883\n",
            "INFO:tensorflow:pgen_loss: 2.9191064834594727\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:Saving checkpoint to path drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step 11175: 1.5138819217681885\n",
            "INFO:tensorflow:pgen_loss: 4.216338157653809\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-11174.data-00000-of-00001\n",
            "INFO:tensorflow:186200\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-11174.index\n",
            "INFO:tensorflow:186200\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-11174.meta\n",
            "INFO:tensorflow:190500\n",
            "INFO:tensorflow:seconds for training step 11176: 1.2021172046661377\n",
            "INFO:tensorflow:pgen_loss: 2.910130739212036\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11177: 0.7921750545501709\n",
            "INFO:tensorflow:pgen_loss: 3.5737571716308594\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11178: 1.0313746929168701\n",
            "INFO:tensorflow:pgen_loss: 4.639336109161377\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11179: 1.0257411003112793\n",
            "INFO:tensorflow:pgen_loss: 3.7802677154541016\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11180: 0.8638627529144287\n",
            "INFO:tensorflow:pgen_loss: 3.8291916847229004\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11181: 1.0001137256622314\n",
            "INFO:tensorflow:pgen_loss: 3.835299253463745\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11182: 0.6868679523468018\n",
            "INFO:tensorflow:pgen_loss: 3.521296739578247\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11183: 0.7347207069396973\n",
            "INFO:tensorflow:pgen_loss: 3.9563019275665283\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11184: 0.8172094821929932\n",
            "INFO:tensorflow:pgen_loss: 3.2893905639648438\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11185: 0.4998490810394287\n",
            "INFO:tensorflow:pgen_loss: 3.276172637939453\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11186: 0.734703540802002\n",
            "INFO:tensorflow:pgen_loss: 3.6318397521972656\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11187: 1.2205908298492432\n",
            "INFO:tensorflow:pgen_loss: 4.312768459320068\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11188: 1.255955457687378\n",
            "INFO:tensorflow:pgen_loss: 3.780012845993042\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11189: 1.1737477779388428\n",
            "INFO:tensorflow:pgen_loss: 4.1895647048950195\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11190: 1.0663607120513916\n",
            "INFO:tensorflow:pgen_loss: 3.950422763824463\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11191: 0.5069105625152588\n",
            "INFO:tensorflow:pgen_loss: 3.2975220680236816\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11192: 0.5892531871795654\n",
            "INFO:tensorflow:pgen_loss: 2.6622776985168457\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11193: 1.0149405002593994\n",
            "INFO:tensorflow:pgen_loss: 4.1882781982421875\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11194: 1.0492806434631348\n",
            "INFO:tensorflow:pgen_loss: 3.9430649280548096\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11195: 0.4913291931152344\n",
            "INFO:tensorflow:pgen_loss: 3.3992133140563965\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11196: 0.6711552143096924\n",
            "INFO:tensorflow:pgen_loss: 3.715519428253174\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11197: 0.6058638095855713\n",
            "INFO:tensorflow:pgen_loss: 2.8371047973632812\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11198: 1.5229473114013672\n",
            "INFO:tensorflow:pgen_loss: 3.137070894241333\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11199: 1.1297714710235596\n",
            "INFO:tensorflow:pgen_loss: 3.9011826515197754\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11200: 0.48119592666625977\n",
            "INFO:tensorflow:pgen_loss: 3.4356391429901123\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11201: 1.5042202472686768\n",
            "INFO:tensorflow:pgen_loss: 4.64190149307251\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11202: 1.2326209545135498\n",
            "INFO:tensorflow:pgen_loss: 4.199872970581055\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11203: 1.0585637092590332\n",
            "INFO:tensorflow:pgen_loss: 3.8151237964630127\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11204: 0.730379581451416\n",
            "INFO:tensorflow:pgen_loss: 3.140056610107422\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11205: 1.0446462631225586\n",
            "INFO:tensorflow:pgen_loss: 3.6750969886779785\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11206: 0.6482586860656738\n",
            "INFO:tensorflow:pgen_loss: 3.9383480548858643\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11207: 0.6529750823974609\n",
            "INFO:tensorflow:pgen_loss: 3.855762481689453\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11208: 1.0750105381011963\n",
            "INFO:tensorflow:pgen_loss: 3.534492015838623\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11209: 1.1026995182037354\n",
            "INFO:tensorflow:pgen_loss: 4.127436637878418\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11210: 0.6999120712280273\n",
            "INFO:tensorflow:pgen_loss: 3.526150941848755\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11211: 1.079216480255127\n",
            "INFO:tensorflow:pgen_loss: 4.406740665435791\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11212: 0.48023462295532227\n",
            "INFO:tensorflow:pgen_loss: 3.5225937366485596\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11213: 0.5770838260650635\n",
            "INFO:tensorflow:pgen_loss: 2.5255894660949707\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11214: 0.2864081859588623\n",
            "INFO:tensorflow:pgen_loss: 1.8900762796401978\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11215: 0.9770987033843994\n",
            "INFO:tensorflow:pgen_loss: 4.166995525360107\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11216: 0.6096529960632324\n",
            "INFO:tensorflow:pgen_loss: 3.0061545372009277\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11217: 0.6409306526184082\n",
            "INFO:tensorflow:pgen_loss: 3.7872347831726074\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11218: 0.49288487434387207\n",
            "INFO:tensorflow:pgen_loss: 2.9886927604675293\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11219: 1.0742640495300293\n",
            "INFO:tensorflow:pgen_loss: 3.5797526836395264\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11220: 0.9444375038146973\n",
            "INFO:tensorflow:pgen_loss: 3.440143585205078\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11221: 0.5589249134063721\n",
            "INFO:tensorflow:pgen_loss: 3.4621589183807373\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11222: 1.0671241283416748\n",
            "INFO:tensorflow:pgen_loss: 3.9739792346954346\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11223: 0.5123136043548584\n",
            "INFO:tensorflow:pgen_loss: 2.508744239807129\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11224: 0.8599321842193604\n",
            "INFO:tensorflow:pgen_loss: 3.7177555561065674\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11225: 0.8970320224761963\n",
            "INFO:tensorflow:pgen_loss: 3.6695971488952637\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11226: 0.7131483554840088\n",
            "INFO:tensorflow:pgen_loss: 3.788975477218628\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11227: 0.3259470462799072\n",
            "INFO:tensorflow:pgen_loss: 2.3081793785095215\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11228: 0.8566908836364746\n",
            "INFO:tensorflow:pgen_loss: 3.8021769523620605\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11229: 0.7026636600494385\n",
            "INFO:tensorflow:pgen_loss: 3.7469840049743652\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11230: 0.7078135013580322\n",
            "INFO:tensorflow:pgen_loss: 3.4729397296905518\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11231: 0.9453105926513672\n",
            "INFO:tensorflow:pgen_loss: 4.116430282592773\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11232: 1.087144374847412\n",
            "INFO:tensorflow:pgen_loss: 3.631664276123047\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11233: 0.7526299953460693\n",
            "INFO:tensorflow:pgen_loss: 3.7761597633361816\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11234: 0.7776315212249756\n",
            "INFO:tensorflow:pgen_loss: 3.2495949268341064\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11235: 1.0755319595336914\n",
            "INFO:tensorflow:pgen_loss: 3.5432465076446533\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11236: 0.6203279495239258\n",
            "INFO:tensorflow:pgen_loss: 2.736543655395508\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11237: 0.9075753688812256\n",
            "INFO:tensorflow:pgen_loss: 4.337740898132324\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11238: 0.40596818923950195\n",
            "INFO:tensorflow:pgen_loss: 3.307239055633545\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11239: 0.3820648193359375\n",
            "INFO:tensorflow:pgen_loss: 2.841407299041748\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11240: 1.100184679031372\n",
            "INFO:tensorflow:pgen_loss: 3.4409079551696777\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11241: 1.0748674869537354\n",
            "INFO:tensorflow:pgen_loss: 3.53800630569458\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11242: 0.8356268405914307\n",
            "INFO:tensorflow:pgen_loss: 3.868488311767578\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:Saving checkpoint to path drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step 11243: 1.2688498497009277\n",
            "INFO:tensorflow:pgen_loss: 3.880044460296631\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11244: 1.6674165725708008\n",
            "INFO:tensorflow:pgen_loss: 3.9973056316375732\t\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-11242.data-00000-of-00001\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:186200\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-11242.index\n",
            "INFO:tensorflow:186200\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-11242.meta\n",
            "INFO:tensorflow:190500\n",
            "INFO:tensorflow:seconds for training step 11245: 0.3886699676513672\n",
            "INFO:tensorflow:pgen_loss: 2.116065740585327\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11246: 0.43465304374694824\n",
            "INFO:tensorflow:pgen_loss: 4.330324649810791\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11247: 0.8425149917602539\n",
            "INFO:tensorflow:pgen_loss: 3.066955089569092\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11248: 1.0693531036376953\n",
            "INFO:tensorflow:pgen_loss: 3.529296875\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11249: 0.904437780380249\n",
            "INFO:tensorflow:pgen_loss: 3.7412750720977783\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11250: 1.0450899600982666\n",
            "INFO:tensorflow:pgen_loss: 4.116722106933594\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11251: 0.6984531879425049\n",
            "INFO:tensorflow:pgen_loss: 4.0536699295043945\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11252: 0.518791675567627\n",
            "INFO:tensorflow:pgen_loss: 3.909273147583008\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11253: 1.0678565502166748\n",
            "INFO:tensorflow:pgen_loss: 4.294220924377441\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11254: 0.8737046718597412\n",
            "INFO:tensorflow:pgen_loss: 4.0165114402771\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11255: 0.6653084754943848\n",
            "INFO:tensorflow:pgen_loss: 3.766740322113037\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11256: 1.2637953758239746\n",
            "INFO:tensorflow:pgen_loss: 3.9600906372070312\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11257: 0.8057422637939453\n",
            "INFO:tensorflow:pgen_loss: 3.3947834968566895\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11258: 0.46690797805786133\n",
            "INFO:tensorflow:pgen_loss: 3.451305866241455\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11259: 1.1207854747772217\n",
            "INFO:tensorflow:pgen_loss: 3.9333667755126953\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11260: 1.127136468887329\n",
            "INFO:tensorflow:pgen_loss: 3.9976298809051514\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11261: 0.7459495067596436\n",
            "INFO:tensorflow:pgen_loss: 3.7284140586853027\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11262: 0.94297194480896\n",
            "INFO:tensorflow:pgen_loss: 3.6104347705841064\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11263: 0.7064259052276611\n",
            "INFO:tensorflow:pgen_loss: 3.641995906829834\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11264: 1.0273821353912354\n",
            "INFO:tensorflow:pgen_loss: 3.9556050300598145\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11265: 0.6771078109741211\n",
            "INFO:tensorflow:pgen_loss: 3.406745195388794\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11266: 0.3728008270263672\n",
            "INFO:tensorflow:pgen_loss: 2.661595582962036\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11267: 0.4428272247314453\n",
            "INFO:tensorflow:pgen_loss: 3.007605791091919\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11268: 1.0503997802734375\n",
            "INFO:tensorflow:pgen_loss: 4.155060768127441\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11269: 0.40044331550598145\n",
            "INFO:tensorflow:pgen_loss: 2.655608892440796\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11270: 0.731769323348999\n",
            "INFO:tensorflow:pgen_loss: 3.0279223918914795\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11271: 0.7388780117034912\n",
            "INFO:tensorflow:pgen_loss: 3.712322235107422\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11272: 0.3872039318084717\n",
            "INFO:tensorflow:pgen_loss: 3.2508301734924316\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11273: 0.6613872051239014\n",
            "INFO:tensorflow:pgen_loss: 3.451516628265381\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11274: 0.6662194728851318\n",
            "INFO:tensorflow:pgen_loss: 3.071880578994751\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11275: 0.5530798435211182\n",
            "INFO:tensorflow:pgen_loss: 3.2296195030212402\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11276: 1.047267198562622\n",
            "INFO:tensorflow:pgen_loss: 4.040676116943359\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11277: 1.0006437301635742\n",
            "INFO:tensorflow:pgen_loss: 2.899829864501953\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11278: 0.584705114364624\n",
            "INFO:tensorflow:pgen_loss: 3.696079730987549\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11279: 1.059230089187622\n",
            "INFO:tensorflow:pgen_loss: 3.848945140838623\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11280: 0.7493524551391602\n",
            "INFO:tensorflow:pgen_loss: 3.390129804611206\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11281: 1.03568696975708\n",
            "INFO:tensorflow:pgen_loss: 4.171135902404785\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11282: 0.6268854141235352\n",
            "INFO:tensorflow:pgen_loss: 2.6710638999938965\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11283: 1.0098650455474854\n",
            "INFO:tensorflow:pgen_loss: 3.076162815093994\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11284: 0.9929988384246826\n",
            "INFO:tensorflow:pgen_loss: 3.11253023147583\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11285: 1.0637075901031494\n",
            "INFO:tensorflow:pgen_loss: 3.9471259117126465\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11286: 1.0606324672698975\n",
            "INFO:tensorflow:pgen_loss: 3.8512072563171387\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11287: 0.38897156715393066\n",
            "INFO:tensorflow:pgen_loss: 2.460422992706299\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11288: 0.6383798122406006\n",
            "INFO:tensorflow:pgen_loss: 3.004037857055664\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11289: 0.6845130920410156\n",
            "INFO:tensorflow:pgen_loss: 3.7677650451660156\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11290: 1.08730149269104\n",
            "INFO:tensorflow:pgen_loss: 3.4408645629882812\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11291: 0.9286320209503174\n",
            "INFO:tensorflow:pgen_loss: 4.183133602142334\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11292: 0.7582399845123291\n",
            "INFO:tensorflow:pgen_loss: 3.2359817028045654\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11293: 0.5969798564910889\n",
            "INFO:tensorflow:pgen_loss: 2.5605850219726562\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11294: 1.0773060321807861\n",
            "INFO:tensorflow:pgen_loss: 3.811455249786377\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11295: 1.0583539009094238\n",
            "INFO:tensorflow:pgen_loss: 4.084325790405273\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11296: 0.952441930770874\n",
            "INFO:tensorflow:pgen_loss: 3.9724020957946777\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11297: 0.7953388690948486\n",
            "INFO:tensorflow:pgen_loss: 3.622129440307617\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11298: 0.9065675735473633\n",
            "INFO:tensorflow:pgen_loss: 3.11755108833313\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11299: 1.0445046424865723\n",
            "INFO:tensorflow:pgen_loss: 4.142319679260254\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11300: 1.0037426948547363\n",
            "INFO:tensorflow:pgen_loss: 3.5773072242736816\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11301: 0.8191733360290527\n",
            "INFO:tensorflow:pgen_loss: 3.5176937580108643\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11302: 0.6948368549346924\n",
            "INFO:tensorflow:pgen_loss: 3.351165294647217\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11303: 0.6002867221832275\n",
            "INFO:tensorflow:pgen_loss: 4.192277908325195\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11304: 0.40921926498413086\n",
            "INFO:tensorflow:pgen_loss: 2.9312217235565186\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11305: 0.6438302993774414\n",
            "INFO:tensorflow:pgen_loss: 4.055021286010742\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11306: 0.6459264755249023\n",
            "INFO:tensorflow:pgen_loss: 3.027726411819458\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11307: 0.47802257537841797\n",
            "INFO:tensorflow:pgen_loss: 3.228393077850342\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11308: 0.9677298069000244\n",
            "INFO:tensorflow:pgen_loss: 3.8322646617889404\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11309: 0.8251481056213379\n",
            "INFO:tensorflow:pgen_loss: 3.9037837982177734\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11310: 0.787773609161377\n",
            "INFO:tensorflow:pgen_loss: 3.6037116050720215\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11311: 0.7920005321502686\n",
            "INFO:tensorflow:pgen_loss: 3.294389247894287\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11312: 1.0465373992919922\n",
            "INFO:tensorflow:pgen_loss: 3.917713165283203\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11313: 0.7267587184906006\n",
            "INFO:tensorflow:pgen_loss: 4.035904884338379\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:Saving checkpoint to path drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step 11314: 1.2857081890106201\n",
            "INFO:tensorflow:pgen_loss: 3.692840576171875\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11315: 1.2313354015350342\n",
            "INFO:tensorflow:pgen_loss: 3.7339160442352295\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-11313.data-00000-of-00001\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:186200\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-11313.index\n",
            "INFO:tensorflow:186200\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-11313.meta\n",
            "INFO:tensorflow:190500\n",
            "INFO:tensorflow:seconds for training step 11316: 0.9912528991699219\n",
            "INFO:tensorflow:pgen_loss: 3.7872138023376465\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11317: 0.6131424903869629\n",
            "INFO:tensorflow:pgen_loss: 2.896083116531372\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11318: 0.9935159683227539\n",
            "INFO:tensorflow:pgen_loss: 4.011975288391113\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11319: 0.8947775363922119\n",
            "INFO:tensorflow:pgen_loss: 3.918308973312378\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11320: 0.8025929927825928\n",
            "INFO:tensorflow:pgen_loss: 3.6855270862579346\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11321: 0.651324987411499\n",
            "INFO:tensorflow:pgen_loss: 4.302425384521484\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11322: 0.5725815296173096\n",
            "INFO:tensorflow:pgen_loss: 3.2921886444091797\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11323: 0.671043872833252\n",
            "INFO:tensorflow:pgen_loss: 3.2540507316589355\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11324: 1.0713629722595215\n",
            "INFO:tensorflow:pgen_loss: 4.196561336517334\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11325: 0.918940544128418\n",
            "INFO:tensorflow:pgen_loss: 3.7824349403381348\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11326: 0.700000524520874\n",
            "INFO:tensorflow:pgen_loss: 3.029113292694092\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11327: 1.2100005149841309\n",
            "INFO:tensorflow:pgen_loss: 3.8005499839782715\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11328: 1.2540979385375977\n",
            "INFO:tensorflow:pgen_loss: 3.5147175788879395\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11329: 1.243859052658081\n",
            "INFO:tensorflow:pgen_loss: 4.135228633880615\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11330: 0.5778379440307617\n",
            "INFO:tensorflow:pgen_loss: 3.1094937324523926\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11331: 0.3861405849456787\n",
            "INFO:tensorflow:pgen_loss: 3.349799394607544\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11332: 0.4418916702270508\n",
            "INFO:tensorflow:pgen_loss: 3.50238037109375\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11333: 0.4881324768066406\n",
            "INFO:tensorflow:pgen_loss: 3.000521183013916\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11334: 0.8606407642364502\n",
            "INFO:tensorflow:pgen_loss: 3.254671573638916\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11335: 0.9039967060089111\n",
            "INFO:tensorflow:pgen_loss: 3.2294414043426514\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11336: 0.34393763542175293\n",
            "INFO:tensorflow:pgen_loss: 2.1637256145477295\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11337: 1.093820333480835\n",
            "INFO:tensorflow:pgen_loss: 4.135668754577637\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11338: 1.060405969619751\n",
            "INFO:tensorflow:pgen_loss: 4.029628276824951\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11339: 0.7807369232177734\n",
            "INFO:tensorflow:pgen_loss: 3.671919345855713\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11340: 0.4482691287994385\n",
            "INFO:tensorflow:pgen_loss: 4.095261573791504\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11341: 0.4506337642669678\n",
            "INFO:tensorflow:pgen_loss: 3.9357657432556152\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11342: 1.0652275085449219\n",
            "INFO:tensorflow:pgen_loss: 3.7165439128875732\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11343: 1.0919370651245117\n",
            "INFO:tensorflow:pgen_loss: 3.9912543296813965\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11344: 1.0004730224609375\n",
            "INFO:tensorflow:pgen_loss: 3.851536273956299\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11345: 0.5006945133209229\n",
            "INFO:tensorflow:pgen_loss: 3.7243945598602295\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11346: 1.068040370941162\n",
            "INFO:tensorflow:pgen_loss: 4.273985862731934\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11347: 0.4208261966705322\n",
            "INFO:tensorflow:pgen_loss: 3.3220252990722656\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11348: 0.9798591136932373\n",
            "INFO:tensorflow:pgen_loss: 3.8522746562957764\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11349: 1.075864315032959\n",
            "INFO:tensorflow:pgen_loss: 3.7168526649475098\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11350: 0.43604207038879395\n",
            "INFO:tensorflow:pgen_loss: 3.1716322898864746\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11351: 1.0608494281768799\n",
            "INFO:tensorflow:pgen_loss: 4.419248580932617\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11352: 1.0513699054718018\n",
            "INFO:tensorflow:pgen_loss: 3.9713432788848877\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11353: 0.4010121822357178\n",
            "INFO:tensorflow:pgen_loss: 3.1819610595703125\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11354: 0.8739087581634521\n",
            "INFO:tensorflow:pgen_loss: 3.282456159591675\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11355: 0.9803073406219482\n",
            "INFO:tensorflow:pgen_loss: 3.1152100563049316\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11356: 1.0557234287261963\n",
            "INFO:tensorflow:pgen_loss: 3.449531078338623\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11357: 0.6021268367767334\n",
            "INFO:tensorflow:pgen_loss: 4.15803337097168\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11358: 0.5606014728546143\n",
            "INFO:tensorflow:pgen_loss: 3.266988754272461\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11359: 0.5735344886779785\n",
            "INFO:tensorflow:pgen_loss: 3.639672040939331\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11360: 0.5911529064178467\n",
            "INFO:tensorflow:pgen_loss: 3.479581832885742\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11361: 0.438720703125\n",
            "INFO:tensorflow:pgen_loss: 3.0852155685424805\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11362: 1.0586881637573242\n",
            "INFO:tensorflow:pgen_loss: 3.806490659713745\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11363: 0.9546220302581787\n",
            "INFO:tensorflow:pgen_loss: 3.936845302581787\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11364: 1.0288922786712646\n",
            "INFO:tensorflow:pgen_loss: 4.299507141113281\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11365: 0.944591760635376\n",
            "INFO:tensorflow:pgen_loss: 4.154348850250244\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11366: 0.5322906970977783\n",
            "INFO:tensorflow:pgen_loss: 3.6742405891418457\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11367: 1.0479099750518799\n",
            "INFO:tensorflow:pgen_loss: 4.663384437561035\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11368: 1.0520529747009277\n",
            "INFO:tensorflow:pgen_loss: 3.0935168266296387\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11369: 0.5539572238922119\n",
            "INFO:tensorflow:pgen_loss: 2.8743555545806885\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11370: 0.7579176425933838\n",
            "INFO:tensorflow:pgen_loss: 4.21695613861084\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11371: 1.0295002460479736\n",
            "INFO:tensorflow:pgen_loss: 3.9445488452911377\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11372: 0.6166791915893555\n",
            "INFO:tensorflow:pgen_loss: 3.0323879718780518\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11373: 0.5446343421936035\n",
            "INFO:tensorflow:pgen_loss: 3.1569862365722656\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11374: 0.6895074844360352\n",
            "INFO:tensorflow:pgen_loss: 3.8856425285339355\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11375: 0.7156691551208496\n",
            "INFO:tensorflow:pgen_loss: 3.8130123615264893\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11376: 0.7958157062530518\n",
            "INFO:tensorflow:pgen_loss: 3.516892671585083\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11377: 1.0460553169250488\n",
            "INFO:tensorflow:pgen_loss: 4.199295997619629\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11378: 0.4923274517059326\n",
            "INFO:tensorflow:pgen_loss: 2.861393451690674\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11379: 0.38106513023376465\n",
            "INFO:tensorflow:pgen_loss: 2.8354530334472656\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11380: 0.8344001770019531\n",
            "INFO:tensorflow:pgen_loss: 3.2826104164123535\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11381: 0.6118924617767334\n",
            "INFO:tensorflow:pgen_loss: 4.243163108825684\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11382: 1.049919843673706\n",
            "INFO:tensorflow:pgen_loss: 3.9977803230285645\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11383: 1.0421702861785889\n",
            "INFO:tensorflow:pgen_loss: 4.401815891265869\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11384: 0.8899993896484375\n",
            "INFO:tensorflow:pgen_loss: 3.9666645526885986\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11385: 0.5699191093444824\n",
            "INFO:tensorflow:pgen_loss: 4.237610816955566\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:Saving checkpoint to path drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step 11386: 0.8865296840667725\n",
            "INFO:tensorflow:pgen_loss: 3.36413836479187\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11387: 1.2107162475585938\n",
            "INFO:tensorflow:pgen_loss: 3.3056957721710205\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-11385.data-00000-of-00001\n",
            "INFO:tensorflow:186200\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-11385.index\n",
            "INFO:tensorflow:186200\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-11385.meta\n",
            "INFO:tensorflow:190500\n",
            "INFO:tensorflow:seconds for training step 11388: 0.8201677799224854\n",
            "INFO:tensorflow:pgen_loss: 3.3884453773498535\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11389: 1.030386209487915\n",
            "INFO:tensorflow:pgen_loss: 3.9253087043762207\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11390: 1.0153679847717285\n",
            "INFO:tensorflow:pgen_loss: 3.491461992263794\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11391: 1.0441057682037354\n",
            "INFO:tensorflow:pgen_loss: 4.534516334533691\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11392: 0.34182190895080566\n",
            "INFO:tensorflow:pgen_loss: 2.857156991958618\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11393: 1.027822732925415\n",
            "INFO:tensorflow:pgen_loss: 3.788515090942383\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11394: 0.9455206394195557\n",
            "INFO:tensorflow:pgen_loss: 3.1820387840270996\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11395: 1.0271058082580566\n",
            "INFO:tensorflow:pgen_loss: 3.6877593994140625\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11396: 1.0547983646392822\n",
            "INFO:tensorflow:pgen_loss: 3.188037872314453\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11397: 0.7606160640716553\n",
            "INFO:tensorflow:pgen_loss: 3.2270424365997314\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11398: 1.949866771697998\n",
            "INFO:tensorflow:pgen_loss: 3.4296061992645264\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11399: 0.696558952331543\n",
            "INFO:tensorflow:pgen_loss: 4.187734127044678\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11400: 1.1787693500518799\n",
            "INFO:tensorflow:pgen_loss: 3.405423641204834\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11401: 0.8683066368103027\n",
            "INFO:tensorflow:pgen_loss: 2.993762493133545\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11402: 0.9857172966003418\n",
            "INFO:tensorflow:pgen_loss: 2.4743728637695312\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11403: 1.0361847877502441\n",
            "INFO:tensorflow:pgen_loss: 3.604210615158081\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11404: 0.6948795318603516\n",
            "INFO:tensorflow:pgen_loss: 3.7308993339538574\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11405: 1.0251057147979736\n",
            "INFO:tensorflow:pgen_loss: 3.663748264312744\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11406: 0.8086047172546387\n",
            "INFO:tensorflow:pgen_loss: 4.132183074951172\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11407: 0.717125654220581\n",
            "INFO:tensorflow:pgen_loss: 3.5229995250701904\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11408: 1.003540277481079\n",
            "INFO:tensorflow:pgen_loss: 3.0762743949890137\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11409: 0.6614484786987305\n",
            "INFO:tensorflow:pgen_loss: 4.592629432678223\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11410: 1.0384902954101562\n",
            "INFO:tensorflow:pgen_loss: 3.4657044410705566\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11411: 0.5174474716186523\n",
            "INFO:tensorflow:pgen_loss: 3.063204288482666\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11412: 0.7504227161407471\n",
            "INFO:tensorflow:pgen_loss: 4.026788234710693\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11413: 0.47773003578186035\n",
            "INFO:tensorflow:pgen_loss: 3.6608054637908936\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11414: 0.4812445640563965\n",
            "INFO:tensorflow:pgen_loss: 3.9541656970977783\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11415: 0.6703290939331055\n",
            "INFO:tensorflow:pgen_loss: 4.174266815185547\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11416: 1.006617546081543\n",
            "INFO:tensorflow:pgen_loss: 3.860279083251953\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11417: 0.8063583374023438\n",
            "INFO:tensorflow:pgen_loss: 3.4859225749969482\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11418: 1.027336597442627\n",
            "INFO:tensorflow:pgen_loss: 3.506298065185547\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11419: 0.6787774562835693\n",
            "INFO:tensorflow:pgen_loss: 3.448873996734619\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11420: 0.7639262676239014\n",
            "INFO:tensorflow:pgen_loss: 3.9285988807678223\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11421: 0.7147684097290039\n",
            "INFO:tensorflow:pgen_loss: 3.605985164642334\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11422: 0.5832040309906006\n",
            "INFO:tensorflow:pgen_loss: 3.2512288093566895\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11423: 1.0237281322479248\n",
            "INFO:tensorflow:pgen_loss: 4.069952964782715\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11424: 0.8483967781066895\n",
            "INFO:tensorflow:pgen_loss: 3.456425189971924\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11425: 1.0157973766326904\n",
            "INFO:tensorflow:pgen_loss: 4.416791915893555\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11426: 1.0305156707763672\n",
            "INFO:tensorflow:pgen_loss: 3.505535840988159\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11427: 1.014866590499878\n",
            "INFO:tensorflow:pgen_loss: 3.880941867828369\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11428: 0.6920871734619141\n",
            "INFO:tensorflow:pgen_loss: 3.3619492053985596\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11429: 0.3099064826965332\n",
            "INFO:tensorflow:pgen_loss: 2.3859310150146484\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11430: 1.0461368560791016\n",
            "INFO:tensorflow:pgen_loss: 3.796313524246216\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11431: 1.006413459777832\n",
            "INFO:tensorflow:pgen_loss: 3.907770872116089\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11432: 0.2915818691253662\n",
            "INFO:tensorflow:pgen_loss: 3.4400105476379395\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11433: 0.5165350437164307\n",
            "INFO:tensorflow:pgen_loss: 3.162621021270752\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11434: 1.0230302810668945\n",
            "INFO:tensorflow:pgen_loss: 3.568152666091919\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11435: 0.9350376129150391\n",
            "INFO:tensorflow:pgen_loss: 3.8956878185272217\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11436: 0.7576510906219482\n",
            "INFO:tensorflow:pgen_loss: 3.9055728912353516\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11437: 0.7648859024047852\n",
            "INFO:tensorflow:pgen_loss: 4.244301795959473\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11438: 0.8949418067932129\n",
            "INFO:tensorflow:pgen_loss: 3.5090243816375732\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11439: 1.0122039318084717\n",
            "INFO:tensorflow:pgen_loss: 3.899996280670166\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11440: 0.40388035774230957\n",
            "INFO:tensorflow:pgen_loss: 3.302527904510498\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11441: 0.9317588806152344\n",
            "INFO:tensorflow:pgen_loss: 3.739581346511841\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11442: 0.7899453639984131\n",
            "INFO:tensorflow:pgen_loss: 4.069497108459473\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11443: 1.0052194595336914\n",
            "INFO:tensorflow:pgen_loss: 3.530277967453003\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11444: 0.6001532077789307\n",
            "INFO:tensorflow:pgen_loss: 3.569580078125\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11445: 0.887458086013794\n",
            "INFO:tensorflow:pgen_loss: 3.395198106765747\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11446: 0.9730665683746338\n",
            "INFO:tensorflow:pgen_loss: 3.241616725921631\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11447: 0.5899035930633545\n",
            "INFO:tensorflow:pgen_loss: 3.026228427886963\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11448: 1.0285568237304688\n",
            "INFO:tensorflow:pgen_loss: 3.567811965942383\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11449: 1.0090460777282715\n",
            "INFO:tensorflow:pgen_loss: 3.8267757892608643\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11450: 0.61883544921875\n",
            "INFO:tensorflow:pgen_loss: 4.280539035797119\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11451: 0.9998819828033447\n",
            "INFO:tensorflow:pgen_loss: 4.0148749351501465\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11452: 0.8272261619567871\n",
            "INFO:tensorflow:pgen_loss: 3.7052884101867676\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11453: 0.7045652866363525\n",
            "INFO:tensorflow:pgen_loss: 3.4409942626953125\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:Saving checkpoint to path drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step 11454: 1.362227201461792\n",
            "INFO:tensorflow:pgen_loss: 3.2513022422790527\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-11453.data-00000-of-00001\n",
            "INFO:tensorflow:186200\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-11453.index\n",
            "INFO:tensorflow:186200\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-11453.meta\n",
            "INFO:tensorflow:190500\n",
            "INFO:tensorflow:seconds for training step 11455: 1.5414083003997803\n",
            "INFO:tensorflow:pgen_loss: 3.209920883178711\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11456: 0.3690330982208252\n",
            "INFO:tensorflow:pgen_loss: 3.5133705139160156\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11457: 1.0228874683380127\n",
            "INFO:tensorflow:pgen_loss: 3.8128204345703125\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11458: 0.8444361686706543\n",
            "INFO:tensorflow:pgen_loss: 3.697282314300537\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11459: 1.020735502243042\n",
            "INFO:tensorflow:pgen_loss: 3.4941165447235107\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11460: 0.9091880321502686\n",
            "INFO:tensorflow:pgen_loss: 4.566591739654541\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11461: 0.9959628582000732\n",
            "INFO:tensorflow:pgen_loss: 3.776583433151245\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11462: 0.35730695724487305\n",
            "INFO:tensorflow:pgen_loss: 2.7182836532592773\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11463: 0.7093782424926758\n",
            "INFO:tensorflow:pgen_loss: 4.3797926902771\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11464: 0.6336064338684082\n",
            "INFO:tensorflow:pgen_loss: 2.9582598209381104\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11465: 0.8519809246063232\n",
            "INFO:tensorflow:pgen_loss: 3.499314069747925\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11466: 0.8095753192901611\n",
            "INFO:tensorflow:pgen_loss: 3.140010356903076\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11467: 1.258232831954956\n",
            "INFO:tensorflow:pgen_loss: 3.1201233863830566\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11468: 0.8268358707427979\n",
            "INFO:tensorflow:pgen_loss: 3.8926913738250732\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11469: 1.1067900657653809\n",
            "INFO:tensorflow:pgen_loss: 3.792102813720703\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11470: 0.5865051746368408\n",
            "INFO:tensorflow:pgen_loss: 3.2589645385742188\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11471: 0.6386876106262207\n",
            "INFO:tensorflow:pgen_loss: 3.525887966156006\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11472: 0.5760457515716553\n",
            "INFO:tensorflow:pgen_loss: 2.883366107940674\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11473: 1.0142560005187988\n",
            "INFO:tensorflow:pgen_loss: 4.0\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11474: 0.9985394477844238\n",
            "INFO:tensorflow:pgen_loss: 3.0369770526885986\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11475: 0.6090161800384521\n",
            "INFO:tensorflow:pgen_loss: 3.3627781867980957\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11476: 0.9913835525512695\n",
            "INFO:tensorflow:pgen_loss: 4.276203155517578\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11477: 0.8170754909515381\n",
            "INFO:tensorflow:pgen_loss: 3.951052188873291\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11478: 1.0039219856262207\n",
            "INFO:tensorflow:pgen_loss: 3.9678287506103516\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11479: 0.9017305374145508\n",
            "INFO:tensorflow:pgen_loss: 4.0512824058532715\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11480: 0.5715968608856201\n",
            "INFO:tensorflow:pgen_loss: 3.2794277667999268\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11481: 1.012085199356079\n",
            "INFO:tensorflow:pgen_loss: 3.7923851013183594\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11482: 0.7092380523681641\n",
            "INFO:tensorflow:pgen_loss: 3.854372024536133\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11483: 0.4609794616699219\n",
            "INFO:tensorflow:pgen_loss: 3.4480271339416504\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11484: 0.44736242294311523\n",
            "INFO:tensorflow:pgen_loss: 3.387345552444458\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11485: 1.0207743644714355\n",
            "INFO:tensorflow:pgen_loss: 3.407492160797119\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11486: 1.0144164562225342\n",
            "INFO:tensorflow:pgen_loss: 3.615248203277588\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11487: 0.7611129283905029\n",
            "INFO:tensorflow:pgen_loss: 3.5766284465789795\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11488: 0.5854306221008301\n",
            "INFO:tensorflow:pgen_loss: 4.163096904754639\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11489: 0.46959853172302246\n",
            "INFO:tensorflow:pgen_loss: 3.9803595542907715\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11490: 0.47153568267822266\n",
            "INFO:tensorflow:pgen_loss: 2.6477434635162354\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11491: 0.8043668270111084\n",
            "INFO:tensorflow:pgen_loss: 3.6452841758728027\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11492: 0.49895811080932617\n",
            "INFO:tensorflow:pgen_loss: 2.7102794647216797\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11493: 0.7926042079925537\n",
            "INFO:tensorflow:pgen_loss: 3.6794495582580566\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11494: 0.6885621547698975\n",
            "INFO:tensorflow:pgen_loss: 3.837561845779419\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11495: 0.6409831047058105\n",
            "INFO:tensorflow:pgen_loss: 3.601871967315674\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11496: 1.0216639041900635\n",
            "INFO:tensorflow:pgen_loss: 3.6313064098358154\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11497: 0.3770778179168701\n",
            "INFO:tensorflow:pgen_loss: 3.576235294342041\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11498: 1.0135648250579834\n",
            "INFO:tensorflow:pgen_loss: 3.1246349811553955\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11499: 1.0001068115234375\n",
            "INFO:tensorflow:pgen_loss: 3.701747179031372\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11500: 1.0184743404388428\n",
            "INFO:tensorflow:pgen_loss: 4.341427326202393\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11501: 0.9383671283721924\n",
            "INFO:tensorflow:pgen_loss: 3.5085384845733643\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11502: 0.9499146938323975\n",
            "INFO:tensorflow:pgen_loss: 4.004340648651123\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11503: 0.49097132682800293\n",
            "INFO:tensorflow:pgen_loss: 2.583555221557617\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11504: 0.7625210285186768\n",
            "INFO:tensorflow:pgen_loss: 3.5238215923309326\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11505: 0.5354206562042236\n",
            "INFO:tensorflow:pgen_loss: 4.015894412994385\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11506: 1.0375430583953857\n",
            "INFO:tensorflow:pgen_loss: 4.253231525421143\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11507: 0.6239888668060303\n",
            "INFO:tensorflow:pgen_loss: 4.196042060852051\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11508: 0.47705793380737305\n",
            "INFO:tensorflow:pgen_loss: 3.0119192600250244\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11509: 1.014296531677246\n",
            "INFO:tensorflow:pgen_loss: 4.357928276062012\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11510: 0.9536306858062744\n",
            "INFO:tensorflow:pgen_loss: 4.203373908996582\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11511: 0.5295464992523193\n",
            "INFO:tensorflow:pgen_loss: 4.004054069519043\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11512: 1.0091588497161865\n",
            "INFO:tensorflow:pgen_loss: 4.387631893157959\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11513: 0.4508497714996338\n",
            "INFO:tensorflow:pgen_loss: 3.072385311126709\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11514: 0.9873182773590088\n",
            "INFO:tensorflow:pgen_loss: 3.385185956954956\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11515: 0.7064387798309326\n",
            "INFO:tensorflow:pgen_loss: 4.084578514099121\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11516: 0.565166711807251\n",
            "INFO:tensorflow:pgen_loss: 3.338047742843628\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11517: 0.7249269485473633\n",
            "INFO:tensorflow:pgen_loss: 4.403029441833496\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11518: 0.8964412212371826\n",
            "INFO:tensorflow:pgen_loss: 3.906259059906006\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11519: 1.0251731872558594\n",
            "INFO:tensorflow:pgen_loss: 4.456363677978516\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11520: 0.5842576026916504\n",
            "INFO:tensorflow:pgen_loss: 3.548607587814331\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11521: 0.677807092666626\n",
            "INFO:tensorflow:pgen_loss: 3.9206111431121826\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11522: 1.0168209075927734\n",
            "INFO:tensorflow:pgen_loss: 4.202349662780762\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11523: 0.9899327754974365\n",
            "INFO:tensorflow:pgen_loss: 3.878174304962158\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11524: 0.6822512149810791\n",
            "INFO:tensorflow:pgen_loss: 3.313796281814575\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11525: 1.031797170639038\n",
            "INFO:tensorflow:pgen_loss: 3.7210044860839844\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:Saving checkpoint to path drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step 11526: 1.2999210357666016\n",
            "INFO:tensorflow:pgen_loss: 3.5824356079101562\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11527: 0.6257603168487549\n",
            "INFO:tensorflow:pgen_loss: 3.945408344268799\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-11525.data-00000-of-00001\n",
            "INFO:tensorflow:186200\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-11525.index\n",
            "INFO:tensorflow:186200\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-11525.meta\n",
            "INFO:tensorflow:190500\n",
            "INFO:tensorflow:seconds for training step 11528: 1.1304774284362793\n",
            "INFO:tensorflow:pgen_loss: 3.8748574256896973\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11529: 1.022545337677002\n",
            "INFO:tensorflow:pgen_loss: 4.71160364151001\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11530: 0.46178507804870605\n",
            "INFO:tensorflow:pgen_loss: 3.0689902305603027\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11531: 0.5700018405914307\n",
            "INFO:tensorflow:pgen_loss: 3.426042079925537\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11532: 0.8897461891174316\n",
            "INFO:tensorflow:pgen_loss: 3.4525203704833984\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11533: 1.0290873050689697\n",
            "INFO:tensorflow:pgen_loss: 4.3860321044921875\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11534: 0.7995405197143555\n",
            "INFO:tensorflow:pgen_loss: 3.6274218559265137\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11535: 0.4019160270690918\n",
            "INFO:tensorflow:pgen_loss: 3.9751980304718018\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11536: 0.5114471912384033\n",
            "INFO:tensorflow:pgen_loss: 3.3165793418884277\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11537: 0.7806427478790283\n",
            "INFO:tensorflow:pgen_loss: 3.5360875129699707\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11538: 0.8883440494537354\n",
            "INFO:tensorflow:pgen_loss: 4.131749153137207\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11539: 0.8097391128540039\n",
            "INFO:tensorflow:pgen_loss: 3.616032838821411\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11540: 0.6933631896972656\n",
            "INFO:tensorflow:pgen_loss: 3.259981870651245\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11541: 1.1928865909576416\n",
            "INFO:tensorflow:pgen_loss: 3.9181976318359375\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11542: 0.7801773548126221\n",
            "INFO:tensorflow:pgen_loss: 3.0758605003356934\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11543: 0.6715235710144043\n",
            "INFO:tensorflow:pgen_loss: 3.5761821269989014\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11544: 1.0315675735473633\n",
            "INFO:tensorflow:pgen_loss: 3.9458861351013184\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11545: 0.9435751438140869\n",
            "INFO:tensorflow:pgen_loss: 4.237549304962158\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11546: 0.30600452423095703\n",
            "INFO:tensorflow:pgen_loss: 2.7538156509399414\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11547: 0.7586090564727783\n",
            "INFO:tensorflow:pgen_loss: 3.5246384143829346\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11548: 0.8449709415435791\n",
            "INFO:tensorflow:pgen_loss: 4.556517124176025\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11549: 0.7134661674499512\n",
            "INFO:tensorflow:pgen_loss: 3.6720223426818848\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11550: 0.662989616394043\n",
            "INFO:tensorflow:pgen_loss: 3.097956657409668\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11551: 0.6034994125366211\n",
            "INFO:tensorflow:pgen_loss: 4.3826117515563965\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11552: 0.9999313354492188\n",
            "INFO:tensorflow:pgen_loss: 3.8434996604919434\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11553: 0.9914231300354004\n",
            "INFO:tensorflow:pgen_loss: 3.774937152862549\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11554: 0.752793550491333\n",
            "INFO:tensorflow:pgen_loss: 3.035949468612671\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11555: 0.986058235168457\n",
            "INFO:tensorflow:pgen_loss: 4.058501243591309\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11556: 1.0340235233306885\n",
            "INFO:tensorflow:pgen_loss: 4.010268211364746\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11557: 1.0186314582824707\n",
            "INFO:tensorflow:pgen_loss: 4.283359527587891\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11558: 1.03836989402771\n",
            "INFO:tensorflow:pgen_loss: 3.9232048988342285\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11559: 0.9678905010223389\n",
            "INFO:tensorflow:pgen_loss: 3.294686794281006\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11560: 0.9860734939575195\n",
            "INFO:tensorflow:pgen_loss: 3.642784595489502\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11561: 1.021528959274292\n",
            "INFO:tensorflow:pgen_loss: 3.363572597503662\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11562: 1.0179979801177979\n",
            "INFO:tensorflow:pgen_loss: 3.9332149028778076\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11563: 0.7774379253387451\n",
            "INFO:tensorflow:pgen_loss: 3.7493464946746826\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11564: 0.6661577224731445\n",
            "INFO:tensorflow:pgen_loss: 3.738739013671875\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11565: 1.0622029304504395\n",
            "INFO:tensorflow:pgen_loss: 3.8298802375793457\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11566: 0.4115939140319824\n",
            "INFO:tensorflow:pgen_loss: 2.863459825515747\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11567: 0.5988855361938477\n",
            "INFO:tensorflow:pgen_loss: 3.047116994857788\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11568: 1.0038881301879883\n",
            "INFO:tensorflow:pgen_loss: 3.4355483055114746\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11569: 1.0298020839691162\n",
            "INFO:tensorflow:pgen_loss: 3.7129058837890625\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11570: 0.5794637203216553\n",
            "INFO:tensorflow:pgen_loss: 3.57641863822937\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11571: 0.6677291393280029\n",
            "INFO:tensorflow:pgen_loss: 3.109022617340088\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11572: 0.8659186363220215\n",
            "INFO:tensorflow:pgen_loss: 3.961219310760498\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11573: 0.709134578704834\n",
            "INFO:tensorflow:pgen_loss: 3.1042253971099854\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11574: 0.6596724987030029\n",
            "INFO:tensorflow:pgen_loss: 3.7950053215026855\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11575: 0.7716286182403564\n",
            "INFO:tensorflow:pgen_loss: 3.572904586791992\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11576: 1.0199356079101562\n",
            "INFO:tensorflow:pgen_loss: 3.8564090728759766\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11577: 0.5880646705627441\n",
            "INFO:tensorflow:pgen_loss: 4.112441062927246\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11578: 0.5288848876953125\n",
            "INFO:tensorflow:pgen_loss: 3.2109904289245605\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11579: 0.8533408641815186\n",
            "INFO:tensorflow:pgen_loss: 3.5959067344665527\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11580: 0.7812356948852539\n",
            "INFO:tensorflow:pgen_loss: 3.4205856323242188\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11581: 0.9130053520202637\n",
            "INFO:tensorflow:pgen_loss: 2.6291122436523438\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11582: 0.7176611423492432\n",
            "INFO:tensorflow:pgen_loss: 3.788037061691284\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11583: 0.8470358848571777\n",
            "INFO:tensorflow:pgen_loss: 3.705672025680542\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11584: 0.6430222988128662\n",
            "INFO:tensorflow:pgen_loss: 3.643883466720581\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11585: 0.6568601131439209\n",
            "INFO:tensorflow:pgen_loss: 3.7082557678222656\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11586: 0.8274385929107666\n",
            "INFO:tensorflow:pgen_loss: 3.656111478805542\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11587: 0.5291495323181152\n",
            "INFO:tensorflow:pgen_loss: 3.748436450958252\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11588: 0.8196144104003906\n",
            "INFO:tensorflow:pgen_loss: 3.6957478523254395\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11589: 1.005638837814331\n",
            "INFO:tensorflow:pgen_loss: 4.2351861000061035\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11590: 0.34533143043518066\n",
            "INFO:tensorflow:pgen_loss: 3.9538726806640625\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11591: 0.9815552234649658\n",
            "INFO:tensorflow:pgen_loss: 4.447906017303467\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11592: 0.44835519790649414\n",
            "INFO:tensorflow:pgen_loss: 4.151805877685547\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11593: 0.9747624397277832\n",
            "INFO:tensorflow:pgen_loss: 4.7192606925964355\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11594: 0.43538546562194824\n",
            "INFO:tensorflow:pgen_loss: 3.6806304454803467\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11595: 0.31342196464538574\n",
            "INFO:tensorflow:pgen_loss: 2.316070795059204\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11596: 0.6316092014312744\n",
            "INFO:tensorflow:pgen_loss: 4.0920090675354\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11597: 0.9976327419281006\n",
            "INFO:tensorflow:pgen_loss: 3.702434539794922\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11598: 0.8296935558319092\n",
            "INFO:tensorflow:pgen_loss: 3.8319308757781982\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11599: 0.7680215835571289\n",
            "INFO:tensorflow:pgen_loss: 3.4435830116271973\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:Saving checkpoint to path drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step 11600: 1.7109079360961914\n",
            "INFO:tensorflow:pgen_loss: 3.6898601055145264\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-11599.data-00000-of-00001\n",
            "INFO:tensorflow:186200\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-11599.index\n",
            "INFO:tensorflow:186200\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-11599.meta\n",
            "INFO:tensorflow:190500\n",
            "INFO:tensorflow:seconds for training step 11601: 1.3672659397125244\n",
            "INFO:tensorflow:pgen_loss: 4.335537910461426\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11602: 1.0125958919525146\n",
            "INFO:tensorflow:pgen_loss: 3.11413311958313\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11603: 0.489640474319458\n",
            "INFO:tensorflow:pgen_loss: 3.7749621868133545\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11604: 1.0206525325775146\n",
            "INFO:tensorflow:pgen_loss: 4.057913303375244\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11605: 1.0268986225128174\n",
            "INFO:tensorflow:pgen_loss: 4.151080131530762\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11606: 0.6357684135437012\n",
            "INFO:tensorflow:pgen_loss: 3.9709205627441406\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11607: 0.3242506980895996\n",
            "INFO:tensorflow:pgen_loss: 2.4219138622283936\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11608: 0.7927694320678711\n",
            "INFO:tensorflow:pgen_loss: 3.7810771465301514\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11609: 0.9909842014312744\n",
            "INFO:tensorflow:pgen_loss: 3.5899620056152344\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11610: 1.002220869064331\n",
            "INFO:tensorflow:pgen_loss: 3.720745086669922\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11611: 0.7430174350738525\n",
            "INFO:tensorflow:pgen_loss: 3.110314130783081\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11612: 1.1090688705444336\n",
            "INFO:tensorflow:pgen_loss: 3.190352201461792\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11613: 1.1251468658447266\n",
            "INFO:tensorflow:pgen_loss: 3.7585577964782715\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11614: 0.48036909103393555\n",
            "INFO:tensorflow:pgen_loss: 3.2896735668182373\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11615: 0.5006105899810791\n",
            "INFO:tensorflow:pgen_loss: 2.9402480125427246\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11616: 0.6118879318237305\n",
            "INFO:tensorflow:pgen_loss: 3.7786407470703125\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11617: 0.7821691036224365\n",
            "INFO:tensorflow:pgen_loss: 3.8066983222961426\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11618: 0.9662902355194092\n",
            "INFO:tensorflow:pgen_loss: 3.687659502029419\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11619: 1.0006442070007324\n",
            "INFO:tensorflow:pgen_loss: 3.860311508178711\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11620: 0.8992702960968018\n",
            "INFO:tensorflow:pgen_loss: 2.9729342460632324\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11621: 0.6873538494110107\n",
            "INFO:tensorflow:pgen_loss: 3.4140448570251465\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11622: 0.6126112937927246\n",
            "INFO:tensorflow:pgen_loss: 2.8486480712890625\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11623: 1.000248670578003\n",
            "INFO:tensorflow:pgen_loss: 3.4492249488830566\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11624: 0.9924156665802002\n",
            "INFO:tensorflow:pgen_loss: 3.9482765197753906\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11625: 0.6448972225189209\n",
            "INFO:tensorflow:pgen_loss: 4.566475868225098\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11626: 0.6469814777374268\n",
            "INFO:tensorflow:pgen_loss: 3.3214569091796875\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11627: 0.6066911220550537\n",
            "INFO:tensorflow:pgen_loss: 3.592592716217041\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11628: 1.0097393989562988\n",
            "INFO:tensorflow:pgen_loss: 4.008158206939697\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11629: 0.6187505722045898\n",
            "INFO:tensorflow:pgen_loss: 3.6435112953186035\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11630: 1.0258240699768066\n",
            "INFO:tensorflow:pgen_loss: 3.5077831745147705\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11631: 1.0353660583496094\n",
            "INFO:tensorflow:pgen_loss: 3.3359744548797607\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11632: 1.0133156776428223\n",
            "INFO:tensorflow:pgen_loss: 3.3624157905578613\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11633: 1.0012400150299072\n",
            "INFO:tensorflow:pgen_loss: 3.9642722606658936\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11634: 0.8583321571350098\n",
            "INFO:tensorflow:pgen_loss: 3.954116106033325\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11635: 1.0357170104980469\n",
            "INFO:tensorflow:pgen_loss: 3.991119861602783\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11636: 0.9974277019500732\n",
            "INFO:tensorflow:pgen_loss: 3.829763889312744\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11637: 1.004439353942871\n",
            "INFO:tensorflow:pgen_loss: 3.2877464294433594\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11638: 1.0359678268432617\n",
            "INFO:tensorflow:pgen_loss: 4.036185264587402\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11639: 1.0087344646453857\n",
            "INFO:tensorflow:pgen_loss: 3.9452621936798096\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11640: 0.6142387390136719\n",
            "INFO:tensorflow:pgen_loss: 2.860703706741333\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11641: 0.9550375938415527\n",
            "INFO:tensorflow:pgen_loss: 3.3916099071502686\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11642: 0.7752439975738525\n",
            "INFO:tensorflow:pgen_loss: 2.8776791095733643\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11643: 0.8526067733764648\n",
            "INFO:tensorflow:pgen_loss: 3.8232409954071045\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11644: 0.5631668567657471\n",
            "INFO:tensorflow:pgen_loss: 3.092707395553589\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11645: 1.035006046295166\n",
            "INFO:tensorflow:pgen_loss: 3.6955764293670654\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11646: 0.607672929763794\n",
            "INFO:tensorflow:pgen_loss: 2.729891538619995\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11647: 0.6905713081359863\n",
            "INFO:tensorflow:pgen_loss: 3.7275478839874268\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11648: 1.004061222076416\n",
            "INFO:tensorflow:pgen_loss: 3.119992733001709\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11649: 0.464296817779541\n",
            "INFO:tensorflow:pgen_loss: 3.436126708984375\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11650: 1.0401535034179688\n",
            "INFO:tensorflow:pgen_loss: 3.8809196949005127\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11651: 0.859278678894043\n",
            "INFO:tensorflow:pgen_loss: 3.5147864818573\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11652: 0.6945810317993164\n",
            "INFO:tensorflow:pgen_loss: 3.883132219314575\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11653: 0.41584157943725586\n",
            "INFO:tensorflow:pgen_loss: 2.477013349533081\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11654: 0.7538678646087646\n",
            "INFO:tensorflow:pgen_loss: 3.2668094635009766\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11655: 1.0209383964538574\n",
            "INFO:tensorflow:pgen_loss: 4.08504581451416\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11656: 1.0405004024505615\n",
            "INFO:tensorflow:pgen_loss: 3.8064475059509277\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11657: 0.8864235877990723\n",
            "INFO:tensorflow:pgen_loss: 4.098148345947266\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11658: 1.0034081935882568\n",
            "INFO:tensorflow:pgen_loss: 3.7686569690704346\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11659: 0.6934938430786133\n",
            "INFO:tensorflow:pgen_loss: 4.06552791595459\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11660: 0.9634072780609131\n",
            "INFO:tensorflow:pgen_loss: 4.047123432159424\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11661: 0.9409768581390381\n",
            "INFO:tensorflow:pgen_loss: 4.007981300354004\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11662: 0.6366503238677979\n",
            "INFO:tensorflow:pgen_loss: 3.4949822425842285\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11663: 0.8917593955993652\n",
            "INFO:tensorflow:pgen_loss: 3.8373444080352783\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11664: 0.5238275527954102\n",
            "INFO:tensorflow:pgen_loss: 3.4044928550720215\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11665: 0.5178532600402832\n",
            "INFO:tensorflow:pgen_loss: 3.743074893951416\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11666: 0.34674572944641113\n",
            "INFO:tensorflow:pgen_loss: 2.713090181350708\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11667: 0.9797489643096924\n",
            "INFO:tensorflow:pgen_loss: 3.70863676071167\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:Saving checkpoint to path drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step 11668: 1.020998477935791\n",
            "INFO:tensorflow:pgen_loss: 4.246708869934082\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11669: 1.140343427658081\n",
            "INFO:tensorflow:pgen_loss: 3.954943895339966\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-11667.data-00000-of-00001\n",
            "INFO:tensorflow:186200\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-11667.index\n",
            "INFO:tensorflow:186200\n",
            "INFO:tensorflow:drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-11667.meta\n",
            "INFO:tensorflow:190500\n",
            "INFO:tensorflow:seconds for training step 11670: 1.047276258468628\n",
            "INFO:tensorflow:pgen_loss: 4.305037498474121\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11671: 0.9349117279052734\n",
            "INFO:tensorflow:pgen_loss: 4.205168724060059\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11672: 0.49020934104919434\n",
            "INFO:tensorflow:pgen_loss: 3.2349886894226074\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11673: 1.016855001449585\n",
            "INFO:tensorflow:pgen_loss: 3.68864369392395\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11674: 1.0136983394622803\n",
            "INFO:tensorflow:pgen_loss: 3.7469799518585205\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11675: 0.8594694137573242\n",
            "INFO:tensorflow:pgen_loss: 3.399394989013672\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11676: 1.0150270462036133\n",
            "INFO:tensorflow:pgen_loss: 3.505840301513672\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11677: 0.5906941890716553\n",
            "INFO:tensorflow:pgen_loss: 3.369947910308838\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11678: 1.0177342891693115\n",
            "INFO:tensorflow:pgen_loss: 3.5109825134277344\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11679: 0.9955589771270752\n",
            "INFO:tensorflow:pgen_loss: 3.9277007579803467\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11680: 0.9914255142211914\n",
            "INFO:tensorflow:pgen_loss: 3.15030837059021\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11681: 0.6223204135894775\n",
            "INFO:tensorflow:pgen_loss: 3.977804183959961\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11682: 0.6416897773742676\n",
            "INFO:tensorflow:pgen_loss: 2.87286114692688\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11683: 1.194706678390503\n",
            "INFO:tensorflow:pgen_loss: 3.7140228748321533\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11684: 1.0388188362121582\n",
            "INFO:tensorflow:pgen_loss: 3.7294509410858154\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11685: 0.7964541912078857\n",
            "INFO:tensorflow:pgen_loss: 3.6269097328186035\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11686: 0.8071448802947998\n",
            "INFO:tensorflow:pgen_loss: 3.7303547859191895\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11687: 0.38739514350891113\n",
            "INFO:tensorflow:pgen_loss: 3.1718430519104004\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11688: 0.2763059139251709\n",
            "INFO:tensorflow:pgen_loss: 1.7910211086273193\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11689: 1.0147459506988525\n",
            "INFO:tensorflow:pgen_loss: 3.4712555408477783\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11690: 0.7113778591156006\n",
            "INFO:tensorflow:pgen_loss: 3.385986328125\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11691: 0.5010368824005127\n",
            "INFO:tensorflow:pgen_loss: 2.6221392154693604\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11692: 0.672926664352417\n",
            "INFO:tensorflow:pgen_loss: 3.8342621326446533\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11693: 0.7852518558502197\n",
            "INFO:tensorflow:pgen_loss: 3.747391939163208\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11694: 0.8650894165039062\n",
            "INFO:tensorflow:pgen_loss: 3.88262677192688\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11695: 1.022322177886963\n",
            "INFO:tensorflow:pgen_loss: 4.191742420196533\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11696: 0.691087007522583\n",
            "INFO:tensorflow:pgen_loss: 3.6976096630096436\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11697: 0.8370721340179443\n",
            "INFO:tensorflow:pgen_loss: 3.59295916557312\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11698: 0.49734997749328613\n",
            "INFO:tensorflow:pgen_loss: 3.51151704788208\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11699: 0.4537827968597412\n",
            "INFO:tensorflow:pgen_loss: 3.4049758911132812\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11700: 0.6849400997161865\n",
            "INFO:tensorflow:pgen_loss: 3.8682243824005127\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11701: 0.6050314903259277\n",
            "INFO:tensorflow:pgen_loss: 3.485459804534912\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11702: 0.7230188846588135\n",
            "INFO:tensorflow:pgen_loss: 4.322267055511475\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11703: 0.8583695888519287\n",
            "INFO:tensorflow:pgen_loss: 4.64254903793335\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11704: 0.9937491416931152\n",
            "INFO:tensorflow:pgen_loss: 4.16224479675293\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11705: 0.898848295211792\n",
            "INFO:tensorflow:pgen_loss: 3.7669620513916016\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11706: 0.39801883697509766\n",
            "INFO:tensorflow:pgen_loss: 3.884962797164917\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11707: 0.9521501064300537\n",
            "INFO:tensorflow:pgen_loss: 3.9025707244873047\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11708: 0.7578365802764893\n",
            "INFO:tensorflow:pgen_loss: 3.5942604541778564\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11709: 0.30696558952331543\n",
            "INFO:tensorflow:pgen_loss: 2.295494794845581\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11710: 0.4654204845428467\n",
            "INFO:tensorflow:pgen_loss: 3.477773666381836\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11711: 1.0148062705993652\n",
            "INFO:tensorflow:pgen_loss: 4.213204860687256\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11712: 0.49538516998291016\n",
            "INFO:tensorflow:pgen_loss: 3.448613405227661\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11713: 1.0023081302642822\n",
            "INFO:tensorflow:pgen_loss: 3.896526336669922\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11714: 0.6813549995422363\n",
            "INFO:tensorflow:pgen_loss: 3.896535873413086\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11715: 0.4608154296875\n",
            "INFO:tensorflow:pgen_loss: 2.8653829097747803\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11716: 0.9526679515838623\n",
            "INFO:tensorflow:pgen_loss: 3.9509952068328857\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11717: 1.0462329387664795\n",
            "INFO:tensorflow:pgen_loss: 4.554420471191406\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11718: 1.0309216976165771\n",
            "INFO:tensorflow:pgen_loss: 4.350833892822266\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11719: 1.0407989025115967\n",
            "INFO:tensorflow:pgen_loss: 4.135269641876221\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11720: 0.7565383911132812\n",
            "INFO:tensorflow:pgen_loss: 3.069469928741455\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11721: 0.5353078842163086\n",
            "INFO:tensorflow:pgen_loss: 4.442104816436768\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11722: 0.7355642318725586\n",
            "INFO:tensorflow:pgen_loss: 3.938678026199341\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11723: 1.0561561584472656\n",
            "INFO:tensorflow:pgen_loss: 4.2934393882751465\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11724: 0.5162713527679443\n",
            "INFO:tensorflow:pgen_loss: 3.4828040599823\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11725: 0.7089557647705078\n",
            "INFO:tensorflow:pgen_loss: 4.252035617828369\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11726: 1.0527501106262207\n",
            "INFO:tensorflow:pgen_loss: 3.7856640815734863\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11727: 1.0363473892211914\n",
            "INFO:tensorflow:pgen_loss: 4.430387020111084\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11728: 1.0955133438110352\n",
            "INFO:tensorflow:pgen_loss: 4.430804252624512\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11729: 1.0300681591033936\n",
            "INFO:tensorflow:pgen_loss: 4.062849521636963\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11730: 0.6742978096008301\n",
            "INFO:tensorflow:pgen_loss: 3.1906449794769287\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11731: 1.0306432247161865\n",
            "INFO:tensorflow:pgen_loss: 4.494732856750488\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11732: 1.0195424556732178\n",
            "INFO:tensorflow:pgen_loss: 4.447429656982422\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11733: 0.8115324974060059\n",
            "INFO:tensorflow:pgen_loss: 4.330025672912598\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11734: 0.8032567501068115\n",
            "INFO:tensorflow:pgen_loss: 4.429136753082275\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11735: 0.7972161769866943\n",
            "INFO:tensorflow:pgen_loss: 3.6466407775878906\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11736: 0.9894862174987793\n",
            "INFO:tensorflow:pgen_loss: 3.9475371837615967\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11737: 1.004706621170044\n",
            "INFO:tensorflow:pgen_loss: 4.415040016174316\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11738: 0.4184231758117676\n",
            "INFO:tensorflow:pgen_loss: 3.5889511108398438\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:seconds for training step 11739: 1.035823106765747\n",
            "INFO:tensorflow:pgen_loss: 3.788595676422119\t\n",
            "INFO:tensorflow:-------------------------------------------\n",
            "INFO:tensorflow:add_summary\n",
            "INFO:tensorflow:Saving checkpoint to path drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step 11740: 1.5175979137420654\n",
            "INFO:tensorflow:pgen_loss: 3.839449405670166\t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### decode first 1000 train data"
      ],
      "metadata": {
        "id": "2f-XJC1JF-0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "reviews = pd.read_csv(default_path + \"train.csv\")\n",
        "reviews.shape\n",
        "reviews.isnull().sum()\n",
        "reviews = reviews.dropna()\n",
        "reviews = reviews.reset_index(drop=True)\n",
        "reviews.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gteQ29o31h0x",
        "outputId": "747c914a-b1f7-45be-fb07-831096cd0e02"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            headline  \\\n",
              "0  EXCLUSIVE: दिल्ली में डीजल टैक्सियों पर बैन से...   \n",
              "1  जॉर्डन: राष्ट्रपति मुखर्जी ने 86 करोड़ डॉलर के...   \n",
              "2  UN में पाकिस्तान की राजदूत मलीहा लोधी ने कराई ...   \n",
              "3  38 देशों में पीएम नरेंद्र मोदी बायोपिक को रिली...   \n",
              "4           13 अगस्त 2011: दिनभर की बड़ी खबरें पढ़ें   \n",
              "\n",
              "                                             article  \n",
              "0  दिल्ली में सुप्रीम कोर्ट के डीज़ल टैक्सियों को...  \n",
              "1  जॉर्डन के ऐतिहासिक दौरे पर पहुंचे राष्ट्रपति प...  \n",
              "2  पाकिस्तानी नेताओं को विवादित और हास्यास्पद बया...  \n",
              "3  पीएम नरेंद्र मोदी बायोपिक में विवेक ओबेरॉय ने ...  \n",
              "4  देश, दुनिया, महानगर, खेल, आर्थिक और बॉलीवुड मे...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c16a7633-d453-4b84-9403-5563997aef37\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>article</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>EXCLUSIVE: दिल्ली में डीजल टैक्सियों पर बैन से...</td>\n",
              "      <td>दिल्ली में सुप्रीम कोर्ट के डीज़ल टैक्सियों को...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>जॉर्डन: राष्ट्रपति मुखर्जी ने 86 करोड़ डॉलर के...</td>\n",
              "      <td>जॉर्डन के ऐतिहासिक दौरे पर पहुंचे राष्ट्रपति प...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>UN में पाकिस्तान की राजदूत मलीहा लोधी ने कराई ...</td>\n",
              "      <td>पाकिस्तानी नेताओं को विवादित और हास्यास्पद बया...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>38 देशों में पीएम नरेंद्र मोदी बायोपिक को रिली...</td>\n",
              "      <td>पीएम नरेंद्र मोदी बायोपिक में विवेक ओबेरॉय ने ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13 अगस्त 2011: दिनभर की बड़ी खबरें पढ़ें</td>\n",
              "      <td>देश, दुनिया, महानगर, खेल, आर्थिक और बॉलीवुड मे...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c16a7633-d453-4b84-9403-5563997aef37')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c16a7633-d453-4b84-9403-5563997aef37 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c16a7633-d453-4b84-9403-5563997aef37');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()"
      ],
      "metadata": {
        "id": "j7hQTaJA1k4X"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class flags_:\n",
        "  pass\n",
        "FLAGS = flags_()\n",
        "\n",
        "article = []\n",
        "reference = []\n",
        "summary = []\n",
        "\n",
        "default_path = \"drive/My Drive/hindi_dataset/\"\n",
        "data_path = \"drive/My Drive/Colab Notebooks/Model 4_5/arabic_finished_files_200k_correct/\" #not used\n",
        "\n",
        "# Where to find data\n",
        "FLAGS.data_path = data_path + 'chunked/train_*' #not used\n",
        "FLAGS.vocab_path = default_path + 'pickles/vocab'\n",
        "\n",
        "# Important settings\n",
        "FLAGS.mode = 'decode' \n",
        "FLAGS.single_pass = True  #true --> decode      false--> train\n",
        "FLAGS.decode_after = 0\n",
        "FLAGS.decode_from = 'train'\n",
        "\n",
        "if FLAGS.mode =='train':\n",
        "  FLAGS.csv = reviews[1000:] #train\n",
        "elif FLAGS.mode =='decode':\n",
        "  FLAGS.csv = reviews[:1000] #test #reviews[-1000:] #test\n",
        "  \n",
        "# Where to save output\n",
        "FLAGS.log_root = default_path +'logs_6_12'  \n",
        "FLAGS.exp_name = 'scheduled-sampling-hardargmax-greedy'\n",
        "\n",
        "# batcher parameter#, for consistent results#, set all these parameters to 1\n",
        "FLAGS.example_queue_threads = 4\n",
        "FLAGS.batch_queue_threads   = 2\n",
        "FLAGS.bucketing_cache_size  = 100\n",
        "\n",
        "# Hyperparameters\n",
        "\n",
        "FLAGS.enc_hidden_dim= 256##, 'dimension of RNN hidden states')\n",
        "FLAGS.dec_hidden_dim= 256##, 'dimension of RNN hidden states')\n",
        "FLAGS.emb_dim= 150 # 'dimension of word embeddings')\n",
        "FLAGS.batch_size=20# , 'minibatch size')\n",
        "FLAGS.max_enc_steps= 400 #100#, 'max timesteps of encoder (max source text tokens)')\n",
        "FLAGS.max_dec_steps= 15 #20#, 'max timesteps of decoder (max summary tokens)')\n",
        "FLAGS.beam_size= 35##, 'beam size for beam search decoding.')\n",
        "FLAGS.min_dec_steps= 20 #20##, 'Minimum sequence length of generated summary. Applies only for beam search decoding mode')\n",
        "FLAGS.max_iter= 20000  #40000##, 'max number of iterations')\n",
        "FLAGS.vocab_size= 50000##, 'Size of vocabulary. These will be read from the vocabulary file in order. If the vocabulary file contains fewer words than this number#, or if this number is set to 0#, will take all words in the vocabulary file.')\n",
        "FLAGS.lr= 0.15##, 'learning rate')\n",
        "FLAGS.adagrad_init_acc= 0.1##, 'initial accumulator value for Adagrad')\n",
        "FLAGS.rand_unif_init_mag= 0.02##, 'magnitude for lstm cells random uniform inititalization')\n",
        "FLAGS.trunc_norm_init_std= 1e-4##, 'std of trunc norm init#, used for initializing everything else')\n",
        "FLAGS.max_grad_norm= 5.0##, 'for gradient clipping')\n",
        "FLAGS.embedding= default_path +\"model_hindi.model\" #False#None##, 'path to the pre-trained embedding file')\n",
        "FLAGS.gpu_num= 0##, 'which gpu to use to train the model')\n",
        "\n",
        "# Pointer-generator or baseline model\n",
        "FLAGS.pointer_gen= True##, 'If True#, use pointer-generator model. If False#, use baseline model.')\n",
        "FLAGS.avoid_trigrams= True##, 'Avoids trigram during decoding')\n",
        "FLAGS.share_decoder_weights= False##, 'Share output matrix projection with word embedding') # Eq 13. in https://arxiv.org/pdf/1705.04304.pdf\n",
        "\n",
        "# Pointer-generator with Self-Critic policy gradient: https://arxiv.org/pdf/1705.04304.pdf\n",
        "FLAGS.rl_training= False #True#, 'Use policy-gradient training by collecting rewards at the end of sequence.')\n",
        "FLAGS.self_critic= True#, 'Uses greedy sentence reward as baseline.')\n",
        "FLAGS.use_discounted_rewards= False#, 'Whether to use discounted rewards.')\n",
        "FLAGS.use_intermediate_rewards= False#, 'Whether to use intermediate rewards.')\n",
        "FLAGS.convert_to_reinforce_model= False #True#, 'Convert a pointer model to a reinforce model. Turn this on and run in train mode.\n",
        "#Your current training model will be copied to a new version (same name with _cov_init appended) \n",
        "#that will be ready to run with coverage flag turned on#, for the coverage training stage.')\n",
        "FLAGS.intradecoder= True#, #%# 'Use intradecoder attention or not')\n",
        "FLAGS.use_temporal_attention=  True# #%#, 'Whether to use temporal attention or not')\n",
        "FLAGS.matrix_attention= False#, 'Use matrix attention#, Eq. 2 https://arxiv.org/pdf/1705.04304.pdf')\n",
        "FLAGS.eta= 2.5E-05#, 'RL/MLE scaling factor#, 1 means use RL loss#, 0 means use MLE loss')\n",
        "FLAGS.fixed_eta= False#, 'Use fixed value for eta or adaptive based on global step')\n",
        "FLAGS.gamma= 0.99#, 'discount factor')\n",
        "FLAGS.reward_function= 'rouge_l/f_score'#, 'either bleu or one of the rouge measures (rouge_1/f_score#,rouge_2/f_score#,rouge_l/f_score)')\n",
        "\n",
        "# parameters of DDQN model\n",
        "FLAGS.ac_training= False#, 'Use Actor-Critic learning by DDQN.')\n",
        "FLAGS.dqn_scheduled_sampling= True #, 'Whether to use scheduled sampling to use estimates of dqn model vs the actual q-estimates values')\n",
        "FLAGS.dqn_layers= '512,256,128'#, 'DQN dense hidden layer size#, will create three dense layers with 512#, 256#, and 128 size')\n",
        "FLAGS.dqn_replay_buffer_size= 100000#, 'Size of the replay buffer')\n",
        "FLAGS.dqn_batch_size= 100#, 'Batch size for training the DDQN model')\n",
        "FLAGS.dqn_target_update= 10000#, 'Update target Q network every 10000 steps')\n",
        "FLAGS.dqn_sleep_time= 2#, 'Train DDQN model every 2 seconds')\n",
        "FLAGS.dqn_gpu_num= 0#, 'GPU number to train the DDQN')\n",
        "FLAGS.dueling_net= True#, 'Whether to use Duelling Network to train the model') # https://arxiv.org/pdf/1511.06581.pdf\n",
        "FLAGS.dqn_polyak_averaging= True#, 'Whether to use polyak averaging to update the target network parameters')\n",
        "FLAGS.calculate_true_q= False#, \"Whether to use true Q-values to train DQN or use DQN's estimates to train it\")\n",
        "FLAGS.dqn_pretrain= False#, \"Pretrain the DDQN network with fixed Actor model\")\n",
        "FLAGS.dqn_pretrain_steps= 10000#, 'Number of steps to pre-train the DDQN')\n",
        "\n",
        "#scheduled sampling parameters#, https://arxiv.org/pdf/1506.03099.pdf\n",
        "# At each time step t and for each sequence in the batch#, we get the input to next decoding step by either\n",
        "#   (1) sampling from the final distribution at (t-1)#, or\n",
        "#   (2) reading from input_decoder_embedding.\n",
        "# We do (1) with probability sampling_probability and (2) with 1 - sampling_probability.\n",
        "# Using sampling_probability=0.0 is equivalent to using only the ground truth data (no sampling).\n",
        "# Using sampling_probability=1.0 is equivalent to doing inference by only relying on the sampled token generated at each decoding step\n",
        "FLAGS.scheduled_sampling= True#, 'whether to do scheduled sampling or not')\n",
        "FLAGS.decay_function= 'linear'#,'linear#, exponential#, inv_sigmoid') #### TODO: implement this\n",
        "FLAGS.sampling_probability= 2.5E-05#, 'epsilon value for choosing ground-truth or model output')\n",
        "FLAGS.fixed_sampling_probability= False#, 'Whether to use fixed sampling probability or adaptive based on global step')\n",
        "FLAGS.hard_argmax= True#, 'Whether to use soft argmax or hard argmax')\n",
        "FLAGS.greedy_scheduled_sampling= True#, 'Whether to use greedy approach or sample for the output#, if True it uses greedy')\n",
        "FLAGS.E2EBackProp= False#, 'Whether to use E2EBackProp algorithm to solve exposure bias')\n",
        "FLAGS.alpha= 1#, 'soft argmax argument')\n",
        "FLAGS.k= 1#, 'number of samples')\n",
        "FLAGS.scheduled_sampling_final_dist= True#, 'Whether to use final distribution or vocab distribution for scheduled sampling')\n",
        "\n",
        "# Coverage hyperparameters\n",
        "FLAGS.coverage= False#, 'Use coverage mechanism. Note#, the experiments reported in the ACL paper train WITHOUT coverage until converged#, and then train for a short phase WITH coveragFLAGS.e afterwards. i.e. to reproduce the results in the ACL paper#, turn this off for most of training then turn on for a short phase at the end.')\n",
        "FLAGS.cov_loss_wt= 1.0#, 'Weight of coverage loss (lambda in the paper). If zero#, then no incentive to minimize coverage loss.')\n",
        "\n",
        "# Utility flags#, for restoring and changing checkpoints\n",
        "FLAGS.convert_to_coverage_model= False#, 'Convert a non-coverage model to a coverage model. Turn this on and run in train mode. Your current training model will be copied to a new version (same name with _cov_init appended) that will be ready to run with coverage flag turned on#, for the coverage training stage.')\n",
        "FLAGS.restore_best_model= False#, 'Restore the best model in the eval/ dir and save it in the train/ dir#, ready to be used for further training. Useful for early stopping#, or if your training checkpoint has become corrupted with e.g. NaN values.')\n",
        "\n",
        "# Debugging. See https://www.tensorflow.org/programmers_guide/debugger\n",
        "FLAGS.debug= False#, \"Run in tensorflow's debug mode (watches for NaN/inf values)\")"
      ],
      "metadata": {
        "id": "iRg85pknFvpv"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq2seq = Seq2Seq()\n",
        "seq2seq.main()"
      ],
      "metadata": {
        "id": "B-IHajyUZ6MM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0lmntKo1p1W"
      },
      "source": [
        "zaksum(article,reference ,summary ,\"drive/My Drive/hindi_dataset/result_Hindi_CL_Scheduled Sampling_7_12_2019_8_27Am.xml\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### rouge scores"
      ],
      "metadata": {
        "id": "4Eci3D8v1r3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "path_ = \"drive/My Drive/hindi_dataset/logs_6_12/decode_train_train_400maxenc_35beam_20mindec_15maxdec_train-ckpt-11739/reference/\";\n",
        "directory = os.fsencode(path_)\n",
        "print(directory)\n",
        "refe_list = []\n",
        "for file_ in os.listdir(directory):\n",
        "  filename = os.fsdecode(file_)\n",
        "  print(filename)\n",
        "  with open(path_+filename, 'r') as file__:\n",
        "    data = file__.read().replace('\\n', '')\n",
        "    refe_list.append(data)\n",
        "\n",
        "path_ = \"drive/My Drive/hindi_dataset/logs_6_12/decode_train_train_400maxenc_35beam_20mindec_15maxdec_train-ckpt-11739/decoded/\";\n",
        "directory = os.fsencode(path_)\n",
        "decode_list = []\n",
        "for file_ in os.listdir(directory):\n",
        "  filename = os.fsdecode(file_)\n",
        "  with open(path_+filename, 'r') as file__:\n",
        "    data = file__.read().replace('\\n', '')\n",
        "    decode_list.append(data)"
      ],
      "metadata": {
        "id": "oBqqH-Oo3DgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(refe_list[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FYpw4lS5fpF",
        "outputId": "4bae7c94-aef1-4c66-e42e-e7c571b7389e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['EXCLUSIVE: दिल्ली में डीजल टैक्सियों पर बैन से मुश्किल में पड़ा चुनाव आयोग', 'जॉर्डन: राष्ट्रपति मुखर्जी ने 86 करोड़ डॉलर के संयंत्र का उद्घाटन किया', 'UN में पाकिस्तान की राजदूत मलीहा लोधी ने कराई फजीहत, मांगनी पड़ी माफी', '38 देशों में पीएम नरेंद्र मोदी बायोपिक को रिलीज करने का है प्लान', '13 अगस्त 2011: दिनभर की बड़ी खबरें पढ़ें']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode_list[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwyzMX8V5m5S",
        "outputId": "1d08bc21-dcd1-47a7-ef76-9d23395bad53"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['दिल्ली चुनाव से पहले दो हफ्ते का भी वक्त नहीं बचा रहे हैं राकेश मेहता', 'जॉर्डन के दौरे पर पहुंचे प्रणब मुखर्जी ने 86 करोड़ डॉलर की लागत का अनुमान', 'संयुक्त राष्ट्र में पाकिस्तान के मंत्री ने ब्रिटिश विदेश मंत्री ट्वीट की माफी का नाम', '38 देशों में रिलीज हो सकती है विवेक ओबेरॉय ने निभाया नरेंद्र मोदी का किरदार', 'पढ़ें 15 अक्टूबर से पढ़ें पढ़ें दिनभर की बड़ी खबरों की बड़ी खबरें एक साथ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge import Rouge\n",
        "\n",
        "r=Rouge()\n",
        "r_scores = r.get_scores(decode_list, refe_list, avg=True)\n",
        "#pprint.pprint(r_scores)\n",
        "print(\"ROGUE-1:\", r_scores[\"rouge-1\"][\"f\"])\n",
        "print(\"ROGUE-2:\", r_scores[\"rouge-2\"][\"f\"])\n",
        "print(\"ROGUE-l:\", r_scores[\"rouge-l\"][\"f\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjX_vqHumT3r",
        "outputId": "66edc9b2-6582-4b7a-b60e-26fb4798b840"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROGUE-1: 0.30646102049182294\n",
            "ROGUE-2: 0.1097163083974107\n",
            "ROGUE-l: 0.2666604184373109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PJ8aQ40L2cXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### decode first 100 test data\n",
        "\n"
      ],
      "metadata": {
        "id": "-1QqzygJ2cxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "reviews = pd.read_csv(default_path + \"test.csv\")\n",
        "reviews.shape\n",
        "reviews.isnull().sum()\n",
        "reviews = reviews.dropna()\n",
        "reviews = reviews.reset_index(drop=True)\n",
        "reviews.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "595fc466-2865-49c2-e82e-d51ffdf777ed",
        "id": "g7kBkwOL2cxz"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            headline  \\\n",
              "0  पठानकोट पहुंचे PM मोदी, एयरबेस का जायजा ले बॉर...   \n",
              "1  सचिन ने देशवासियों को समर्पित किया अपना दोहरा शतक   \n",
              "2  एनआईए करेगी छत्तीसगढ़ में सुरक्षा खामियों की ज...   \n",
              "3  सीधी बात:  शाह बोले- हमारा बस चलता तो अब तक मं...   \n",
              "4  ऋषभ पंत के पास यूनिक टैलेंट, उसके साथ छेड़छाड़ न...   \n",
              "\n",
              "                                             article  \n",
              "0  प्रधानमंत्री नरेंद्र मोदी पठानकोट एयरबेस पहुंच...  \n",
              "1  सचिन तेंदुलकर ने एकदिवसीय अंतरराष्ट्रीय क्रिके...  \n",
              "2  केंद्रीय गृह राज्य मंत्री आर. पी. एन. सिंह ने ...  \n",
              "3  भारतीय जनता पार्टी (बीजेपी) के राष्ट्रीय अध्यक...  \n",
              "4  ऋषभ पंत की कभी कभार इस बात के लिए आलोचना की जा...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06a71385-723d-4026-b9c5-3f08ce34d893\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>article</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>पठानकोट पहुंचे PM मोदी, एयरबेस का जायजा ले बॉर...</td>\n",
              "      <td>प्रधानमंत्री नरेंद्र मोदी पठानकोट एयरबेस पहुंच...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>सचिन ने देशवासियों को समर्पित किया अपना दोहरा शतक</td>\n",
              "      <td>सचिन तेंदुलकर ने एकदिवसीय अंतरराष्ट्रीय क्रिके...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>एनआईए करेगी छत्तीसगढ़ में सुरक्षा खामियों की ज...</td>\n",
              "      <td>केंद्रीय गृह राज्य मंत्री आर. पी. एन. सिंह ने ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>सीधी बात:  शाह बोले- हमारा बस चलता तो अब तक मं...</td>\n",
              "      <td>भारतीय जनता पार्टी (बीजेपी) के राष्ट्रीय अध्यक...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ऋषभ पंत के पास यूनिक टैलेंट, उसके साथ छेड़छाड़ न...</td>\n",
              "      <td>ऋषभ पंत की कभी कभार इस बात के लिए आलोचना की जा...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06a71385-723d-4026-b9c5-3f08ce34d893')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-06a71385-723d-4026-b9c5-3f08ce34d893 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-06a71385-723d-4026-b9c5-3f08ce34d893');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()"
      ],
      "metadata": {
        "id": "7b0xkpA42cx0"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class flags_:\n",
        "  pass\n",
        "FLAGS = flags_()\n",
        "\n",
        "article = []\n",
        "reference = []\n",
        "summary = []\n",
        "\n",
        "default_path = \"drive/My Drive/hindi_dataset/\"\n",
        "data_path = \"drive/My Drive/Colab Notebooks/Model 4_5/arabic_finished_files_200k_correct/\" #not used\n",
        "\n",
        "# Where to find data\n",
        "FLAGS.data_path = data_path + 'chunked/train_*' #not used\n",
        "FLAGS.vocab_path = default_path + 'pickles/vocab'\n",
        "\n",
        "# Important settings\n",
        "FLAGS.mode = 'decode' \n",
        "FLAGS.single_pass = True  #true --> decode      false--> train\n",
        "FLAGS.decode_after = 0\n",
        "FLAGS.decode_from = 'train'\n",
        "\n",
        "if FLAGS.mode =='train':\n",
        "  FLAGS.csv = reviews[1000:] #train\n",
        "elif FLAGS.mode =='decode':\n",
        "  FLAGS.csv = reviews[:1000] #test #reviews[-1000:] #test\n",
        "  \n",
        "# Where to save output\n",
        "FLAGS.log_root = default_path +'logs_6_12'  \n",
        "FLAGS.exp_name = 'scheduled-sampling-hardargmax-greedy'\n",
        "\n",
        "# batcher parameter#, for consistent results#, set all these parameters to 1\n",
        "FLAGS.example_queue_threads = 4\n",
        "FLAGS.batch_queue_threads   = 2\n",
        "FLAGS.bucketing_cache_size  = 100\n",
        "\n",
        "# Hyperparameters\n",
        "\n",
        "FLAGS.enc_hidden_dim= 256##, 'dimension of RNN hidden states')\n",
        "FLAGS.dec_hidden_dim= 256##, 'dimension of RNN hidden states')\n",
        "FLAGS.emb_dim= 150 # 'dimension of word embeddings')\n",
        "FLAGS.batch_size=20# , 'minibatch size')\n",
        "FLAGS.max_enc_steps= 400 #100#, 'max timesteps of encoder (max source text tokens)')\n",
        "FLAGS.max_dec_steps= 15 #20#, 'max timesteps of decoder (max summary tokens)')\n",
        "FLAGS.beam_size= 35##, 'beam size for beam search decoding.')\n",
        "FLAGS.min_dec_steps= 20 #20##, 'Minimum sequence length of generated summary. Applies only for beam search decoding mode')\n",
        "FLAGS.max_iter= 20000  #40000##, 'max number of iterations')\n",
        "FLAGS.vocab_size= 50000##, 'Size of vocabulary. These will be read from the vocabulary file in order. If the vocabulary file contains fewer words than this number#, or if this number is set to 0#, will take all words in the vocabulary file.')\n",
        "FLAGS.lr= 0.15##, 'learning rate')\n",
        "FLAGS.adagrad_init_acc= 0.1##, 'initial accumulator value for Adagrad')\n",
        "FLAGS.rand_unif_init_mag= 0.02##, 'magnitude for lstm cells random uniform inititalization')\n",
        "FLAGS.trunc_norm_init_std= 1e-4##, 'std of trunc norm init#, used for initializing everything else')\n",
        "FLAGS.max_grad_norm= 5.0##, 'for gradient clipping')\n",
        "FLAGS.embedding= default_path +\"model_hindi.model\" #False#None##, 'path to the pre-trained embedding file')\n",
        "FLAGS.gpu_num= 0##, 'which gpu to use to train the model')\n",
        "\n",
        "# Pointer-generator or baseline model\n",
        "FLAGS.pointer_gen= True##, 'If True#, use pointer-generator model. If False#, use baseline model.')\n",
        "FLAGS.avoid_trigrams= True##, 'Avoids trigram during decoding')\n",
        "FLAGS.share_decoder_weights= False##, 'Share output matrix projection with word embedding') # Eq 13. in https://arxiv.org/pdf/1705.04304.pdf\n",
        "\n",
        "# Pointer-generator with Self-Critic policy gradient: https://arxiv.org/pdf/1705.04304.pdf\n",
        "FLAGS.rl_training= False #True#, 'Use policy-gradient training by collecting rewards at the end of sequence.')\n",
        "FLAGS.self_critic= True#, 'Uses greedy sentence reward as baseline.')\n",
        "FLAGS.use_discounted_rewards= False#, 'Whether to use discounted rewards.')\n",
        "FLAGS.use_intermediate_rewards= False#, 'Whether to use intermediate rewards.')\n",
        "FLAGS.convert_to_reinforce_model= False #True#, 'Convert a pointer model to a reinforce model. Turn this on and run in train mode.\n",
        "#Your current training model will be copied to a new version (same name with _cov_init appended) \n",
        "#that will be ready to run with coverage flag turned on#, for the coverage training stage.')\n",
        "FLAGS.intradecoder= True#, #%# 'Use intradecoder attention or not')\n",
        "FLAGS.use_temporal_attention=  True# #%#, 'Whether to use temporal attention or not')\n",
        "FLAGS.matrix_attention= False#, 'Use matrix attention#, Eq. 2 https://arxiv.org/pdf/1705.04304.pdf')\n",
        "FLAGS.eta= 2.5E-05#, 'RL/MLE scaling factor#, 1 means use RL loss#, 0 means use MLE loss')\n",
        "FLAGS.fixed_eta= False#, 'Use fixed value for eta or adaptive based on global step')\n",
        "FLAGS.gamma= 0.99#, 'discount factor')\n",
        "FLAGS.reward_function= 'rouge_l/f_score'#, 'either bleu or one of the rouge measures (rouge_1/f_score#,rouge_2/f_score#,rouge_l/f_score)')\n",
        "\n",
        "# parameters of DDQN model\n",
        "FLAGS.ac_training= False#, 'Use Actor-Critic learning by DDQN.')\n",
        "FLAGS.dqn_scheduled_sampling= True #, 'Whether to use scheduled sampling to use estimates of dqn model vs the actual q-estimates values')\n",
        "FLAGS.dqn_layers= '512,256,128'#, 'DQN dense hidden layer size#, will create three dense layers with 512#, 256#, and 128 size')\n",
        "FLAGS.dqn_replay_buffer_size= 100000#, 'Size of the replay buffer')\n",
        "FLAGS.dqn_batch_size= 100#, 'Batch size for training the DDQN model')\n",
        "FLAGS.dqn_target_update= 10000#, 'Update target Q network every 10000 steps')\n",
        "FLAGS.dqn_sleep_time= 2#, 'Train DDQN model every 2 seconds')\n",
        "FLAGS.dqn_gpu_num= 0#, 'GPU number to train the DDQN')\n",
        "FLAGS.dueling_net= True#, 'Whether to use Duelling Network to train the model') # https://arxiv.org/pdf/1511.06581.pdf\n",
        "FLAGS.dqn_polyak_averaging= True#, 'Whether to use polyak averaging to update the target network parameters')\n",
        "FLAGS.calculate_true_q= False#, \"Whether to use true Q-values to train DQN or use DQN's estimates to train it\")\n",
        "FLAGS.dqn_pretrain= False#, \"Pretrain the DDQN network with fixed Actor model\")\n",
        "FLAGS.dqn_pretrain_steps= 10000#, 'Number of steps to pre-train the DDQN')\n",
        "\n",
        "#scheduled sampling parameters#, https://arxiv.org/pdf/1506.03099.pdf\n",
        "# At each time step t and for each sequence in the batch#, we get the input to next decoding step by either\n",
        "#   (1) sampling from the final distribution at (t-1)#, or\n",
        "#   (2) reading from input_decoder_embedding.\n",
        "# We do (1) with probability sampling_probability and (2) with 1 - sampling_probability.\n",
        "# Using sampling_probability=0.0 is equivalent to using only the ground truth data (no sampling).\n",
        "# Using sampling_probability=1.0 is equivalent to doing inference by only relying on the sampled token generated at each decoding step\n",
        "FLAGS.scheduled_sampling= True#, 'whether to do scheduled sampling or not')\n",
        "FLAGS.decay_function= 'linear'#,'linear#, exponential#, inv_sigmoid') #### TODO: implement this\n",
        "FLAGS.sampling_probability= 2.5E-05#, 'epsilon value for choosing ground-truth or model output')\n",
        "FLAGS.fixed_sampling_probability= False#, 'Whether to use fixed sampling probability or adaptive based on global step')\n",
        "FLAGS.hard_argmax= True#, 'Whether to use soft argmax or hard argmax')\n",
        "FLAGS.greedy_scheduled_sampling= True#, 'Whether to use greedy approach or sample for the output#, if True it uses greedy')\n",
        "FLAGS.E2EBackProp= False#, 'Whether to use E2EBackProp algorithm to solve exposure bias')\n",
        "FLAGS.alpha= 1#, 'soft argmax argument')\n",
        "FLAGS.k= 1#, 'number of samples')\n",
        "FLAGS.scheduled_sampling_final_dist= True#, 'Whether to use final distribution or vocab distribution for scheduled sampling')\n",
        "\n",
        "# Coverage hyperparameters\n",
        "FLAGS.coverage= False#, 'Use coverage mechanism. Note#, the experiments reported in the ACL paper train WITHOUT coverage until converged#, and then train for a short phase WITH coveragFLAGS.e afterwards. i.e. to reproduce the results in the ACL paper#, turn this off for most of training then turn on for a short phase at the end.')\n",
        "FLAGS.cov_loss_wt= 1.0#, 'Weight of coverage loss (lambda in the paper). If zero#, then no incentive to minimize coverage loss.')\n",
        "\n",
        "# Utility flags#, for restoring and changing checkpoints\n",
        "FLAGS.convert_to_coverage_model= False#, 'Convert a non-coverage model to a coverage model. Turn this on and run in train mode. Your current training model will be copied to a new version (same name with _cov_init appended) that will be ready to run with coverage flag turned on#, for the coverage training stage.')\n",
        "FLAGS.restore_best_model= False#, 'Restore the best model in the eval/ dir and save it in the train/ dir#, ready to be used for further training. Useful for early stopping#, or if your training checkpoint has become corrupted with e.g. NaN values.')\n",
        "\n",
        "# Debugging. See https://www.tensorflow.org/programmers_guide/debugger\n",
        "FLAGS.debug= False#, \"Run in tensorflow's debug mode (watches for NaN/inf values)\")"
      ],
      "metadata": {
        "id": "_cGDb2Ds2cx0"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq2seq = Seq2Seq()\n",
        "seq2seq.main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f073fc42-6d19-435d-e578-fcb734583b2c",
        "id": "HjkdzPWX2cx0"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Starting seq2seq_attention in decode mode...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duplicate: a\n",
            "Duplicate: the\n",
            "Duplicate: we\n",
            "Duplicate: it\n",
            "Duplicate: up\n",
            "Duplicate: this\n",
            "Duplicate: am\n",
            "Duplicate: my\n",
            "Duplicate: he\n",
            "Duplicate: day\n",
            "Duplicate: police\n",
            "Duplicate: no\n",
            "Duplicate: party\n",
            "Duplicate: new\n",
            "Duplicate: you\n",
            "Duplicate: to\n",
            "Duplicate: one\n",
            "Duplicate: us\n",
            "Duplicate: in\n",
            "Duplicate: and\n",
            "Duplicate: all\n",
            "Duplicate: world\n",
            "Duplicate: what\n",
            "Duplicate: live\n",
            "Duplicate: for\n",
            "Duplicate: happy\n",
            "Duplicate: watch\n",
            "Duplicate: so\n",
            "Duplicate: if\n",
            "Duplicate: love\n",
            "Duplicate: s\n",
            "Duplicate: govt\n",
            "Duplicate: m\n",
            "Duplicate: i\n",
            "Duplicate: update\n",
            "Duplicate: there\n",
            "Duplicate: they\n",
            "Duplicate: beingsalmankhan\n",
            "Duplicate: here\n",
            "Duplicate: when\n",
            "Duplicate: office\n",
            "Duplicate: she\n",
            "Duplicate: today\n",
            "Duplicate: on\n",
            "Duplicate: more\n",
            "Duplicate: thank\n",
            "Duplicate: fire\n",
            "Duplicate: t\n",
            "Duplicate: our\n",
            "Duplicate: but\n",
            "Duplicate: will\n",
            "Duplicate: bollywood\n",
            "Duplicate: watch\n",
            "Duplicate: now\n",
            "Duplicate: it\n",
            "Duplicate: home\n",
            "Duplicate: as\n",
            "Duplicate: b\n",
            "Duplicate: pm\n",
            "Duplicate: state\n",
            "Duplicate: is\n",
            "Duplicate: how\n",
            "Duplicate: u\n",
            "Duplicate: team\n",
            "Duplicate: cricket\n",
            "Duplicate: pak\n",
            "Duplicate: go\n",
            "Duplicate: first\n",
            "Duplicate: court\n",
            "Duplicate: with\n",
            "Duplicate: people\n",
            "Duplicate: do\n",
            "Duplicate: just\n",
            "Duplicate: that\n",
            "Duplicate: ji\n",
            "Duplicate: house\n",
            "Duplicate: charges\n",
            "Duplicate: d\n",
            "Duplicate: an\n",
            "Duplicate: government\n",
            "Duplicate: video\n",
            "Duplicate: two\n",
            "Duplicate: birthday\n",
            "Duplicate: live\n",
            "Duplicate: former\n",
            "Duplicate: r\n",
            "Duplicate: sir\n",
            "Duplicate: let\n",
            "Duplicate: why\n",
            "Duplicate: singh\n",
            "Duplicate: his\n",
            "Duplicate: may\n",
            "Duplicate: road\n",
            "Duplicate: result\n",
            "Duplicate: video\n",
            "Duplicate: n\n",
            "Duplicate: is\n",
            "Duplicate: at\n",
            "Duplicate: security\n",
            "Duplicate: women\n",
            "Duplicate: of\n",
            "Duplicate: national\n",
            "Duplicate: best\n",
            "Duplicate: election\n",
            "Duplicate: vs\n",
            "Duplicate: please\n",
            "Duplicate: film\n",
            "Duplicate: not\n",
            "Duplicate: style\n",
            "Duplicate: after\n",
            "Duplicate: news\n",
            "Duplicate: high\n",
            "Duplicate: special\n",
            "Duplicate: have\n",
            "Duplicate: c\n",
            "Duplicate: visuals\n",
            "Duplicate: hospital\n",
            "Duplicate: good\n",
            "Duplicate: your\n",
            "Duplicate: week\n",
            "Duplicate: main\n",
            "Duplicate: play\n",
            "Duplicate: times\n",
            "Duplicate: total\n",
            "Duplicate: results\n",
            "Duplicate: chief\n",
            "Duplicate: trailer\n",
            "Duplicate: from\n",
            "Duplicate: link\n",
            "Duplicate: list\n",
            "Duplicate: year\n",
            "Duplicate: assembly\n",
            "Duplicate: salmankhan\n",
            "Duplicate: can\n",
            "Duplicate: power\n",
            "Duplicate: rs\n",
            "Duplicate: follow\n",
            "Duplicate: file\n",
            "Duplicate: india\n",
            "Duplicate: strong\n",
            "Duplicate: airport\n",
            "Duplicate: test\n",
            "Duplicate: x\n",
            "Duplicate: act\n",
            "Duplicate: se\n",
            "Duplicate: big\n",
            "Duplicate: great\n",
            "Duplicate: star\n",
            "Duplicate: minister\n",
            "Duplicate: super\n",
            "Duplicate: well\n",
            "Duplicate: life\n",
            "Duplicate: man\n",
            "Duplicate: get\n",
            "Duplicate: who\n",
            "Duplicate: anushkasharma\n",
            "Duplicate: me\n",
            "Duplicate: media\n",
            "Duplicate: aaj\n",
            "Duplicate: hope\n",
            "Duplicate: colorstv\n",
            "Duplicate: make\n",
            "Duplicate: president\n",
            "Duplicate: mi\n",
            "Duplicate: district\n",
            "Duplicate: delhi\n",
            "Duplicate: school\n",
            "Duplicate: temple\n",
            "Duplicate: kya\n",
            "Duplicate: hi\n",
            "Duplicate: india\n",
            "Duplicate: khan\n",
            "Duplicate: review\n",
            "Duplicate: aap\n",
            "Duplicate: ca\n",
            "Duplicate: over\n",
            "Duplicate: job\n",
            "Duplicate: board\n",
            "Duplicate: some\n",
            "Duplicate: city\n",
            "Duplicate: health\n",
            "Duplicate: very\n",
            "Duplicate: international\n",
            "Duplicate: heading\n",
            "Duplicate: light\n",
            "Duplicate: time\n",
            "Duplicate: who\n",
            "Duplicate: thanks\n",
            "Duplicate: movie\n",
            "Duplicate: three\n",
            "Duplicate: look\n",
            "Duplicate: air\n",
            "Duplicate: welcome\n",
            "Duplicate: class\n",
            "Duplicate: toc\n",
            "Duplicate: the\n",
            "Duplicate: photo\n",
            "Duplicate: station\n",
            "Duplicate: these\n",
            "Duplicate: director\n",
            "Duplicate: last\n",
            "Duplicate: v\n",
            "Duplicate: book\n",
            "Duplicate: new\n",
            "Duplicate: of\n",
            "Duplicate: service\n",
            "Duplicate: actor\n",
            "Duplicate: loc\n",
            "Duplicate: justice\n",
            "Duplicate: business\n",
            "Duplicate: its\n",
            "Duplicate: group\n",
            "Duplicate: case\n",
            "Duplicate: yes\n",
            "Duplicate: vs\n",
            "Duplicate: weekend\n",
            "Duplicate: officer\n",
            "Duplicate: congratulations\n",
            "Duplicate: stay\n",
            "Duplicate: senior\n",
            "Duplicate: full\n",
            "Duplicate: ye\n",
            "Duplicate: are\n",
            "Duplicate: family\n",
            "Duplicate: app\n",
            "Duplicate: led\n",
            "Duplicate: heavy\n",
            "Duplicate: also\n",
            "Duplicate: hair\n",
            "Duplicate: official\n",
            "Duplicate: floor\n",
            "Duplicate: read\n",
            "Duplicate: pic\n",
            "Duplicate: bhai\n",
            "Duplicate: captain\n",
            "Duplicate: public\n",
            "Duplicate: medical\n",
            "Duplicate: directed\n",
            "Duplicate: exam\n",
            "Duplicate: k\n",
            "Duplicate: out\n",
            "Duplicate: railway\n",
            "Duplicate: investigation\n",
            "Duplicate: votes\n",
            "Duplicate: by\n",
            "Duplicate: don\n",
            "Duplicate: only\n",
            "Duplicate: even\n",
            "Duplicate: such\n",
            "Duplicate: mumbai\n",
            "Duplicate: proud\n",
            "Duplicate: express\n",
            "Duplicate: next\n",
            "Duplicate: view\n",
            "Duplicate: army\n",
            "Duplicate: hai\n",
            "Duplicate: music\n",
            "Duplicate: dharmamovies\n",
            "Duplicate: match\n",
            "Duplicate: had\n",
            "Duplicate: pay\n",
            "Duplicate: exclusive\n",
            "Duplicate: her\n",
            "Duplicate: ind\n",
            "Duplicate: services\n",
            "Duplicate: force\n",
            "Duplicate: singh\n",
            "Duplicate: cr\n",
            "Duplicate: four\n",
            "Duplicate: black\n",
            "Duplicate: dear\n",
            "Duplicate: h\n",
            "Duplicate: ek\n",
            "Duplicate: candidate\n",
            "Duplicate: youth\n",
            "Duplicate: states\n",
            "Duplicate: update\n",
            "Duplicate: bank\n",
            "Duplicate: was\n",
            "Duplicate: sector\n",
            "Duplicate: boss\n",
            "Duplicate: kumar\n",
            "Duplicate: final\n",
            "Duplicate: in\n",
            "Duplicate: press\n",
            "Duplicate: open\n",
            "Duplicate: development\n",
            "Duplicate: see\n",
            "Duplicate: fan\n",
            "Duplicate: priyanka\n",
            "Duplicate: space\n",
            "Duplicate: looking\n",
            "Duplicate: photo\n",
            "Duplicate: opposition\n",
            "Duplicate: law\n",
            "Duplicate: story\n",
            "Duplicate: another\n",
            "Duplicate: most\n",
            "Duplicate: out\n",
            "Duplicate: while\n",
            "Duplicate: yeh\n",
            "Duplicate: boss\n",
            "Duplicate: zeemusiccompany\n",
            "Duplicate: post\n",
            "Duplicate: wish\n",
            "Duplicate: keep\n",
            "Duplicate: card\n",
            "Duplicate: top\n",
            "Duplicate: series\n",
            "Duplicate: many\n",
            "Duplicate: war\n",
            "Duplicate: be\n",
            "Duplicate: show\n",
            "Duplicate: title\n",
            "Duplicate: updates\n",
            "Duplicate: hero\n",
            "Duplicate: water\n",
            "Duplicate: starplus\n",
            "Duplicate: nation\n",
            "Duplicate: border\n",
            "Duplicate: faroutakhtar\n",
            "Duplicate: march\n",
            "Duplicate: khan\n",
            "Duplicate: education\n",
            "Duplicate: every\n",
            "Duplicate: katrinakaif\n",
            "Duplicate: mobile\n",
            "Duplicate: note\n",
            "Duplicate: mother\n",
            "Duplicate: normal\n",
            "Duplicate: miss\n",
            "Duplicate: never\n",
            "Duplicate: like\n",
            "Duplicate: saddened\n",
            "Duplicate: tak\n",
            "Duplicate: gold\n",
            "Duplicate: sachin\n",
            "Duplicate: search\n",
            "Duplicate: name\n",
            "Duplicate: above\n",
            "Duplicate: bigg\n",
            "Duplicate: tax\n",
            "Duplicate: ii\n",
            "Duplicate: bat\n",
            "Duplicate: father\n",
            "Duplicate: voting\n",
            "Duplicate: global\n",
            "Duplicate: source\n",
            "Duplicate: men\n",
            "Duplicate: w\n",
            "Duplicate: films\n",
            "Duplicate: award\n",
            "Duplicate: deeply\n",
            "Duplicate: meeting\n",
            "Duplicate: central\n",
            "Duplicate: finally\n",
            "Duplicate: check\n",
            "Duplicate: always\n",
            "Duplicate: building\n",
            "Duplicate: ali\n",
            "Duplicate: being\n",
            "Duplicate: xi\n",
            "Duplicate: tendulkar\n",
            "Duplicate: committee\n",
            "Duplicate: you\n",
            "Duplicate: students\n",
            "Duplicate: rescue\n",
            "Duplicate: action\n",
            "Duplicate: song\n",
            "Duplicate: did\n",
            "Duplicate: find\n",
            "Duplicate: ipl\n",
            "Duplicate: ca\n",
            "Duplicate: both\n",
            "Duplicate: wicket\n",
            "Duplicate: fans\n",
            "Duplicate: sports\n",
            "Duplicate: god\n",
            "Duplicate: exp\n",
            "Duplicate: cabinet\n",
            "Duplicate: foreign\n",
            "Duplicate: instagram\n",
            "Duplicate: coming\n",
            "Duplicate: conference\n",
            "Duplicate: whatsapp\n",
            "Duplicate: social\n",
            "Duplicate: updates\n",
            "Duplicate: should\n",
            "Duplicate: hotel\n",
            "Duplicate: not\n",
            "Duplicate: meet\n",
            "Duplicate: kapoor\n",
            "Duplicate: ram\n",
            "Duplicate: up\n",
            "Duplicate: ministers\n",
            "Duplicate: and\n",
            "Duplicate: death\n",
            "Duplicate: traffic\n",
            "Duplicate: biz\n",
            "Duplicate: ke\n",
            "Duplicate: bill\n",
            "Duplicate: isro\n",
            "Duplicate: everyone\n",
            "Duplicate: step\n",
            "Duplicate: control\n",
            "Duplicate: posted\n",
            "Duplicate: delhi\n",
            "Duplicate: where\n",
            "Duplicate: cinema\n",
            "Duplicate: major\n",
            "Duplicate: gaya\n",
            "Duplicate: photos\n",
            "Duplicate: tomorrow\n",
            "Duplicate: pok\n",
            "Duplicate: budget\n",
            "Duplicate: twitter\n",
            "Duplicate: alert\n",
            "Duplicate: credit\n",
            "Duplicate: hum\n",
            "Duplicate: phone\n",
            "Duplicate: trust\n",
            "Duplicate: reddy\n",
            "Duplicate: sorry\n",
            "Duplicate: now\n",
            "Duplicate: ios\n",
            "Duplicate: for\n",
            "Duplicate: nothing\n",
            "Duplicate: sitting\n",
            "Duplicate: encounter\n",
            "Duplicate: mishra\n",
            "Duplicate: ranbirkapoor\n",
            "Duplicate: entertainment\n",
            "Duplicate: wishing\n",
            "Duplicate: am\n",
            "Duplicate: college\n",
            "Duplicate: jail\n",
            "Duplicate: mission\n",
            "Duplicate: produced\n",
            "Duplicate: take\n",
            "Duplicate: red\n",
            "Duplicate: head\n",
            "Duplicate: anupampkher\n",
            "Duplicate: mohan\n",
            "Duplicate: art\n",
            "Duplicate: videos\n",
            "Duplicate: mark\n",
            "Duplicate: poco\n",
            "Duplicate: all\n",
            "Duplicate: no\n",
            "Duplicate: kartik\n",
            "Duplicate: idea\n",
            "Duplicate: aur\n",
            "Duplicate: must\n",
            "Duplicate: bachchan\n",
            "Duplicate: ground\n",
            "Duplicate: their\n",
            "Duplicate: viral\n",
            "Duplicate: news\n",
            "Duplicate: part\n",
            "Duplicate: land\n",
            "Duplicate: back\n",
            "Duplicate: peace\n",
            "Duplicate: games\n",
            "Duplicate: train\n",
            "Duplicate: condolences\n",
            "Duplicate: my\n",
            "Duplicate: sun\n",
            "Duplicate: colors\n",
            "Duplicate: box\n",
            "Duplicate: ab\n",
            "Duplicate: to\n",
            "Duplicate: taapsee\n",
            "Duplicate: centre\n",
            "Duplicate: near\n",
            "Duplicate: anilkapoor\n",
            "Duplicate: ho\n",
            "Duplicate: so\n",
            "Duplicate: indian\n",
            "Duplicate: shraddhakapoor\n",
            "Duplicate: ki\n",
            "Duplicate: economic\n",
            "Duplicate: sad\n",
            "Duplicate: dekhiye\n",
            "Duplicate: iii\n",
            "Duplicate: skfilmsofficial\n",
            "Duplicate: because\n",
            "Duplicate: awards\n",
            "Duplicate: flash\n",
            "Duplicate: loved\n",
            "Duplicate: since\n",
            "Duplicate: parineetichopra\n",
            "Duplicate: answer\n",
            "Duplicate: those\n",
            "Duplicate: de\n",
            "Duplicate: catch\n",
            "Duplicate: earthquake\n",
            "Duplicate: tonight\n",
            "Duplicate: kapil\n",
            "Duplicate: really\n",
            "Duplicate: sit\n",
            "Duplicate: come\n",
            "Duplicate: would\n",
            "Duplicate: srk\n",
            "Duplicate: venue\n",
            "Duplicate: wedding\n",
            "Duplicate: aap\n",
            "Duplicate: queen\n",
            "Duplicate: met\n",
            "Duplicate: want\n",
            "Duplicate: baby\n",
            "Duplicate: o\n",
            "Duplicate: human\n",
            "Duplicate: viral\n",
            "Duplicate: defence\n",
            "Duplicate: got\n",
            "Duplicate: pro\n",
            "Duplicate: joint\n",
            "Duplicate: 6s\n",
            "Duplicate: amazing\n",
            "Duplicate: foundation\n",
            "Duplicate: gate\n",
            "Duplicate: earlier\n",
            "Duplicate: forces\n",
            "Duplicate: section\n",
            "Duplicate: history\n",
            "Duplicate: none\n",
            "Duplicate: shocked\n",
            "Duplicate: working\n",
            "Duplicate: e\n",
            "Duplicate: 5s\n",
            "Duplicate: c.\n",
            "Duplicate: parliamentary\n",
            "Duplicate: admit\n",
            "Duplicate: line\n",
            "Duplicate: girl\n",
            "Duplicate: rest\n",
            "Duplicate: shame\n",
            "Duplicate: bio\n",
            "Duplicate: woman\n",
            "Duplicate: celebrations\n",
            "Duplicate: during\n",
            "Duplicate: lady\n",
            "Duplicate: general\n",
            "Duplicate: hi\n",
            "Duplicate: six\n",
            "Duplicate: gullyboy\n",
            "Duplicate: ka\n",
            "Duplicate: right\n",
            "Duplicate: highway\n",
            "Duplicate: makeup\n",
            "Duplicate: sunnyleone\n",
            "Duplicate: cool\n",
            "Duplicate: or\n",
            "Duplicate: question\n",
            "Duplicate: grand\n",
            "Duplicate: lakh\n",
            "Duplicate: injured\n",
            "Duplicate: 's\n",
            "Duplicate: spoke\n",
            "Duplicate: then\n",
            "Duplicate: leader\n",
            "Duplicate: about\n",
            "Duplicate: body\n",
            "Duplicate: five\n",
            "Duplicate: beautiful\n",
            "Duplicate: spot\n",
            "Duplicate: due\n",
            "Duplicate: operation\n",
            "Duplicate: hit\n",
            "Duplicate: releasing\n",
            "Duplicate: under\n",
            "Duplicate: staff\n",
            "Duplicate: administration\n",
            "Duplicate: stars\n",
            "Duplicate: iss\n",
            "Duplicate: date\n",
            "Duplicate: naxals\n",
            "Duplicate: agar\n",
            "Duplicate: terrorists\n",
            "Duplicate: fashion\n",
            "Duplicate: opening\n",
            "Duplicate: constitution\n",
            "Duplicate: days\n",
            "Duplicate: any\n",
            "Duplicate: p\n",
            "Duplicate: block\n",
            "Duplicate: biggboss12\n",
            "Duplicate: jo\n",
            "Duplicate: key\n",
            "Duplicate: technology\n",
            "Duplicate: first\n",
            "Duplicate: jab\n",
            "Duplicate: agency\n",
            "Duplicate: ready\n",
            "Duplicate: off\n",
            "Duplicate: selfie\n",
            "Duplicate: bus\n",
            "Duplicate: does\n",
            "Duplicate: we\n",
            "Duplicate: club\n",
            "Duplicate: respect\n",
            "Duplicate: anupampkher\n",
            "Duplicate: sources\n",
            "Duplicate: yoga\n",
            "Duplicate: metro\n",
            "Duplicate: review\n",
            "Duplicate: kajol\n",
            "Duplicate: pure\n",
            "Duplicate: once\n",
            "Duplicate: whosunilgrover\n",
            "Duplicate: guys\n",
            "Duplicate: constituency\n",
            "Duplicate: this\n",
            "Duplicate: river\n",
            "Duplicate: lots\n",
            "Duplicate: department\n",
            "Duplicate: mere\n",
            "Duplicate: uri\n",
            "Duplicate: iv\n",
            "Duplicate: call\n",
            "Duplicate: online\n",
            "Duplicate: pls\n",
            "Duplicate: before\n",
            "Duplicate: old\n",
            "Duplicate: forest\n",
            "Duplicate: on\n",
            "Duplicate: headquarters\n",
            "Duplicate: na\n",
            "Duplicate: information\n",
            "Duplicate: has\n",
            "Duplicate: data\n",
            "Duplicate: constable\n",
            "Duplicate: further\n",
            "Duplicate: thekapilsharmashow\n",
            "Duplicate: be\n",
            "Duplicate: real\n",
            "Duplicate: meri\n",
            "Duplicate: petrol\n",
            "Duplicate: locals\n",
            "Duplicate: summit\n",
            "Duplicate: white\n",
            "Duplicate: nations\n",
            "Duplicate: clash\n",
            "Duplicate: dance\n",
            "Duplicate: love\n",
            "Duplicate: crime\n",
            "Duplicate: extremely\n",
            "Duplicate: free\n",
            "Duplicate: work\n",
            "Duplicate: financial\n",
            "Duplicate: union\n",
            "Duplicate: bharat\n",
            "Duplicate: biggboss\n",
            "Duplicate: outfit\n",
            "Duplicate: company\n",
            "Duplicate: poster\n",
            "Duplicate: salute\n",
            "Duplicate: session\n",
            "Duplicate: trade\n",
            "Duplicate: baahubali2\n",
            "Duplicate: still\n",
            "Duplicate: cricketer\n",
            "Duplicate: aajtak.in\n",
            "Duplicate: united\n",
            "Duplicate: quality\n",
            "Duplicate: dil\n",
            "Duplicate: toh\n",
            "Duplicate: join\n",
            "Duplicate: ban\n",
            "Duplicate: share\n",
            "Duplicate: time\n",
            "Duplicate: car\n",
            "Duplicate: aus\n",
            "Duplicate: private\n",
            "Duplicate: true\n",
            "Duplicate: beauty\n",
            "Duplicate: civil\n",
            "Duplicate: big\n",
            "Duplicate: boy\n",
            "Duplicate: crore\n",
            "Duplicate: area\n",
            "Duplicate: styled\n",
            "Duplicate: stop\n",
            "Duplicate: armed\n",
            "Duplicate: trophy\n",
            "Duplicate: priyankachopra\n",
            "Duplicate: sarkar\n",
            "Duplicate: ghz\n",
            "Duplicate: game\n",
            "Duplicate: sharma\n",
            "Duplicate: insurance\n",
            "Duplicate: training\n",
            "Duplicate: salman\n",
            "Duplicate: kapoor\n",
            "Duplicate: protest\n",
            "Duplicate: motion\n",
            "Duplicate: local\n",
            "Duplicate: prayers\n",
            "Duplicate: mm\n",
            "Duplicate: income\n",
            "Duplicate: tiger\n",
            "Duplicate: zero\n",
            "Duplicate: festival\n",
            "Duplicate: mat\n",
            "Duplicate: details\n",
            "Duplicate: moon\n",
            "Duplicate: rashtrapatibhvn\n",
            "Duplicate: picture\n",
            "Duplicate: l\n",
            "Duplicate: king\n",
            "Duplicate: ab\n",
            "Duplicate: jai\n",
            "Duplicate: few\n",
            "Duplicate: bb13\n",
            "Duplicate: kareenakapoorkhan\n",
            "Duplicate: feeling\n",
            "Duplicate: stadium\n",
            "Duplicate: bridge\n",
            "Duplicate: breaking\n",
            "Duplicate: vivo_india\n",
            "Duplicate: poll\n",
            "Duplicate: hollywood\n",
            "Duplicate: modi\n",
            "Duplicate: crosses\n",
            "Duplicate: dad\n",
            "Duplicate: kalank\n",
            "Duplicate: rajinikanth\n",
            "Duplicate: bhushankumar\n",
            "Duplicate: room\n",
            "Duplicate: day\n",
            "Duplicate: happiness\n",
            "Duplicate: type\n",
            "Duplicate: pictures\n",
            "Duplicate: zenfone\n",
            "Duplicate: seat\n",
            "Duplicate: demonetisation\n",
            "Duplicate: project\n",
            "Duplicate: rights\n",
            "Duplicate: plus\n",
            "Duplicate: democracy\n",
            "Duplicate: shoot\n",
            "Duplicate: rain\n",
            "Duplicate: ranveersingh\n",
            "Duplicate: express\n",
            "Duplicate: friends\n",
            "Duplicate: best\n",
            "Duplicate: rsvpmovies\n",
            "Duplicate: sometimes\n",
            "Duplicate: player\n",
            "Duplicate: at\n",
            "Duplicate: mujhe\n",
            "Duplicate: left\n",
            "Duplicate: code\n",
            "Duplicate: tune\n",
            "Duplicate: cup\n",
            "Duplicate: support\n",
            "Duplicate: me\n",
            "Duplicate: earth\n",
            "Duplicate: crossed\n",
            "Duplicate: look\n",
            "Duplicate: emergency\n",
            "Duplicate: street\n",
            "Duplicate: must\n",
            "Duplicate: enjoy\n",
            "Duplicate: blockbuster\n",
            "Duplicate: race\n",
            "Duplicate: km\n",
            "Duplicate: superb\n",
            "Duplicate: doctors\n",
            "Duplicate: greetings\n",
            "Duplicate: aaryan\n",
            "Duplicate: diesel\n",
            "Duplicate: night\n",
            "Duplicate: sony\n",
            "Duplicate: yesterday\n",
            "Duplicate: store\n",
            "Duplicate: phase\n",
            "Duplicate: independent\n",
            "Duplicate: absolutely\n",
            "Duplicate: exam\n",
            "Duplicate: shot\n",
            "Duplicate: let\n",
            "Duplicate: latest\n",
            "Duplicate: color\n",
            "Duplicate: internet\n",
            "Duplicate: huge\n",
            "Duplicate: paytm\n",
            "Duplicate: teaser\n",
            "Duplicate: active\n",
            "Duplicate: nett\n",
            "Duplicate: ambani\n",
            "Duplicate: glad\n",
            "Duplicate: band\n",
            "Duplicate: mini\n",
            "Duplicate: looks\n",
            "Duplicate: mass\n",
            "Duplicate: going\n",
            "Duplicate: photos\n",
            "Duplicate: money\n",
            "Duplicate: playing\n",
            "Duplicate: seven\n",
            "Duplicate: har\n",
            "Duplicate: member\n",
            "Duplicate: board\n",
            "Duplicate: tata\n",
            "Duplicate: elections\n",
            "Duplicate: made\n",
            "Duplicate: accused\n",
            "Duplicate: end\n",
            "Duplicate: aa\n",
            "Duplicate: blessed\n",
            "Duplicate: fund\n",
            "Duplicate: country\n",
            "Duplicate: too\n",
            "Duplicate: prime\n",
            "Duplicate: television\n",
            "Duplicate: simmba\n",
            "Duplicate: guess\n",
            "Duplicate: democratic\n",
            "Duplicate: political\n",
            "Duplicate: exclusive\n",
            "Duplicate: drive\n",
            "Duplicate: heart\n",
            "Duplicate: digvijaya\n",
            "Duplicate: breaking\n",
            "Duplicate: sharing\n",
            "Duplicate: someone\n",
            "Duplicate: report\n",
            "Duplicate: management\n",
            "Duplicate: protesters\n",
            "Duplicate: according\n",
            "Duplicate: aisa\n",
            "Duplicate: tributes\n",
            "Duplicate: nex\n",
            "Duplicate: fit\n",
            "Duplicate: digital\n",
            "Duplicate: top\n",
            "Duplicate: police\n",
            "Duplicate: personal\n",
            "Duplicate: legislative\n",
            "Duplicate: contact\n",
            "Duplicate: guard\n",
            "Duplicate: fake\n",
            "Duplicate: ashutosh\n",
            "Duplicate: thejohnabraham\n",
            "Duplicate: unit\n",
            "Duplicate: table\n",
            "Duplicate: go\n",
            "Duplicate: iss\n",
            "Duplicate: le\n",
            "Duplicate: soon\n",
            "Duplicate: yuvraj\n",
            "Duplicate: eyes\n",
            "Duplicate: anniversary\n",
            "Duplicate: celebration\n",
            "Duplicate: sky\n",
            "Duplicate: abbas\n",
            "Duplicate: son\n",
            "Duplicate: polling\n",
            "Duplicate: rao\n",
            "Duplicate: incredible\n",
            "Duplicate: nobody\n",
            "Duplicate: na\n",
            "Duplicate: science\n",
            "Duplicate: second\n",
            "Duplicate: oil\n",
            "Duplicate: jawans\n",
            "Duplicate: politics\n",
            "Duplicate: di\n",
            "Duplicate: could\n",
            "Duplicate: maa\n",
            "Duplicate: jobs\n",
            "Duplicate: whatever\n",
            "Duplicate: independence\n",
            "Duplicate: why\n",
            "Duplicate: biggboss13\n",
            "Duplicate: wing\n",
            "Duplicate: system\n",
            "Duplicate: break\n",
            "Duplicate: protection\n",
            "Duplicate: technical\n",
            "Duplicate: core\n",
            "Duplicate: each\n",
            "Duplicate: journey\n",
            "Duplicate: say\n",
            "Duplicate: do\n",
            "Duplicate: mind\n",
            "Duplicate: age\n",
            "Duplicate: tweet\n",
            "Duplicate: mode\n",
            "Duplicate: shooting\n",
            "Duplicate: throwback\n",
            "Duplicate: beta\n",
            "Duplicate: dream\n",
            "Duplicate: attack\n",
            "Duplicate: recruitment\n",
            "Duplicate: maybe\n",
            "Duplicate: kumar\n",
            "Duplicate: pannu\n",
            "Duplicate: saw\n",
            "Duplicate: feel\n",
            "Duplicate: kar\n",
            "Duplicate: task\n",
            "Duplicate: ko\n",
            "Duplicate: desh\n",
            "Duplicate: simmba\n",
            "Duplicate: result\n",
            "Duplicate: wearing\n",
            "Duplicate: alliance\n",
            "Duplicate: theshilpashetty\n",
            "Duplicate: kiss\n",
            "Duplicate: saraalikhan\n",
            "Duplicate: examination\n",
            "Duplicate: spo\n",
            "Duplicate: dark\n",
            "Duplicate: lal\n",
            "Duplicate: urithesurgicalstrike\n",
            "Duplicate: shoes\n",
            "Duplicate: delighted\n",
            "Duplicate: today\n",
            "Duplicate: children\n",
            "Duplicate: heartfelt\n",
            "Duplicate: other\n",
            "Duplicate: everything\n",
            "Duplicate: prakash\n",
            "Duplicate: flight\n",
            "Duplicate: happy\n",
            "Duplicate: air\n",
            "Duplicate: complex\n",
            "Duplicate: super\n",
            "Duplicate: members\n",
            "Duplicate: poor\n",
            "Duplicate: little\n",
            "Duplicate: image\n",
            "Duplicate: baat\n",
            "Duplicate: behind\n",
            "Duplicate: third\n",
            "Duplicate: dept\n",
            "Duplicate: something\n",
            "Duplicate: ms\n",
            "Duplicate: park\n",
            "Duplicate: bullet\n",
            "Duplicate: devotees\n",
            "Duplicate: again\n",
            "Duplicate: memorial\n",
            "Duplicate: blue\n",
            "Duplicate: food\n",
            "Duplicate: morning\n",
            "Duplicate: model\n",
            "Duplicate: freedom\n",
            "Duplicate: strongly\n",
            "Duplicate: several\n",
            "Duplicate: bharat_thefilm\n",
            "Duplicate: hindi\n",
            "Duplicate: zafar\n",
            "Duplicate: commission\n",
            "Duplicate: ranbir\n",
            "Duplicate: filmfare\n",
            "Duplicate: leaving\n",
            "Duplicate: pilot\n",
            "Duplicate: wabetainfo\n",
            "Duplicate: celebrating\n",
            "Duplicate: billion\n",
            "Duplicate: event\n",
            "Duplicate: baba\n",
            "Duplicate: remember\n",
            "Duplicate: town\n",
            "Duplicate: getting\n",
            "Duplicate: ok\n",
            "Duplicate: industry\n",
            "Duplicate: link\n",
            "Duplicate: bb12\n",
            "Duplicate: season\n",
            "Duplicate: metoo\n",
            "Duplicate: rishi\n",
            "Duplicate: toh\n",
            "Duplicate: performance\n",
            "Duplicate: additional\n",
            "Duplicate: release\n",
            "Duplicate: ne\n",
            "Duplicate: speaker\n",
            "Duplicate: y\n",
            "Duplicate: despite\n",
            "Duplicate: location\n",
            "Duplicate: limited\n",
            "Duplicate: maddockfilms\n",
            "Duplicate: congrats\n",
            "Duplicate: alert\n",
            "Duplicate: beach\n",
            "Duplicate: university\n",
            "Duplicate: star\n",
            "Duplicate: farmers\n",
            "Duplicate: making\n",
            "Duplicate: hain\n",
            "Duplicate: jio\n",
            "Duplicate: facts\n",
            "Duplicate: vision\n",
            "Duplicate: presenting\n",
            "Duplicate: oscar\n",
            "Duplicate: village\n",
            "Duplicate: account\n",
            "Duplicate: anti\n",
            "Duplicate: request\n",
            "Duplicate: long\n",
            "Duplicate: range\n",
            "Duplicate: radio\n",
            "Duplicate: mom\n",
            "Duplicate: disha\n",
            "Duplicate: min\n",
            "Duplicate: parliament\n",
            "Duplicate: main\n",
            "Duplicate: till\n",
            "Duplicate: highest\n",
            "Duplicate: yet\n",
            "Duplicate: sreesanth\n",
            "Duplicate: officers\n",
            "Duplicate: driver\n",
            "Duplicate: leaders\n",
            "Duplicate: half\n",
            "Duplicate: anand\n",
            "Duplicate: grateful\n",
            "Duplicate: colors\n",
            "Duplicate: mix\n",
            "Duplicate: give\n",
            "Duplicate: vice\n",
            "Duplicate: koi\n",
            "Duplicate: council\n",
            "Duplicate: front\n",
            "Duplicate: severe\n",
            "Duplicate: budget\n",
            "Duplicate: un\n",
            "Duplicate: need\n",
            "Duplicate: raid\n",
            "Duplicate: master\n",
            "Duplicate: guest\n",
            "Duplicate: actress\n",
            "Duplicate: transport\n",
            "Duplicate: screen\n",
            "Duplicate: way\n",
            "Duplicate: download\n",
            "Duplicate: finale\n",
            "Duplicate: photography\n",
            "Duplicate: nickjonas\n",
            "Duplicate: movies\n",
            "Duplicate: smart\n",
            "Duplicate: exchange\n",
            "Duplicate: bad\n",
            "Duplicate: silver\n",
            "Duplicate: sad\n",
            "Duplicate: sharma\n",
            "Duplicate: coach\n",
            "Duplicate: congress\n",
            "Duplicate: anand\n",
            "Duplicate: base\n",
            "Duplicate: regional\n",
            "Duplicate: run\n",
            "Duplicate: tell\n",
            "Duplicate: avengers\n",
            "Duplicate: im\n",
            "Duplicate: mortal\n",
            "Duplicate: bio\n",
            "Duplicate: praying\n",
            "Duplicate: sab\n",
            "Duplicate: vote\n",
            "Duplicate: fun\n",
            "Duplicate: excellent\n",
            "Duplicate: hot\n",
            "Duplicate: affairs\n",
            "Duplicate: dabangg3\n",
            "Duplicate: voter\n",
            "Duplicate: d.\n",
            "Duplicate: greater\n",
            "Duplicate: mera\n",
            "Duplicate: abhi\n",
            "Duplicate: having\n",
            "Duplicate: se\n",
            "Duplicate: priya\n",
            "Duplicate: mon\n",
            "Duplicate: excited\n",
            "Duplicate: click\n",
            "Duplicate: awesome\n",
            "Duplicate: watched\n",
            "Duplicate: duty\n",
            "Duplicate: sl\n",
            "Duplicate: rural\n",
            "Duplicate: chairman\n",
            "Duplicate: teachers\n",
            "Duplicate: branch\n",
            "Duplicate: vihar\n",
            "Duplicate: record\n",
            "Duplicate: delegation\n",
            "Duplicate: sale\n",
            "Duplicate: riteishd\n",
            "Duplicate: annual\n",
            "Duplicate: ministry\n",
            "Duplicate: universe\n",
            "Duplicate: ex\n",
            "Duplicate: witness\n",
            "Duplicate: center\n",
            "Duplicate: shah\n",
            "Duplicate: papa\n",
            "Duplicate: disaster\n",
            "Duplicate: mein\n",
            "Duplicate: know\n",
            "Duplicate: legend\n",
            "Duplicate: place\n",
            "Duplicate: sanju\n",
            "Duplicate: organisation\n",
            "Duplicate: lunch\n",
            "Duplicate: daddy\n",
            "Duplicate: taking\n",
            "Duplicate: one\n",
            "Duplicate: golden\n",
            "Duplicate: quick\n",
            "Duplicate: association\n",
            "Duplicate: summer\n",
            "Duplicate: early\n",
            "Duplicate: janta\n",
            "Duplicate: missing\n",
            "Duplicate: kiss\n",
            "Duplicate: sport\n",
            "Duplicate: reallyswara\n",
            "Duplicate: person\n",
            "Duplicate: level\n",
            "Duplicate: division\n",
            "Duplicate: victim\n",
            "Duplicate: tv\n",
            "Duplicate: paper\n",
            "Duplicate: welfare\n",
            "Duplicate: clean\n",
            "Duplicate: admission\n",
            "Duplicate: remarks\n",
            "Duplicate: double\n",
            "Duplicate: relief\n",
            "Duplicate: team\n",
            "Duplicate: movement\n",
            "Duplicate: sahab\n",
            "Duplicate: wi-fi\n",
            "Duplicate: intelligence\n",
            "Duplicate: green\n",
            "Duplicate: massive\n",
            "Duplicate: ceremony\n",
            "Duplicate: deepika\n",
            "Duplicate: courtesy\n",
            "Duplicate: mou\n",
            "Duplicate: kuch\n",
            "Duplicate: ball\n",
            "Duplicate: situation\n",
            "Duplicate: eng\n",
            "Duplicate: north\n",
            "Duplicate: register\n",
            "Duplicate: ur\n",
            "Duplicate: policy\n",
            "Duplicate: child\n",
            "Duplicate: secretary\n",
            "Duplicate: trailer\n",
            "Duplicate: number\n",
            "Duplicate: blast\n",
            "Duplicate: community\n",
            "Duplicate: years\n",
            "Duplicate: judge\n",
            "Duplicate: pyaar\n",
            "Duplicate: lawyer\n",
            "Duplicate: br\n",
            "Duplicate: hard\n",
            "Duplicate: ever\n",
            "Duplicate: teacher\n",
            "Duplicate: iphone\n",
            "Duplicate: statement\n",
            "Duplicate: par\n",
            "Duplicate: nahi\n",
            "Duplicate: late\n",
            "Duplicate: indian\n",
            "Duplicate: instead\n",
            "Duplicate: highest\n",
            "Duplicate: dhadak\n",
            "Duplicate: wow\n",
            "Duplicate: salman\n",
            "Duplicate: military\n",
            "Duplicate: dancing\n",
            "Duplicate: camera\n",
            "Duplicate: official\n",
            "Duplicate: ma\n",
            "Duplicate: vishal\n",
            "Duplicate: wife\n",
            "Duplicate: order\n",
            "Duplicate: citizens\n",
            "Duplicate: letter\n",
            "Duplicate: shaadi\n",
            "Duplicate: market\n",
            "Duplicate: young\n",
            "Duplicate: a4\n",
            "Duplicate: pollution\n",
            "Duplicate: god\n",
            "Duplicate: watching\n",
            "Duplicate: common\n",
            "Duplicate: priyanka\n",
            "Duplicate: collection\n",
            "Duplicate: bodies\n",
            "Duplicate: face\n",
            "Duplicate: kedarnath\n",
            "Duplicate: deep\n",
            "Duplicate: hearing\n",
            "Duplicate: listen\n",
            "Duplicate: tigerzindahai\n",
            "Duplicate: veerediwedding\n",
            "Duplicate: student\n",
            "Duplicate: polls\n",
            "Duplicate: around\n",
            "Duplicate: hate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Building graph...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duplicate: gate\n",
            "max_size of vocab was specified as 50000; we now have 50000 words. Stopping reading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:129: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:130: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:174: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "INFO:tensorflow:batch_size 35, attn_size: 512, emb_size: 150\n",
            "INFO:tensorflow:Adding attention_decoder timestep 0 of 1\n",
            "INFO:tensorflow:Time to build graph: 1 seconds\n",
            "INFO:tensorflow:Loading checkpoint drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-11739\n",
            "INFO:tensorflow:Restoring parameters from drive/My Drive/hindi_dataset/logs_6_12/train/model.ckpt-11739\n",
            "INFO:tensorflow:Wrote example 0 to file\n",
            "INFO:tensorflow:sentence summarized 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['पठानकोट', 'एयरबेस', 'पर', 'पहुंच', 'रहे', 'हैं', 'नरेंद्र', 'मोदी', 'ने', 'की', 'पठानकोट', 'के', 'लिए', 'की', 'जांच']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 1 to file\n",
            "INFO:tensorflow:sentence summarized 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['175', 'रन', 'के', 'पार', 'कर', 'रहे', 'हैं', 'सचिन', 'तेंदुलकर', 'ने', 'भारतीय', 'क्रिकेट', 'को', 'समर्पित', 'किया']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 2 to file\n",
            "INFO:tensorflow:sentence summarized 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['नक्सली', 'हमले', 'में', 'गृह', 'मंत्री', 'ने', 'छत्तीसगढ़', 'में', 'नक्सली', 'नेताओं', 'के', 'काफिले', 'पर', 'की', 'जांच']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 3 to file\n",
            "INFO:tensorflow:sentence summarized 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['अमित', 'शाह', 'बोले-', 'मध्य', 'प्रदेश', 'में', 'राम', 'मंदिर', 'बन', 'रहे', 'हैं', 'अमित', 'गवर्नर', 'अमित', 'शाह']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 4 to file\n",
            "INFO:tensorflow:sentence summarized 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['पंत', 'की', 'आलोचना', 'के', 'लिए', 'दिल्ली', 'कैपिटल्स', 'के', 'स्काउटिंग', 'प्रमुख', 'प्रवीण', 'आमरे', 'को', 'लगता', 'है']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 5 to file\n",
            "INFO:tensorflow:sentence summarized 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['माइक्रोसॉफ्ट', 'के', 'दिग्गज', 'मार्क', 'लुकोव्सकी', 'के', 'हार्डवेयर', 'सिस्टम', 'पर', 'काम', 'कर', 'रहा', 'है', 'गूगल', 'का']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 6 to file\n",
            "INFO:tensorflow:sentence summarized 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['छत्तीसगढ़', 'में', 'दो', 'नाबालिग', 'भाईयों', 'के', 'बीच', 'दोनों', 'भाई', 'के', 'भाई', 'ने', 'की', 'की', 'की']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 7 to file\n",
            "INFO:tensorflow:sentence summarized 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['संसद', 'सत्र', 'में', 'शामिल', 'होने', 'वाला', 'आदमी', 'की', 'जेब', 'में', 'रहती', 'है', 'अम्मा', 'की', 'तस्वीर']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 8 to file\n",
            "INFO:tensorflow:sentence summarized 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['बांदीपोरा', 'में', 'छुट्टी', 'पर', 'बीएसएफ', 'के', 'जवान', 'की', 'गोली', 'मारकर', 'हत्या', 'की', 'लश्कर', 'का', 'आंतकियों']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 9 to file\n",
            "INFO:tensorflow:sentence summarized 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['अमित', 'शाह', 'की', 'रैली', 'में', 'कांग्रेस', 'में', 'शामिल', 'हो', 'रहे', 'हैं', 'अमित', 'सिंह', 'सिंह', 'सिंह']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 10 to file\n",
            "INFO:tensorflow:sentence summarized 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['संजय', 'कोइराला', 'के', 'नाम', 'पर', 'चल', 'रही', 'है', 'फिल्म', 'की', 'ये', 'है', 'वजह', 'का', 'सौदा']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 11 to file\n",
            "INFO:tensorflow:sentence summarized 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['पैरा', 'मेडिकल', 'की', 'दोषियों', 'के', 'खिलाफ', 'सख्त', 'कार्रवाई', 'की', 'मांग', 'करेंगे', 'मीरा', 'कुमार', 'ने', 'की']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 12 to file\n",
            "INFO:tensorflow:sentence summarized 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['मथुरा', 'में', 'तीन', 'दिन', 'पूर्व', 'एक', 'वृद्ध', 'महिला', 'से', 'किया', 'दुराचार', 'का', 'मामला', 'दर्ज', 'हुआ']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 13 to file\n",
            "INFO:tensorflow:sentence summarized 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['चीन', 'के', 'आर्थिक', 'सुधारों', 'की', 'राह', 'से', 'अप्रभावित', 'हैं', '‘जिम्मेदार', 'हू', 'जिन्ताओ', 'की', 'भूमिका', 'में']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 14 to file\n",
            "INFO:tensorflow:sentence summarized 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['आसाराम', 'के', 'खिलाफ', 'बलात्कार', 'केस', 'की', 'सीबीआई', 'जांच', 'की', 'सिफारिश', 'कर', 'गई', 'थी', 'हत्या', 'की']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 15 to file\n",
            "INFO:tensorflow:sentence summarized 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['रेप', 'का', 'सबसे', 'बर्बर', 'हत्यारा', 'क्या', 'है', 'दिल्ली', 'गैंग', 'का', 'सबसे', 'छोटा', 'कत्ल', 'का', 'आरोप']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 16 to file\n",
            "INFO:tensorflow:sentence summarized 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['श्रीलंका', 'की', 'हिंसक', 'घटनाओं', 'की', 'वजह', 'से', 'पहले', 'कोलंबो', 'में', 'टीम', 'इंडिया', 'का', 'पहला', 'मुकाबला']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 17 to file\n",
            "INFO:tensorflow:sentence summarized 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['इराक', 'में', 'दो', 'दिनों', 'में', 'आत्मघाती', 'हमले', 'में', '26', 'लोगों', 'की', 'मौत', 'का', 'दूसरा', 'हमला']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 18 to file\n",
            "INFO:tensorflow:sentence summarized 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['स्टेज', 'पर', 'घूम', 'रहे', 'हैं', '68', 'साल', 'का', 'सबसे', 'तेजी', 'और', '69', 'का', 'होने', 'वाला']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 19 to file\n",
            "INFO:tensorflow:sentence summarized 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['रेलवे', 'टिकटों', 'की', 'गिरफ्त', 'में', 'रेलवे', 'का', 'दलाल', 'राकेश', 'चौरसिया', 'को', 'रेलवे', 'ने', 'किया', 'गिरफ्तार']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 20 to file\n",
            "INFO:tensorflow:sentence summarized 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['कर्नाटक', 'के', 'पूर्व', 'मंत्री', 'जनार्दन', 'रेड्डी', 'की', 'बेटी', 'की', 'शादी', 'का', 'विवाह', '16', 'नवंबर', 'को']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 21 to file\n",
            "INFO:tensorflow:sentence summarized 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['सैमसंग', 'इंडिया', 'और', 'जमशेदपुर', 'में', '10', 'वर्तमान', 'स्कूलों', 'के', 'लिए', 'तैयार', 'हो', 'रहे', 'हैं', 'दो']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 22 to file\n",
            "INFO:tensorflow:sentence summarized 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['शेयर', 'बाजार', 'में', '37', 'अंकों', 'की', 'बढ़त', 'के', 'साथ', 'बंद', 'हुआ', 'शेयर', 'बाजार', 'का', 'रिकॉर्ड']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 23 to file\n",
            "INFO:tensorflow:sentence summarized 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['संजय', 'भंडारी', 'ने', 'की', 'कांग्रेस', 'पर', 'पलटवार', 'की', 'जांच', 'के', 'लिए', 'तैयार', 'हो', 'रही', 'थी']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 24 to file\n",
            "INFO:tensorflow:sentence summarized 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['राजा', 'कैंसर', 'का', 'इस्तेमाल', 'कर', 'चुके', 'हैं', 'आम', 'आदमी', 'की', 'चीजों', 'के', 'लिए', 'ये', 'हैं']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 25 to file\n",
            "INFO:tensorflow:sentence summarized 26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['रामनाथ', 'कोविंद', 'की', 'जीत', 'के', 'बहाने', 'मायावती', 'का', 'समर्थन', 'कर', 'रहे', 'हैं', 'मीरा', 'प्रसाद', 'मौर्य']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 26 to file\n",
            "INFO:tensorflow:sentence summarized 27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['बुढ़ापे', 'में', 'याददाश्त', 'खोने', 'का', 'खतरा', 'हो', 'जाता', 'है', 'संतरे', 'का', 'जूस', 'जूस', 'पीते', 'हैं']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 27 to file\n",
            "INFO:tensorflow:sentence summarized 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['जियोनी', 'ने', 'पेश', 'किया', 'नया', 'स्मार्टफोन', 'पायनियर', 'P6', 'फेसिंग', 'कैमरा', 'कैमरा', 'वाला', 'फोन', 'का', 'ऑपशन']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 28 to file\n",
            "INFO:tensorflow:sentence summarized 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['मुलायम', 'सिंह', 'यादव', 'का', 'नरेंद्र', 'मोदी', 'का', 'प्रदर्शन', 'कार्यक्रम', 'में', 'तीन', 'लाख', 'से', 'अधिक', 'राज्यों']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 29 to file\n",
            "INFO:tensorflow:sentence summarized 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['डॉक्टर', 'हेलेन', 'का', 'अमेरिकी', 'वैज्ञानिक', 'के', 'पास', 'डॉक्टर', 'हेलेन', 'फिशर', 'फिशर', 'विज्ञानी', 'विज्ञानी', 'का', 'जवाब']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 30 to file\n",
            "INFO:tensorflow:sentence summarized 31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['दक्षिण', 'अफ्रीका', 'के', 'वर्ल्ड', 'कप', 'में', 'सबसे', 'बड़ी', 'जीत', 'से', 'बस', 'पर', 'आ', 'रहे', 'हैं']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 31 to file\n",
            "INFO:tensorflow:sentence summarized 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['सेंसेक्स', '60', 'अंकों', 'की', 'गिरावट', 'के', 'साथ', 'बंद', 'हुआ', 'निवेशकों', 'की', 'दूसरी', 'निवेशकों', 'की', 'चिंता']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 32 to file\n",
            "INFO:tensorflow:sentence summarized 33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['उत्तर', 'प्रदेश', 'में', 'दो', 'युवतियों', 'के', 'आपस', 'में', 'समलिंगी', 'विवाह', 'का', 'मामला', 'आया', 'था', 'पुलिस']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 33 to file\n",
            "INFO:tensorflow:sentence summarized 34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['इंडिया', 'का', 'चुनाव', 'लड़ना', 'चाहते', 'थे', 'नरेंद्र', 'पवार', 'से', 'बात', 'पवार', 'का', 'शरद', 'पवार', 'का']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 34 to file\n",
            "INFO:tensorflow:sentence summarized 35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['स्\\u200dपीक', 'एशिया', 'केस', 'में', '4', 'लाख', 'सदस्यों', 'के', 'दो', 'अप्रैल', 'तक', 'जांच', 'लगाने', 'का', 'निर्देश']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 35 to file\n",
            "INFO:tensorflow:sentence summarized 36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['नोएडा', 'में', 'महिला', 'की', 'मौत', 'मामले', 'में', 'दहेज', 'के', 'खिलाफ', 'केस', 'दर्ज', 'हुआ', 'दहेज', 'का']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 36 to file\n",
            "INFO:tensorflow:sentence summarized 37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['अनिल', 'कुंबले', 'को', 'दूसरे', 'दिन', 'भारत', 'का', 'मजबूत', 'स्थिति', 'में', 'अस्\\u200dपताल', 'ले', 'गए', 'अनिल', 'कुंबले']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 37 to file\n",
            "INFO:tensorflow:sentence summarized 38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['विद्या', 'सागर', 'ने', 'विधवा', 'की', 'विधवा', 'की', 'शादी', 'की', 'शुरुआत', 'की', 'ये', '5', 'बड़ी', 'खबरें']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 38 to file\n",
            "INFO:tensorflow:sentence summarized 39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['सूरज', 'पंचोली', 'खान', 'की', 'खुदकुशी', 'के', 'मामले', 'पर', 'सूरज', 'पंचोली', 'ने', 'शेयर', 'की', 'की', 'की']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 39 to file\n",
            "INFO:tensorflow:sentence summarized 40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['निर्भया', 'मामले', 'में', 'वाइस', 'कली', 'पुरी', 'ने', 'दिया', 'निर्भया', 'के', 'पिता', 'को', 'जिंदा', 'जला', 'दिया']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 40 to file\n",
            "INFO:tensorflow:sentence summarized 41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['लंदन', 'में', 'दो', 'मिनट', 'में', 'गिर', 'रहे', 'हैं', 'देवेंद्रो', 'देवेंद्रो', 'देवेंद्रो', 'सिंह', 'और', 'जय', 'सिंह']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 41 to file\n",
            "INFO:tensorflow:sentence summarized 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['जम्मू-कश्मीर', 'दौरे', 'से', 'दो', 'दिन', 'में', 'मारे', 'गए', '11', 'लोगों', 'की', 'जान', 'का', 'सैनिकों', 'को']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 42 to file\n",
            "INFO:tensorflow:sentence summarized 43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['कॉफी', 'के', 'संस्थापक', 'कारोबारी', 'का', 'अंतिम', 'संस्कार', 'में', '36', 'घंटे', 'से', 'ज्यादा', 'समय', 'के', 'बाद']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 43 to file\n",
            "INFO:tensorflow:sentence summarized 44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['माली', 'माली', 'की', 'महिला', 'टीम', 'ने', 'अंतरराष्ट्रीय', 'स्तर', 'में', 'सबसे', 'ज्यादा', 'गेंदें', '6', 'रनों', 'पर']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 44 to file\n",
            "INFO:tensorflow:sentence summarized 45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['मुंबई', 'में', 'तत्काल', 'प्रीमियम', 'टिकटों', 'के', 'खरीदार', 'नहीं', 'जा', 'रहे', 'हैं', 'तत्काल', 'अधिकारी', 'ने', 'दी']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 45 to file\n",
            "INFO:tensorflow:sentence summarized 46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['टीम', 'इंडिया', 'के', 'खिलाफ', 'टी-20', 'सीरीज', 'का', 'पहला', 'प्रसारण', 'रन', 'बनाने', 'वाले', 'जावेद', 'के', 'नाम']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 46 to file\n",
            "INFO:tensorflow:sentence summarized 47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['श्यामा', 'प्रसाद', 'मुखर्जी', 'की', 'मौत', 'मामले', 'में', 'अड़ंगा', 'लगाने', 'पर', 'कांग्रेस', 'का', 'कांग्रेस', 'का', 'आरोप']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 47 to file\n",
            "INFO:tensorflow:sentence summarized 48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['रंगून', 'के', 'दायरे', 'में', 'कंगना', 'जूलिया', 'का', 'किरदार', 'निभा', 'रही', 'है', 'कंगना', 'रनोट.', 'ये', 'हैं']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 48 to file\n",
            "INFO:tensorflow:sentence summarized 49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['जाह्नवी', 'का', 'सिंपल', 'लुक', 'लीक', 'होने', 'के', 'बाद', 'मेकर्स', 'ने', 'जाह्नवी', 'के', 'सेट', 'पर', 'मोबाइल']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 49 to file\n",
            "INFO:tensorflow:sentence summarized 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['नितिन', 'गडकरी', 'खिलाफ', 'अभद्र', 'भाषा', 'का', 'इस्\\u200dतेमाल', 'करने', 'वाले', 'बीजेपी', 'अध्\\u200dयक्ष', 'नितिन', 'गडकरी', 'का', 'बयान']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 50 to file\n",
            "INFO:tensorflow:sentence summarized 51\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['जम्मू-कश्मीर', 'में', 'तनाव', 'के', 'बाद', 'अब', 'तक', 'कोई', 'अप्रिय', 'नहीं', 'हो', 'रहे', 'कई', 'अहम', 'कदम']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 51 to file\n",
            "INFO:tensorflow:sentence summarized 52\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['वित्त', 'मंत्री', 'अरुण', 'जेटली', 'ने', 'जेटली', 'से', 'छोटे', 'टैक्स', 'स्लैब', 'में', 'लाने', 'के', 'लिए', 'टैक्स']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 52 to file\n",
            "INFO:tensorflow:sentence summarized 53\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['रितिक', 'के', 'साथ', 'लड़की', 'के', 'गले', 'भी', 'मिलते', 'थे', 'रितिक', 'और', 'सुजैन', 'खान', 'के', 'दोस्त']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 53 to file\n",
            "INFO:tensorflow:sentence summarized 54\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['बदमाशों', 'ने', 'की', 'जिम', 'ट्रेनर', 'की', 'गोली', 'मारकर', 'हत्या', 'बदमाशों', 'की', 'की', 'हत्या', 'की', 'हत्या']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 54 to file\n",
            "INFO:tensorflow:sentence summarized 55\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['इंफोसिस', 'के', 'सवालों', 'का', 'जवाब', 'देने', 'के', 'लिए', 'दो', 'कॉल', 'सेंटर', 'शुरू', 'हो', 'सकता', 'है']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 55 to file\n",
            "INFO:tensorflow:sentence summarized 56\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['गुड़गांव', 'के', 'मिलेनियम', 'सिटी', 'से', 'लापता', 'बदमाशों', 'ने', 'अगवा', 'किया', 'आखिरी', 'बार', 'सुरेंदर', 'फोगाट', 'फोगाट']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 56 to file\n",
            "INFO:tensorflow:sentence summarized 57\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['4', 'करोड़', 'रुपये', 'की', 'कमाई', 'कर', 'सकती', 'है', 'सिद्धार्थ', 'मल्होत्रा', 'की', 'फिल्म', 'का', 'फर्स्ट', 'डे']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 57 to file\n",
            "INFO:tensorflow:sentence summarized 58\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['बिहार', 'की', 'राजनीति', 'में', 'चाहती', 'हैं', 'नीतीश', 'कुमार', 'की', 'बात', 'करते', 'हैं', 'कि', 'खुद', 'को']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 58 to file\n",
            "INFO:tensorflow:sentence summarized 59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['मध्य', 'जापान', 'के', 'यामानाशी', 'में', '5.5', 'तीव्रता', 'में', 'आया', 'भूकंप', 'का', 'नुकसान', 'की', 'खबर', 'नहीं']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 59 to file\n",
            "INFO:tensorflow:sentence summarized 60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['22', 'साल', 'की', 'बेटी', 'की', 'परीक्षा', 'में', 'प्रीति', 'यादव', 'ने', 'किया', 'पिता', 'का', 'नाम', 'रौशन']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 60 to file\n",
            "INFO:tensorflow:sentence summarized 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['खाद्य', 'सुरक्षा', 'बिल', 'का', 'वादा', 'कर', 'रहे', 'हैं', 'सोनिया', 'गांधी', 'ने', 'खाद्य', 'सुरक्षा', 'की', 'अपील']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 61 to file\n",
            "INFO:tensorflow:sentence summarized 62\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['राम', 'रहीम', 'के', 'डेरे', 'की', 'तलाशी', 'में', 'रहे', 'हैं', 'बाबा', 'राम', 'रहीम', 'का', 'राम', 'रहीम']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 62 to file\n",
            "INFO:tensorflow:sentence summarized 63\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['गूगल', 'ने', 'दुनिया', 'भर', 'के', 'मुसलमानों', 'के', 'लिए', 'किब्ला', 'ढूंढते', 'हैं', 'गूगल', 'का', 'नया', 'फीचर']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 63 to file\n",
            "INFO:tensorflow:sentence summarized 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['पढ़िए', 'सोमवार', 'शाम', 'की', 'पांच', 'बड़ी', 'खबरें.', 'पढ़ें', 'सोमवार', 'सुबह', 'की', '5', 'बड़ी', 'खबरें', 'का']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 64 to file\n",
            "INFO:tensorflow:sentence summarized 65\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['दो', 'करोड़', 'रुपये', 'का', 'कारोबार', 'करने', 'वाले', 'छोटे', 'व्यापारी', 'और', 'डिजिटल', 'माध्यमों', 'से', 'कम', 'टैक्स']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 65 to file\n",
            "INFO:tensorflow:sentence summarized 66\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['शरीर', 'से', 'विषैले', 'पदार्थ', 'और', 'अनियमित', 'जीवनशैली', 'की', 'वजह', 'से', 'हो', 'गए', 'हैं', 'ये', 'हैं']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 66 to file\n",
            "INFO:tensorflow:sentence summarized 67\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['बीसीसीआई', 'ने', 'भारतीय', 'क्रिकेट', 'के', 'लिये', '20-20', 'लाख', 'रुपये', 'के', 'नकद', 'पुरस्कार', 'भी', 'दी', 'बधाई']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 67 to file\n",
            "INFO:tensorflow:sentence summarized 68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['3', 'जून', 'को', 'Central', '3', 'बच्चों', 'के', 'मार्क्स', 'कर', 'सकते', 'हैं', 'मार्क्स', 'ना', 'करें', 'ये']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 68 to file\n",
            "INFO:tensorflow:sentence summarized 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['शिवसेना', 'का', 'सामना', 'करने', 'का', 'काम', 'कर', 'रहे', 'हैं', 'पृथ्वीराज', 'चव्हाण', 'ने', 'कुर्सी', 'से', 'हटा']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 69 to file\n",
            "INFO:tensorflow:sentence summarized 70\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['पूर्व', 'प्रधानमंत्री', 'राजीव', 'गांधी', 'की', 'हत्या', 'के', 'बाद', 'मोदी', 'ने', 'की', 'श्रद्धांजलि', 'अर्पित', 'की', 'हत्या']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 70 to file\n",
            "INFO:tensorflow:sentence summarized 71\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['20', 'साल', 'की', 'नौकरानी', 'से', 'बलात्कार', 'करने', 'के', 'आरोप', 'में', 'काम', 'करते', 'थे', 'व्यापारी', 'गिरफ्तार']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 71 to file\n",
            "INFO:tensorflow:sentence summarized 72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"'मन\", '27', 'दिसंबर', 'को', \"'मन\", 'करेंगे', 'पीएम', 'मोदी', 'साल', 'की', \"बात'\", \"'मन\", 'की', \"बात'\", 'की']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 72 to file\n",
            "INFO:tensorflow:sentence summarized 73\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['न्यूजीलैंड', 'ने', 'ऑस्ट्रेलिया', 'को', 'आखिरी', 'बार', 'न्यूजीलैंड', 'वनडे', 'में', '2-1', 'से', 'की', 'जीत', 'की', 'ये']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 73 to file\n",
            "INFO:tensorflow:sentence summarized 74\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['पूर्वांचल', 'बीजेपी', 'की', 'रैली', 'में', '23', 'सितंबर', 'को', 'एक', 'रैली', 'में', 'शामिल', 'होंगे', 'मनोज', 'तिवारी']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 74 to file\n",
            "INFO:tensorflow:sentence summarized 75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['बिप्लब', 'देब', 'ने', 'भाजपा', 'की', 'ऐतिहासिक', 'जीत', 'का', 'अंत', 'बन', 'रहे', 'हैं', 'बिप्लब', 'देब', 'देब']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 75 to file\n",
            "INFO:tensorflow:sentence summarized 76\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['राष्ट्रमंडल', 'खेलों', 'से', 'संबंधित', 'मंत्रियों', 'की', 'तैयारियों', 'की', 'समीक्षा', 'करेंगे', 'मनमोहन', 'सिंह', 'ने', 'की', 'बैठक']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 76 to file\n",
            "INFO:tensorflow:sentence summarized 77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['शेयर', 'बाजार', 'की', 'गिरावट', 'के', 'साथ', 'बंद', 'हुआ', 'है', 'शेयर', 'बाजार', 'का', 'बेहतर', 'साबित', 'हुआ']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 77 to file\n",
            "INFO:tensorflow:sentence summarized 78\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['जम्मू-कश्मीर', 'के', 'मसले', 'पर', 'पाकिस्तान', 'के', 'मंत्री', 'इमरान', 'खान', 'बोले-', 'भारत', 'के', 'खिलाफ', 'हो', 'सकती']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 78 to file\n",
            "INFO:tensorflow:sentence summarized 79\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['पाकिस्तान', 'के', 'परमाणु', 'हथियार', 'प्रतिरोध', 'के', 'लिए', 'भारतीय', 'रणनीतिक', 'विशेषज्ञों', 'ने', 'की', 'निंदा', 'की', 'क्षमता']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 79 to file\n",
            "INFO:tensorflow:sentence summarized 80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['कांग्रेस', 'गठबंधन', 'के', 'दो', 'दिन', 'में', 'जारी', 'हो', 'सकता', 'है', 'यूपी', 'की', 'रणनीति', 'का', 'खाका']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 80 to file\n",
            "INFO:tensorflow:sentence summarized 81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['बॉस', 'ऑफिस', 'पर', 'ये', 'है', 'बॉस', 'की', 'ये', 'है', 'ये', 'है', 'वजह', 'से', 'करें', 'ये']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 81 to file\n",
            "INFO:tensorflow:sentence summarized 82\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['कटरीना', 'शतरंज', 'का', 'खेल', 'खेलने', 'के', 'माहिर', 'हैं', 'आमिर', 'भी', 'कटरीना', 'कैफ', 'भी', 'हो', 'गया']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 82 to file\n",
            "INFO:tensorflow:sentence summarized 83\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['सर्दियों', 'में', 'कोहरे', 'के', 'बाद', 'अब', 'भी', 'नहीं', 'हो', 'रहे', 'हैं', 'कोहरे', 'का', 'होता', 'है']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 83 to file\n",
            "INFO:tensorflow:sentence summarized 84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['सचिन', 'पूजा', 'पंडाल', 'का', 'उद्घाटन', 'करने', 'वेस्ट', 'इंडीज', 'के', 'पूर्व', 'कप्तान', 'विव', 'रिचर्ड्स', 'रिचर्ड्स', 'ने']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 84 to file\n",
            "INFO:tensorflow:sentence summarized 85\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['लोकसभा', 'चुनाव', 'से', 'पहले', 'भाजपा', 'को', 'अपने', 'नेताओं', 'को', 'सकते', 'हैं', 'अमित', 'शाह', 'का', 'खतरा']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 85 to file\n",
            "INFO:tensorflow:sentence summarized 86\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['दीवाली', 'के', 'ठीक', 'एक', 'दिन', 'बाद', 'चार', 'नवंबर', 'को', 'होगी', 'फिल्म', \"'कृष\", \"3'\", 'का', 'प्रदर्शन']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 86 to file\n",
            "INFO:tensorflow:sentence summarized 87\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['हैरी', 'और', 'ब्रिटिश', 'सिंगर', 'को', 'एक', 'हफ्ते', 'में', 'दूसरी', 'बार', 'प्रशंसकों', 'ने', 'शेयर', 'की', 'जैकेट']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 87 to file\n",
            "INFO:tensorflow:sentence summarized 88\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['महिलाओं', 'के', 'खिलाफ', 'हिंसा', 'का', 'अंतरराष्ट्रीय', 'राष्ट्र', 'का', 'हिस्सा', 'संयुक्त', 'राष्ट्र', 'के', 'साथ', 'रोशन', 'किया']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 88 to file\n",
            "INFO:tensorflow:sentence summarized 89\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['नवादा', 'में', 'नीतीश', 'मोदी', 'और', 'नीतीश', 'कुमार', 'का', 'इन', 'नेताओं', 'पर', 'जूते', 'फेंकने', 'से', 'परहेज']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 89 to file\n",
            "INFO:tensorflow:sentence summarized 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['गृह', 'मंत्री', 'पी', 'चिदंबरम', 'का', 'घर', 'सबसे', 'खतरनाक', 'जगह', 'सबसे', 'खतरनाक', 'मानते', 'हैं', 'गृह', 'मंत्री']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 90 to file\n",
            "INFO:tensorflow:sentence summarized 91\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['न्यूजीलैंड', 'ने', 'श्रीलंका', 'को', 'पांच', 'विकेट', 'से', 'हरा', 'दिया', 'न्यूजीलैंड', 'का', 'चौथे', 'दिन', 'न्यूजीलैंड', 'का']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 91 to file\n",
            "INFO:tensorflow:sentence summarized 92\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['हिमाचल', 'प्रदेश', 'में', 'चुनाव', 'आयोग', 'का', 'एक', 'दल', 'चुनाव', 'से', 'पहले', 'चुनाव', 'आयुक्त', 'विनोद', 'जुत्शी']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 92 to file\n",
            "INFO:tensorflow:sentence summarized 93\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['दिल्ली', 'मेट्रो', 'की', 'जनता', 'का', 'सम्\\u200dमान', 'करते', 'हैं', 'मोहन', 'भागवत', 'ने', 'की', 'राष्ट्रपति', 'से', 'मुलाकात']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 93 to file\n",
            "INFO:tensorflow:sentence summarized 94\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['कश्मीर', 'के', 'कुछ', 'भागों', 'में', 'कर्फ्यू', 'में', 'दो', 'लोगों', 'की', 'हत्या', 'की', 'अपील', 'की', 'अपील']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 94 to file\n",
            "INFO:tensorflow:sentence summarized 95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['अकाली', 'दल', 'ने', 'हरियाणा', 'विधानसभा', 'चुनाव', 'में', 'विधानसभा', 'चुनाव', 'लड़ने', 'का', 'ऐलान', 'कर', 'रही', 'है']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 95 to file\n",
            "INFO:tensorflow:sentence summarized 96\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['श्री', 'शक्ति', 'के', 'इंजन', 'में', 'तकनीकी', 'खराबी', 'के', 'चलते', 'ट्रेन', 'सुरंग', 'में', 'कोई', 'दिक्कत', 'नहीं']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 96 to file\n",
            "INFO:tensorflow:sentence summarized 97\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['जिग्नेश', 'मेवाणी', 'ने', 'राहुल', 'गांधी', 'से', 'मुलाकात', 'के', 'बाद', 'नहीं', 'हो', 'रहे', 'हैं', 'हार्दिक', 'पटेल']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 97 to file\n",
            "INFO:tensorflow:sentence summarized 98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['महाराष्ट्र', 'के', 'गांवों', 'में', 'पानी', 'भरने', 'के', 'लिए', 'पानी', 'भरते', 'हुए', '1200', 'लोगों', 'का', 'स्तर']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 98 to file\n",
            "INFO:tensorflow:sentence summarized 99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['आईआईटी', 'खड़गपुर', 'से', 'पासआउट', 'होने', 'का', 'एक', 'इंसान', 'को', 'बेचने', 'पर', 'पैसे', 'देती', 'है', 'ये']\n",
            "file written\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Wrote example 99 to file\n",
            "INFO:tensorflow:sentence summarized 100\n",
            "INFO:tensorflow:Counter 100 stopped.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['तेज', 'सर्दी', 'की', 'वजह', 'से', 'कोटा', 'में', 'एक', 'शख्स', 'की', 'मौत', 'भी', 'हो', 'गई', 'है']\n",
            "file written\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uH6Nx1-M6M4C"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### rouge scores"
      ],
      "metadata": {
        "id": "VY0KdisD6NOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "path_ = \"drive/My Drive/hindi_dataset/logs_6_12/decode_train_train_400maxenc_35beam_20mindec_15maxdec_train-ckpt-11739/reference/\";\n",
        "directory = os.fsencode(path_)\n",
        "print(directory)\n",
        "refe_list = []\n",
        "for file_ in os.listdir(directory):\n",
        "  filename = os.fsdecode(file_)\n",
        "  print(filename)\n",
        "  with open(path_+filename, 'r') as file__:\n",
        "    data = file__.read().replace('\\n', '')\n",
        "    refe_list.append(data)\n",
        "\n",
        "path_ = \"drive/My Drive/hindi_dataset/logs_6_12/decode_train_train_400maxenc_35beam_20mindec_15maxdec_train-ckpt-11739/decoded/\";\n",
        "directory = os.fsencode(path_)\n",
        "decode_list = []\n",
        "for file_ in os.listdir(directory):\n",
        "  filename = os.fsdecode(file_)\n",
        "  with open(path_+filename, 'r') as file__:\n",
        "    data = file__.read().replace('\\n', '')\n",
        "    decode_list.append(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tDQwQR96NOB",
        "outputId": "a3a13692-4fc7-439d-8ace-f31c52aa4ce9"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'drive/My Drive/hindi_dataset/logs_6_12/decode_train_train_400maxenc_35beam_20mindec_15maxdec_train-ckpt-11739/reference/'\n",
            "000000_reference.txt\n",
            "000001_reference.txt\n",
            "000002_reference.txt\n",
            "000003_reference.txt\n",
            "000004_reference.txt\n",
            "000005_reference.txt\n",
            "000006_reference.txt\n",
            "000007_reference.txt\n",
            "000008_reference.txt\n",
            "000009_reference.txt\n",
            "000010_reference.txt\n",
            "000011_reference.txt\n",
            "000012_reference.txt\n",
            "000013_reference.txt\n",
            "000014_reference.txt\n",
            "000015_reference.txt\n",
            "000016_reference.txt\n",
            "000017_reference.txt\n",
            "000018_reference.txt\n",
            "000019_reference.txt\n",
            "000020_reference.txt\n",
            "000021_reference.txt\n",
            "000022_reference.txt\n",
            "000023_reference.txt\n",
            "000024_reference.txt\n",
            "000025_reference.txt\n",
            "000026_reference.txt\n",
            "000027_reference.txt\n",
            "000028_reference.txt\n",
            "000029_reference.txt\n",
            "000030_reference.txt\n",
            "000031_reference.txt\n",
            "000032_reference.txt\n",
            "000033_reference.txt\n",
            "000034_reference.txt\n",
            "000035_reference.txt\n",
            "000036_reference.txt\n",
            "000037_reference.txt\n",
            "000038_reference.txt\n",
            "000039_reference.txt\n",
            "000040_reference.txt\n",
            "000041_reference.txt\n",
            "000042_reference.txt\n",
            "000043_reference.txt\n",
            "000044_reference.txt\n",
            "000045_reference.txt\n",
            "000046_reference.txt\n",
            "000047_reference.txt\n",
            "000048_reference.txt\n",
            "000049_reference.txt\n",
            "000050_reference.txt\n",
            "000051_reference.txt\n",
            "000052_reference.txt\n",
            "000053_reference.txt\n",
            "000054_reference.txt\n",
            "000055_reference.txt\n",
            "000056_reference.txt\n",
            "000057_reference.txt\n",
            "000058_reference.txt\n",
            "000059_reference.txt\n",
            "000060_reference.txt\n",
            "000061_reference.txt\n",
            "000062_reference.txt\n",
            "000063_reference.txt\n",
            "000064_reference.txt\n",
            "000065_reference.txt\n",
            "000066_reference.txt\n",
            "000067_reference.txt\n",
            "000068_reference.txt\n",
            "000069_reference.txt\n",
            "000070_reference.txt\n",
            "000071_reference.txt\n",
            "000072_reference.txt\n",
            "000073_reference.txt\n",
            "000074_reference.txt\n",
            "000075_reference.txt\n",
            "000076_reference.txt\n",
            "000077_reference.txt\n",
            "000078_reference.txt\n",
            "000079_reference.txt\n",
            "000080_reference.txt\n",
            "000081_reference.txt\n",
            "000082_reference.txt\n",
            "000083_reference.txt\n",
            "000084_reference.txt\n",
            "000085_reference.txt\n",
            "000086_reference.txt\n",
            "000087_reference.txt\n",
            "000088_reference.txt\n",
            "000089_reference.txt\n",
            "000090_reference.txt\n",
            "000091_reference.txt\n",
            "000092_reference.txt\n",
            "000093_reference.txt\n",
            "000094_reference.txt\n",
            "000095_reference.txt\n",
            "000096_reference.txt\n",
            "000097_reference.txt\n",
            "000098_reference.txt\n",
            "000099_reference.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(refe_list[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "751250d0-c6a6-40aa-f5be-2866f484fd8e",
        "id": "XACGabYs6NOB"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['पठानकोट पहुंचे PM मोदी, एयरबेस का जायजा ले बॉर्डर इलाकों का करेंगे हवाई सर्वे', 'सचिन ने देशवासियों को समर्पित किया अपना दोहरा शतक', 'एनआईए करेगी छत्तीसगढ़ में सुरक्षा खामियों की जांच: आरपीएन सिंह', 'सीधी बात:  शाह बोले- हमारा बस चलता तो अब तक मंदिर बन गया होता', 'ऋषभ पंत के पास यूनिक टैलेंट, उसके साथ छेड़छाड़ नहीं कर सकते: प्रवीण आमरे']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode_list[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8266938-67dd-47b7-b49f-caf8228ef937",
        "id": "wLLj3Y5-6NOB"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['पठानकोट एयरबेस पर पहुंच रहे हैं नरेंद्र मोदी ने की पठानकोट के लिए की जांच', '175 रन के पार कर रहे हैं सचिन तेंदुलकर ने भारतीय क्रिकेट को समर्पित किया', 'नक्सली हमले में गृह मंत्री ने छत्तीसगढ़ में नक्सली नेताओं के काफिले पर की जांच', 'अमित शाह बोले- मध्य प्रदेश में राम मंदिर बन रहे हैं अमित गवर्नर अमित शाह', 'पंत की आलोचना के लिए दिल्ली कैपिटल्स के स्काउटिंग प्रमुख प्रवीण आमरे को लगता है']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge import Rouge\n",
        "\n",
        "r=Rouge()\n",
        "r_scores = r.get_scores(decode_list, refe_list, avg=True)\n",
        "#pprint.pprint(r_scores)\n",
        "print(\"ROGUE-1:\", r_scores[\"rouge-1\"][\"f\"])\n",
        "print(\"ROGUE-2:\", r_scores[\"rouge-2\"][\"f\"])\n",
        "print(\"ROGUE-l:\", r_scores[\"rouge-l\"][\"f\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4409eec-79c3-4f5f-ecdb-dbfec0fba47f",
        "id": "FgrHwPQM6NOB"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROGUE-1: 0.29283123357830865\n",
            "ROGUE-2: 0.0982716513630498\n",
            "ROGUE-l: 0.25619188663090325\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "csQVHu_T6NOC"
      },
      "execution_count": 49,
      "outputs": []
    }
  ]
}
